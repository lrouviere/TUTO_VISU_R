[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualisation avec R",
    "section": "",
    "text": "Présentation\nCe tutoriel présente une introduction au logiciel R ainsi qu’à quelques outils de visualisation avec R. On pourra trouver :\n\nles supports de cours associés à ce tutoriel ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html ;\nle tutoriel sans les corrections à l’url https://lrouviere.github.io/TUTO_VISU_R/\nle tutoriel avec les corrigés (à certains moments) à l’url https://lrouviere.github.io/TUTO_VISU_R/correction/.\n\nIl est recommandé d’utiliser mozilla firefox pour lire le tutoriel.\nLes thèmes suivants sont abordés :\n\nLogiciel R\n\nPrésentation du logiciel, environnement Rstudio, reporting avec quarto et Rmarkdown\nObjets R\nManipulation des données (essentiellement avec dplyr)\n\nVisualisation\n\nVisualisation statique (représentations standards et avec ggplot2)\nCartographie\n\nstatique avec ggmap et sf\ndynamiques avec leaflet\n\nVisualisation dynamique\n\ngraphes standards avec RamChartset plotly\nréseaux avec visNetwork\ntableaux de bord avec flexdashboard\n\n\nUn peu de statistique avec R\n\nRégression : ajustement de modèles, formules, prévisions…\nIntroduction au problème de l’estimation, lois de probabilités, notions d’estimateurs, performance d’estimateurs, intervalles de confiance.\n\n\nOn pourra trouver des supports de cours ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html. Des compléments sur les outils du tidyverse pourront être consultés dans le très complet document de Barnier (2020) ainsi que les ouvrages de Wickham et Grolemund (2017) et de Cornillon et al. (2018).\n\n\n\n\nBarnier, J. 2020. Introduction à R et au tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io.\n\n\nWickham, A., et G. Grolemund. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz."
  },
  {
    "objectID": "01-intro.html#r-script",
    "href": "01-intro.html#r-script",
    "title": "1  Introduction",
    "section": "1.1 R Script",
    "text": "1.1 R Script\nIl existe différentes façons de travailler sur RStudio. De façon classique, on peut\n\nouvrir un script.\nentrer les commandes dans le script.\nregarder les sorties dans la console (en cliquant sur le bouton run).\nsauver le script."
  },
  {
    "objectID": "01-intro.html#packages",
    "href": "01-intro.html#packages",
    "title": "1  Introduction",
    "section": "1.2 Packages",
    "text": "1.2 Packages\nUn package est une ensemble de programmes et fonctions R qui complètent les fonctions existantes par défaut dans le logiciel. Un package est généralement dédié à une méthode ou un champ d’application spécifique. Il existe plus de 18 000 packages disponibles sur le CRAN https://cran.r-project.org. On installe un package en\n\nutilisant le fonction install.packages dans la console. ou\nou cliquant sur le bouton Packages.\n\nUne fois le package installé sur la machine, on l’installe avec la fonction library :\n\ninstall.packages(package.name)\nlibrary(packages.name)\n\n\nExercice 1.1 (Installation et chargement) \n\n\nExécuter\n\niris |&gt; summarize(mean_Petal=mean(Petal.Length))\n\nQue se passe t-il ?\n\nOn a un message d’erreur. L’opérateur |&gt; n’est pas reconnu.\n\nInstaller et charger le package tidyverse et ré-exécuter le code précédent.\n\ninstall.packages(\"tidyverse\")\n\n\nlibrary(tidyverse)\niris |&gt; summarize(mean_Petal=mean(Petal.Length))\n##   mean_Petal\n## 1      3.758"
  },
  {
    "objectID": "01-intro.html#quarto",
    "href": "01-intro.html#quarto",
    "title": "1  Introduction",
    "section": "1.3 Quarto",
    "text": "1.3 Quarto\nQuarto est un langage, compatible avec notamment R et Python, qui permet de créer différents types de documents :\n\nrapports au format pdf ou rtf\npages web html\ndiaporama pour des présentations (html, beamer, PowerPoint…)\napplications web interactives\n…\n\nqui comportent du code R.\n\n1.3.1 Syntaxe\nLa syntaxe s’apprend assez facilement (il faut pratiquer), on pourra trouver un descriptif synthétique sur la page https://quarto.org ainsi que dans la cheatsheet dédiée à Rmarkdown puisque quarto est compatible avec markdown. Par exemple :\n\nCaractère en italique ou gras : *italique* et **gras** donne italique et gras\nListes non ordonnées\n- item 1\n- item 2\nproduit\n\nitem 1\nitem 2\n\nliste ordonnée :\n1. item 1\n2. item 2\nproduit\n\nitem 1\nitem 2\n\ntableau :\n|      | Col1 | Col2 | Col3 |\n|:----:|:----:|:----:|:----:|\n| Row1 |  1   |   2  |   3  |\n| Row2 |  1   |   2  |   3  |\nrenvoie\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nRow1\n1\n2\n3\n\n\nRow2\n1\n2\n3\n\n\n\n\néquation latex :\n$$\\int_a^b f(x)dx=1$$\nrenvoie \\[\\int_a^b f(x)dx=1\\]\n\n\n\n1.3.2 Les chunks\nLe code R doit être écrit dans des chunks. On peut insérer des chunks avec :\n\nla raccourci clavier Ctrl + Alt + I (OS X: Cmd + Option + I)\nla bouton Insert -&gt; Code Chunk -&gt; R\nen tapant :\n\n```{r}\ncommandes...\n```\nPlusieurs options peuvent être spécifiés au chunk en fonction de ce que l’on souhaite voir dans le document, par exemple :\n\necho : TRUEor FALSE pour spécifier si on souhaite afficher le code ;\neval : TRUEor FALSE pour spécifier si le code doit être évalusé ou non ;\nresults : hide si on ne veut pas voir la sortie du code.\n\nOn pourra trouver l’ensemble des options disponibles sur cette page : https://yihui.org/knitr/options/\n\nExercice 1.2 (Premier document) \n\n\nOuvrir un document quarto (File -&gt; New File -&gt; Quarto Document).\nCliquer sur le bouton Render et visualiser la sortie html.\nObtenir une sortie pdf.\nModifier le document en créant une section Cosinus dans laquelle on tracera la fonction cosinus, on pourra utiliser le code suivant dans un chunk.\n\nx &lt;- seq(-2*pi,2*pi,by=0.01)\ny &lt;- cos(x)\nplot(x,y,type=\"l\")\n\nAjouter une section Sinus dans laquelle on tracera la fonction sinus.\n\n\n\n\n1.3.3 Notebook\nL’environnement notebook fonctionne exactement comme un document markdown mais permet de visualiser la sortie eu format html sans avoir à recompiler le document en entier. Cet environnement est donc souvent privilégié pendant la réalisation d’un projet en science des données. Pour créer un notebook, on peut passer par RStudio : File -&gt; New File -&gt; R Notebook ou simplement remplacer\noutput: html_document\npar\noutput: html_notebook\ndans l’entête d’un document markdown.\n\nTransformer le document markdown de l’exercice précédent en notebook. On pourra visualier la sortie en cliquant sur Preview.\n\n\n\n1.3.4 Diaporama R\nRstudio propose aussi différents environnements pour construire des diaporamas. On pourra utiliser le menu File -&gt; New File -&gt; Quarto Presentation . On utilisera la même syntaxe que pour les documents markdown. Les slides sont séparés par le symbole ## et les codes R sont toujours insérés dans des chunks.\n\nExercice 1.3 (Premier document)  \n\nCréer 2 diapositives :\n\nTitre : Cosinus où on tracera la fonction cosinus.\nTitre : Sinus où on tracera la fonction sinus.\n\nEn modifiant les options des chunks modifier les diapositives de manière à\n\nne pas voir le code R mais voir les graphiques\nvoir uniquement le code R mais pas les graphiques.\n\n\n\n\n\n1.3.5 Exemples de styles de documents Quarto\nPar défaut l’entête d’un document quarto est de la forme\n---\ntitle: \"Mon document\"\nauthor: \"Laurent\"\nformat: html\neditor: visual\n---\nIl existe un grand nombre d’options qui permettent d’améliorer le document final. On peut par exemple changer la langue et ajouter une table des matières avec\nlang: fr\ntoc: true\nOn peut également utiliser des styles prédéfinis en changeant le thème, par exemple\ntheme: cerulean\n\n\n\n\n\nOn pourra trouver des compléments sur les différents styles et options ici : https://quarto.org/docs/output-formats/html-themes.html#navigation."
  },
  {
    "objectID": "01-intro.html#lenvironnement-projet-de-rstudio",
    "href": "01-intro.html#lenvironnement-projet-de-rstudio",
    "title": "1  Introduction",
    "section": "1.4 L’environnement projet de Rstudio",
    "text": "1.4 L’environnement projet de Rstudio\nIl permet de créer un répertoire dans l’arborescence et facilite la gestion des chemins. R travaille par défaut dans un répertoire que l’on peut identifier à l’aide de la commande\n\ngetwd()\n\nCe répertoire peut être modifié avec la fonction\n\nsetwd()\n\nou avec les boutons\nSession -&gt; Set Working Directory -&gt; Choose Directory\nTravailler en mode projet permet, entre autres, d’utiliser le répertoire du projet comme répertoire de travail ppar défaut.\n\n\nOuvrir Rstudio et executer la fonction getwd(). Expliquer la sortie.\n\nCette fonction renvoie le répertoire à partir duquel R travaille.\n\nCréer un projet avec\nFile -&gt; New Project -&gt; New Directory -&gt; New Project\nOn choisit un répertoire dans l’arborescence qui contiendra le répertoire de cet enseignement.\nExécuter à nouveau la commande getwd().\n\nLe répertoire de travail est maintenant le répertoire du projet.\n\nFermer le projet en cliquant sur Close Project en haut à droite de la fenêtre Rstudio.\nRé-ouvrir le projet, toujours en cliquant en haut à droite de la fenêtre Rstudio."
  },
  {
    "objectID": "02-objetsR.html#création-dobjets",
    "href": "02-objetsR.html#création-dobjets",
    "title": "2  Les objets R",
    "section": "2.1 Création d’objets",
    "text": "2.1 Création d’objets\n\n2.1.1 Numérique\nOn crée un objet R en assignant une valeur (ou un caractère, vecteur…) avec les opérateurs &lt;-, -&gt;, =\n\nb &lt;- 41.3  # assigne la valeur 41.3 à l'objet b\nx &lt;- b     # b est assigné à x\nx = b      # b est assigné à x\nb -&gt; x     # b est assigné à x\nis.numeric(b)\n## [1] TRUE\nmode(b)\n## [1] \"numeric\"\n\n\n\n2.1.2 Caractère\nLes chaines de caractères sont définies avec des guillemets : \"chaine\", par exemple\n\nx &lt;- \"La mort\"\ny &lt;- \"aux trousses\"\npaste(x,y)\n## [1] \"La mort aux trousses\"\nis.character(x)\n## [1] TRUE\n\n\n\n2.1.3 Facteur\nL’objet facteur est très utile pour travailler avec des variables qualitatives. Cet objet permet d’identifier les modalités prisent par la variable et de travailler dessus, en changeant par exemple le nom d’une modalité :\n\nV1 &lt;- factor(c(\"less20years\",\"more50years\",\"less20years\",\"more50years\",\"less20years\"))\nV1\n## [1] less20years more50years less20years more50years less20years\n## Levels: less20years more50years\nlevels(V1)\n## [1] \"less20years\" \"more50years\"\nlevels(V1) &lt;- c(\"Young\",\"Old\")\nV1\n## [1] Young Old   Young Old   Young\n## Levels: Young Old\n\n\n\n2.1.4 Logique (Booléen)\n\nx &lt;- TRUE\nis.logical(x)\n## [1] TRUE\nmode(x)\n## [1] \"logical\"\na &lt;- 1\na==1\n## [1] TRUE\na!=1\n## [1] FALSE\na&lt;0\n## [1] FALSE\na&gt;0\n## [1] TRUE"
  },
  {
    "objectID": "02-objetsR.html#vecteur",
    "href": "02-objetsR.html#vecteur",
    "title": "2  Les objets R",
    "section": "2.2 Vecteur",
    "text": "2.2 Vecteur\nOn peut définir un vecteur de plusieurs façons :\n\nfonction collect c\n\nx &lt;- c(1.2,5,9,11)\nx\n## [1]  1.2  5.0  9.0 11.0\n\nopérateur séquence :\n\n1:5\n## [1] 1 2 3 4 5\n\nfonction séquence seq\n\nseq(1,10,by=2)\n## [1] 1 3 5 7 9\nseq(0,1,length=10)\n##  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n##  [8] 0.7777778 0.8888889 1.0000000\n\nfonction rep\n\nrep(1,4)\n## [1] 1 1 1 1\nrep(c(1,3),each=3)\n## [1] 1 1 1 3 3 3\n\n\nOn peut aussi créer des vecteurs caractère ou logique\n\nx &lt;- c(\"A\",\"B\",\"C\")\nx &lt;- rep(\"A\",5)\npaste(\"X\",1:5,sep=\"-\")\n## [1] \"X-1\" \"X-2\" \"X-3\" \"X-4\" \"X-5\"\nsubstr(\"statistician\",5,9)\n## [1] \"istic\"\n\n\nc(T,F,T)\n## [1]  TRUE FALSE  TRUE\n\n\n2.2.1 Sélectionner une partie d’un vecteur\nLa sélection s’effectue à l’aide de crochets [ ]\n\nx &lt;- c(-4,-3,1,3,5,8,0)\nx[2]\n## [1] -3\nx[c(2,5)]\n## [1] -3  5\nx&gt;0\n## [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE\nx[x&gt;0]\n## [1] 1 3 5 8\n\n\n\n2.2.2 Opérations sur les vecteurs\nOn peut facilement additionner, multiplier des vecteurs :\n\nx &lt;- seq(-10,10,by=2)\ny &lt;- 1:length(x)\nx+y\n##  [1] -9 -6 -3  0  3  6  9 12 15 18 21\nx*y\n##  [1] -10 -16 -18 -16 -10   0  14  32  54  80 110\nz &lt;- x&gt;0\nx*z\n##  [1]  0  0  0  0  0  0  2  4  6  8 10\n\n\nExercice 2.1 (Manipulation de vecteurs) On s’intéresse à des fonctions classiques permettant de manipuler des vecteurs.\n\nCalculer la moyenne, la somme, la médiane et la variance du vecteur (1,3,8,9,11).\n\nx &lt;- c(1,3,8,9,11)\nmean(x)\n## [1] 6.4\nsum(x)\n## [1] 32\nmedian(x)\n## [1] 8\nvar(x)\n## [1] 17.8\n\nCréer les vecteurs suivants en utilisant la fonction rep.\nvec1 = 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 \nvec2 = 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\nvec3 = 1 1 2 2 2 3 3 3 3 4 4 4 4 4\n\nrep(1:5,3)\n##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\nrep(1:5,each=3)\n##  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\nrep(1:4,2:5)\n##  [1] 1 1 2 2 2 3 3 3 3 4 4 4 4 4\n\nCréer le vecteur suivant à l’aide de la fonction paste, puis avec la fonction str_c.\nvec4 = \"A0)\" \"A1)\" \"A2)\" \"A3)\" \"A4)\" \"A5)\" \"A6)\" \"A7)\" \"A8)\" \"A9)\" \"A10)\"\n\npaste(\"A\",0:10,\")\",sep=\"\")\n##  [1] \"A0)\"  \"A1)\"  \"A2)\"  \"A3)\"  \"A4)\"  \"A5)\"  \"A6)\"  \"A7)\"  \"A8)\"  \"A9)\" \n## [11] \"A10)\"\n#ou\nstr_c(\"A\",1:10,\")\")\n##  [1] \"A1)\"  \"A2)\"  \"A3)\"  \"A4)\"  \"A5)\"  \"A6)\"  \"A7)\"  \"A8)\"  \"A9)\"  \"A10)\"\n\nletters est un vecteur qui contient les 26 lettres de l’alphabet.\n\nTrouver le numéro de la lettre \\(q\\) (sans compter “avec les doigts” !). On pourra utiliser la fonction which ou str_which.\n\nindex_q &lt;- which(letters==\"q\")\n#ou\nindex_q &lt;- str_which(letters,\"q\")\n\n\n\n\nCréer le vecteur “a1”,“b2”,\\(\\dots\\) jusqu’à \\(q\\) et son index.\n\npaste(letters[1:index_q],1:index_q,sep=\"\")\n##  [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n## [13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\"\n#ou\nstr_c(letters[1:index_q],1:index_q)\n##  [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n## [13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\""
  },
  {
    "objectID": "02-objetsR.html#matrices",
    "href": "02-objetsR.html#matrices",
    "title": "2  Les objets R",
    "section": "2.3 Matrices",
    "text": "2.3 Matrices\nLa fonction matrix permet de définir des matrices.\n\nm &lt;- matrix(1:4,ncol=2)\nm\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nm &lt;- matrix(1:4,nrow=2)\nm\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nm &lt;- matrix(1:4,nrow=2,byrow=TRUE)\ndim(m)\n## [1] 2 2\n\nLa position d’un élément dans une matrice est indiquée par ses numéros de ligne et de colonne. Ainsi, pour sélectionner le terme de la 2ème ligne et la 1ère colonne, on utilisera\n\nm[2,1]\n## [1] 3\n\nOn peut aussi extraire des lignes et des colonnes :\n\nm[1,] #première ligne\n## [1] 1 2\nm[,2] #deuxième colonne\n## [1] 2 4\n\nIl n’est pas difficile de faire les calculs usuels sur les matrices :\n\ndet(m) #déterminant\n## [1] -2\nsolve(m) #inverse\n##      [,1] [,2]\n## [1,] -2.0  1.0\n## [2,]  1.5 -0.5\nt(m) #transposé\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nn &lt;- matrix(5:8,nrow=2)\nm+n\n##      [,1] [,2]\n## [1,]    6    9\n## [2,]    9   12\nm*n #attention : produit de Hadamart\n##      [,1] [,2]\n## [1,]    5   14\n## [2,]   18   32\nm%*%n #Produit matriciel\n##      [,1] [,2]\n## [1,]   17   23\n## [2,]   39   53\neigen(m) #Décomposition en valeurs propres\n## eigen() decomposition\n## $values\n## [1]  5.3722813 -0.3722813\n## \n## $vectors\n##            [,1]       [,2]\n## [1,] -0.4159736 -0.8245648\n## [2,] -0.9093767  0.5657675"
  },
  {
    "objectID": "02-objetsR.html#listes",
    "href": "02-objetsR.html#listes",
    "title": "2  Les objets R",
    "section": "2.4 Listes",
    "text": "2.4 Listes\nUne liste est un objet hétérogène. Elle permet de stocker des objets de différents modes dans un même objet. Par exemple, on peut céer une liste qui contient un vecteur et une matrice à l’aide de\n\nmylist &lt;- list(vector=rep(1:5),mat=matrix(1:8,nrow=2))\nmylist\n## $vector\n## [1] 1 2 3 4 5\n## \n## $mat\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8\nlength(mylist)\n## [1] 2\n\nL’extraction s’effectue en indiquant la position de l’objet à extraire dans un double crochet [[  ]] :\n\nmylist[[1]]\n## [1] 1 2 3 4 5\n\nOn peut aussi utiliser le nom de l’élément à extraire :\n\nmylist$mat\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8\nmylist[[\"mat\"]]\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8"
  },
  {
    "objectID": "02-objetsR.html#dataframe",
    "href": "02-objetsR.html#dataframe",
    "title": "2  Les objets R",
    "section": "2.5 Dataframe",
    "text": "2.5 Dataframe\nLes dataframes sont des listes particulières dont les composantes ont la même longueur, mais potentiellement des modes différents. C’est l’objet généralement utilisé pour les tableaux de données (qui contiennent souvent des variables quantitatives et qualitatives). Par exemple,\n\nname &lt;- c(\"Paul\",\"Mary\",\"Steven\",\"Charlotte\",\"Peter\")\nsex &lt;- factor(c(\"M\",\"F\",\"M\",\"F\",\"M\"))\nsize &lt;- c(180,165,168,170,175)\ndata &lt;- data.frame(name,sex,size)\nsummary(data)\n##      name           sex        size      \n##  Length:5           F:2   Min.   :165.0  \n##  Class :character   M:3   1st Qu.:168.0  \n##  Mode  :character         Median :170.0  \n##                           Mean   :171.6  \n##                           3rd Qu.:175.0  \n##                           Max.   :180.0\n\nOn observe que name est un vecteur de caractères, sex un facteur et size un vecteur numérique.\nL’extraction est similaire aux matrices et aux listes :\n\ndata[2,3]\n## [1] 165\ndata[,2]\n## [1] M F M F M\n## Levels: F M\ndata$sex\n## [1] M F M F M\n## Levels: F M"
  },
  {
    "objectID": "02-objetsR.html#quelques-fonctions-importantes",
    "href": "02-objetsR.html#quelques-fonctions-importantes",
    "title": "2  Les objets R",
    "section": "2.6 Quelques fonctions importantes",
    "text": "2.6 Quelques fonctions importantes\n\nsummary produit un résumé d’un objet\n\nsummary(data)\n##      name           sex        size      \n##  Length:5           F:2   Min.   :165.0  \n##  Class :character   M:3   1st Qu.:168.0  \n##  Mode  :character         Median :170.0  \n##                           Mean   :171.6  \n##                           3rd Qu.:175.0  \n##                           Max.   :180.0\nsummary(1:10)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    3.25    5.50    5.50    7.75   10.00\n\nmean, sum, median, var, min, max… (facile à comprendre)\nsort, order\n\nx &lt;- c(1,8,5,4)\nsort(x)\n## [1] 1 4 5 8\norder(x)\n## [1] 1 4 3 2\n\napply applique une fonction f aux lignes ou colonnes d’une matrice ou dataframe\n\nV1 &lt;- 1:10\nV2 &lt;- seq(-20,25,length=10)\ndf &lt;- data.frame(V1,V2)\napply(df,1,mean)\n##  [1] -9.5 -6.5 -3.5 -0.5  2.5  5.5  8.5 11.5 14.5 17.5\napply(df,2,sum)\n## V1 V2 \n## 55 25"
  },
  {
    "objectID": "02-objetsR.html#exercices-complémentaires",
    "href": "02-objetsR.html#exercices-complémentaires",
    "title": "2  Les objets R",
    "section": "2.7 Exercices complémentaires",
    "text": "2.7 Exercices complémentaires\n\nExercice 2.2 (Manipulation de matrices) Cet exercice propose des questions classiques sur la manipulation de matrices.\n\nCréer la matrice suivante que l’on appellera mat (on pourra utiliser les fonctions rownames et colnames) :\n\n\n\n\n\ncolumn 1\ncolumn 2\ncolumn 3\ncolumn 4\n\n\n\n\nrow-1\n1\n5\n5\n0\n\n\nrow-2\n0\n5\n6\n1\n\n\nrow-3\n3\n0\n3\n3\n\n\nrow-4\n4\n4\n4\n2\n\n\n\n\n\nmat &lt;- matrix(c(1,0,3,4,5,5,0,4,5,6,3,4,0,1,3,2),ncol=4)\nrownames(mat) &lt;- paste(\"row-\",1:4,sep=\"\")\ncolnames(mat) &lt;- paste(\"column \",1:4)\nmat\n##       column  1 column  2 column  3 column  4\n## row-1         1         5         5         0\n## row-2         0         5         6         1\n## row-3         3         0         3         3\n## row-4         4         4         4         2\n\nCréer un vecteur qui contient la diagonal de mat.\n\ndiag(mat)\n## [1] 1 5 3 2\n\nCréer une matrice qui contient les 2 premières lignes de mat.\n\nmat[1:2,]\n##       column  1 column  2 column  3 column  4\n## row-1         1         5         5         0\n## row-2         0         5         6         1\n\nCréer une matrice qui contient les 2 dernières colonnes de mat.\n\nmat[,3:4]\n##       column  3 column  4\n## row-1         5         0\n## row-2         6         1\n## row-3         3         3\n## row-4         4         2\n\nCalculer le déterminant et l’inverse de mat.\n\ndet(mat)\n## [1] 60\nsolve(mat)\n##           row-1 row-2      row-3         row-4\n## column  1   0.5  -0.5  0.1666667 -1.665335e-16\n## column  2  -0.6   0.4 -0.4666667  5.000000e-01\n## column  3   0.7  -0.3  0.4333333 -5.000000e-01\n## column  4  -1.2   0.8 -0.2666667  5.000000e-01\n\n\n\n\nExercice 2.3 (Manipulations simples sur un jeu de données) On considère le jeu de données iris disponible dans R :\n\ndata(iris)\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\n\nCalculer les moyennes et variances des variables Sepal.Width et Petal.Length.\n\nmean(iris$Sepal.Width)\n## [1] 3.057333\nmean(iris$Petal.Length)\n## [1] 3.758\nvar(iris$Sepal.Width)\n## [1] 0.1899794\nvar(iris$Petal.Length)\n## [1] 3.116278\n\nCréer un sous jeu de données qui contient uniquement les iris de l’espèce versicolor. On appellera ce tableau iris2.\n\ntest &lt;- iris$Species==\"versicolor\"\niris2 &lt;- iris[test,]\nsummary(iris2)\n##   Sepal.Length    Sepal.Width     Petal.Length   Petal.Width          Species  \n##  Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000   setosa    : 0  \n##  1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200   versicolor:50  \n##  Median :5.900   Median :2.800   Median :4.35   Median :1.300   virginica : 0  \n##  Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326                  \n##  3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500                  \n##  Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800\n\nOrdonner les individus dans iris2 par valeurs décroissantes de la variable Sepal.Length (on pourra utiliser la fonction order).\n\nord &lt;- order(iris2$Sepal.Length,decreasing=TRUE)\niris3 &lt;- iris2[ord,]\nhead(iris3)\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n## 51          7.0         3.2          4.7         1.4 versicolor\n## 53          6.9         3.1          4.9         1.5 versicolor\n## 77          6.8         2.8          4.8         1.4 versicolor\n## 66          6.7         3.1          4.4         1.4 versicolor\n## 78          6.7         3.0          5.0         1.7 versicolor\n## 87          6.7         3.1          4.7         1.5 versicolor\n\nCalculer les valeurs moyennes de Sepal.Length pour chaque espèce.\n\nmean(iris[iris$Species==\"versicolor\",\"Sepal.Length\"])\n## [1] 5.936\nmean(iris[iris$Species==\"virginica\",\"Sepal.Length\"])\n## [1] 6.588\nmean(iris[iris$Species==\"setosa\",\"Sepal.Length\"])\n## [1] 5.006\n\nAjouter une variable (qu’on appellera sum.Petal) dans le dataframe iris qui contiendra la somme de Petal.Length et Petal.Width.\n\niris$sum.petal &lt;- iris$Petal.Length+iris$Petal.Width\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species sum.petal\n## 1          5.1         3.5          1.4         0.2  setosa       1.6\n## 2          4.9         3.0          1.4         0.2  setosa       1.6\n## 3          4.7         3.2          1.3         0.2  setosa       1.5\n## 4          4.6         3.1          1.5         0.2  setosa       1.7\n## 5          5.0         3.6          1.4         0.2  setosa       1.6\n## 6          5.4         3.9          1.7         0.4  setosa       2.1\n\n\n\n\nExercice 2.4 (Fonction apply) On considère le jeu de données suivant\n\nlibrary(lattice)\ndata(\"ethanol\")\n\n\nCalculer les indicateurs numériques standards (moyenne, min, max, etc.) des 3 variables du jeux de données ethanol (disponible dans le package lattice).\n\nsummary(ethanol)\n##       NOx              C                E         \n##  Min.   :0.370   Min.   : 7.500   Min.   :0.5350  \n##  1st Qu.:0.953   1st Qu.: 8.625   1st Qu.:0.7618  \n##  Median :1.754   Median :12.000   Median :0.9320  \n##  Mean   :1.957   Mean   :12.034   Mean   :0.9265  \n##  3rd Qu.:3.003   3rd Qu.:15.000   3rd Qu.:1.1098  \n##  Max.   :4.028   Max.   :18.000   Max.   :1.2320\napply(ethanol,2,mean)\n##        NOx          C          E \n##  1.9573750 12.0340909  0.9264773\n\nCalculer les quartiles de chaque variables. On pourra faire un apply avec la fonction quantile.\n\nquantile(ethanol$NOx,probs=c(0.25,0.5,0.75))\n##    25%    50%    75% \n## 0.9530 1.7545 3.0030\nquantile(ethanol$C,probs=c(0.25,0.5,0.75))\n##    25%    50%    75% \n##  8.625 12.000 15.000\nquantile(ethanol$E,probs=c(0.25,0.5,0.75))\n##     25%     50%     75% \n## 0.76175 0.93200 1.10975\n#ou mieux\napply(ethanol,2,quantile,probs=c(0.25,0.5,0.75))\n##        NOx      C       E\n## 25% 0.9530  8.625 0.76175\n## 50% 1.7545 12.000 0.93200\n## 75% 3.0030 15.000 1.10975\n\nFaire de même pour les déciles.\n\napply(ethanol,2,quantile,probs=seq(0.1,0.9,by=0.1))\n##        NOx    C      E\n## 10% 0.6000  7.5 0.6496\n## 20% 0.8030  7.5 0.7206\n## 30% 1.0138  9.0 0.7977\n## 40% 1.4146  9.0 0.8636\n## 50% 1.7545 12.0 0.9320\n## 60% 2.0994 12.6 1.0104\n## 70% 2.7232 15.0 1.0709\n## 80% 3.3326 15.0 1.1404\n## 90% 3.6329 18.0 1.1920\n\n\n\n\nExercice 2.5 (Données manquantes) On considère le jeu de données presidents\n\ndata(\"presidents\")\ndf &lt;- matrix(presidents,ncol=4,byrow=T)\n\n\nEst-ce que la ligne 20 contient au moins une données manquante ? On pourra utiliser la fonction any.\n\nany(is.na(df[20,]))\n## [1] FALSE\n\nQuelles sont les lignes de df qui contiennent au moins une donnée manquante ? On pourra utiliser la fonction which.\n\nwhich(apply(is.na(df),1,any))\n## [1]  1  4  8 28\n\nSupprimer les lignes de df qui contiennent au moins une donnée manquante.\n\nind_sup &lt;- which(apply(is.na(df),1,any))\ndf1 &lt;- df[-ind_sup,]\nsummary(df1)\n##        V1              V2              V3              V4       \n##  Min.   :28.00   Min.   :24.00   Min.   :24.00   Min.   :23.00  \n##  1st Qu.:52.50   1st Qu.:49.00   1st Qu.:46.50   1st Qu.:44.50  \n##  Median :64.50   Median :60.50   Median :61.00   Median :55.50  \n##  Mean   :60.96   Mean   :56.69   Mean   :56.27   Mean   :53.04  \n##  3rd Qu.:71.00   3rd Qu.:64.75   3rd Qu.:66.50   3rd Qu.:61.50  \n##  Max.   :80.00   Max.   :83.00   Max.   :79.00   Max.   :78.00\n\n\nOn aurait aussi pu utiliser directement la fonction na.omit :\n\n\ndf2 &lt;- na.omit(df)\nall(df1==df2)\n## [1] TRUE"
  },
  {
    "objectID": "03-dplyr.html#importer-des-données",
    "href": "03-dplyr.html#importer-des-données",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.1 Importer des données",
    "text": "3.1 Importer des données\nLes fonctions read.table et read.csv sont les fonctions standards de R pour importer des données à partir de fichiers .txt ou .csv. Il est important de bien gérer le chemin du répertoire où se trouve le fichier. On peut le spécifier explicitement ou utiliser des fonctions comme file.path :\n\npath &lt;- file.path(\"data/\", \"piscines.csv\") #premier : répertoire, deuxième : fichier\npiscines &lt;- read.csv(path)\nclass(piscines)\n## [1] \"data.frame\"\nsummary(piscines)\n##      Name             Address             Latitude        Longitude    \n##  Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n##  Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n##  Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n##                                        Mean   :-27.49   Mean   :153.0  \n##                                        3rd Qu.:-27.45   3rd Qu.:153.1  \n##                                        Max.   :-27.31   Max.   :153.2\n\nIl existe plusieurs options importantes dans read.csv, notamment\n\nsep : le caractère de séparation (espace, virgule…)\ndec : le caractère pour le séparateur décimal (vigule, point…)\nheader : logique pour indiquer si le nom des variables est spécifié à la première ligne du fichier\nrow.names : vecteurs des identifiants (si besoin)\nna.strings : vecteur de caractères pour repérer les données manquantes.\n…\n\nLe package readr du tidyverse propose d’autres fonctions comme read_csv ou read_delim. Il n’y a pas de différences énormes avec les fonctions standards, les objets créés sont des tibbles et plus des dataframes (même si les tibbles sont des dataframes…). Par exemple\n\nlibrary(readr)\npiscines &lt;- read_csv(\"data/piscines.csv\")\nsummary(piscines)\n##      Name             Address             Latitude        Longitude    \n##  Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n##  Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n##  Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n##                                        Mean   :-27.49   Mean   :153.0  \n##                                        3rd Qu.:-27.45   3rd Qu.:153.1  \n##                                        Max.   :-27.31   Max.   :153.2\nclass(piscines)\n## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\n\nEnfin si on n’est pas très à l’aise avec ces fonctions, on pourra utiliser le bouton Import Dataset qui se trouve dans l’onglet Environment de RStudio. Cette manière de procédé fonctionne pour des jeux de données “propres”. Si les bases contiennent trop de spécificités, on devra utiliser les fonctions présentées précédemment avec les bonnes options.\n\nExercice 3.1 (Premières importations avec readr) On étudie les fonctions classiques permettant d’importer des données.\n\nImporter les données qui se trouvent dans le fichier mydata.csv. On utilisera les fonctions read_csv, read_csv2 et read_delim avec les options par défaut et on comparera les sorties.\n\nread_csv(\"data/mydata.csv\")\n## # A tibble: 3 × 1\n##   `surname;height;weight;feet_size;sex`\n##   &lt;chr&gt;                                \n## 1 tony;184;80;9.5;M                    \n## 2 james;175.5;78;8.5;M                 \n## 3 john;158;72;8;M\nread_csv2(\"data/mydata.csv\")\n## # A tibble: 3 × 5\n##   surname height weight feet_size sex  \n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;\n## 1 tony       184     80        95 M    \n## 2 james     1755     78        85 M    \n## 3 john       158     72         8 M\nread_delim(\"data/mydata.csv\")\n## # A tibble: 3 × 5\n##   surname height weight feet_size sex  \n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;\n## 1 tony      184      80       9.5 M    \n## 2 james     176.     78       8.5 M    \n## 3 john      158      72       8   M\n\n\nread_csv n’utilise pas le bon séparateur par défaut, read_csv2 ne lit pas correctement le symbole pour la décimale, read_delim fonctionne bien pour ce fichier (sinon il aurait fallu ajouter l’option delim).\n\nImporter les données qui se trouvent dans le fichier mydata2.csv.\n\ndata2 &lt;- read_delim(\"data/mydata2.csv\",delim=\" \")\ndata2\n## # A tibble: 4 × 4\n##   height weight  size sex  \n##   &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;\n## 1 184    80       9.5 M    \n## 2 175.5  78       8.5 M    \n## 3 .      72       8   M    \n## 4 178    .        7   F\nsummary(data2)\n##     height             weight               size          sex           \n##  Length:4           Length:4           Min.   :7.00   Length:4          \n##  Class :character   Class :character   1st Qu.:7.75   Class :character  \n##  Mode  :character   Mode  :character   Median :8.25   Mode  :character  \n##                                        Mean   :8.25                     \n##                                        3rd Qu.:8.75                     \n##                                        Max.   :9.50\n\n\nLes variable height et weight sont interprétées comme des variables qualitatives, cela vient du fait qu’il y a des données manquante mal lues.\n\nCe fichier contient des données manquantes (identifiées par un point). A l’aide de l’option na, refaire l’importation en identifiant correctement les données manquantes.\n\ndata2 &lt;- read_delim(\"data/mydata2.csv\",delim=\" \",na=\".\")\ndata2\n## # A tibble: 4 × 4\n##   height weight  size sex  \n##    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n## 1   184      80   9.5 M    \n## 2   176.     78   8.5 M    \n## 3    NA      72   8   M    \n## 4   178      NA   7   F\nsummary(data2)\n##      height          weight           size          sex           \n##  Min.   :175.5   Min.   :72.00   Min.   :7.00   Length:4          \n##  1st Qu.:176.8   1st Qu.:75.00   1st Qu.:7.75   Class :character  \n##  Median :178.0   Median :78.00   Median :8.25   Mode  :character  \n##  Mean   :179.2   Mean   :76.67   Mean   :8.25                     \n##  3rd Qu.:181.0   3rd Qu.:79.00   3rd Qu.:8.75                     \n##  Max.   :184.0   Max.   :80.00   Max.   :9.50                     \n##  NA's   :1       NA's   :1\n\nChanger les levels de la variable sex en woman et man (on pourra utiliser la fonction levels).\n\ndata22 &lt;- data2\n\n\n1ère façon :\n\ndata2$sex &lt;- as.factor(data2$sex)\nlevels(data2$sex) &lt;- c(\"woman\",\"man\")\ndata2\n## # A tibble: 4 × 4\n##   height weight  size sex  \n##    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n## 1   184      80   9.5 man  \n## 2   176.     78   8.5 man  \n## 3    NA      72   8   man  \n## 4   178      NA   7   woman\n\n2ème façon avec recode_factor du package forcats :\n\ndata22$sex &lt;- recode_factor(data2$sex,\"F\"=\"woman\",\"M\"=\"man\")\ndata22\n## # A tibble: 4 × 4\n##   height weight  size sex  \n##    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n## 1   184      80   9.5 man  \n## 2   176.     78   8.5 man  \n## 3    NA      72   8   man  \n## 4   178      NA   7   woman\n\n\n\n\n\nExercice 3.2 (Importer avec read.csv) Refaire l’exercice précédent avec la fonction read.csv.\n\nOn commence avec les paramètres par défaut :\n\n\ndata1 &lt;- read.csv(\"data/mydata.csv\")\nsummary(data1)\n##  surname.height.weight.feet_size.sex\n##  Length:3                           \n##  Class :character                   \n##  Mode  :character\n\n\nLe séparateur n’est pas bien défini ! On corrige :\n\n\ndata1 &lt;- read.csv(\"data/mydata.csv\",sep=\";\",\n                  dec=\".\",row.names = 1)\nsummary(data1)\n##      height          weight        feet_size         sex           \n##  Min.   :158.0   Min.   :72.00   Min.   :8.000   Length:3          \n##  1st Qu.:166.8   1st Qu.:75.00   1st Qu.:8.250   Class :character  \n##  Median :175.5   Median :78.00   Median :8.500   Mode  :character  \n##  Mean   :172.5   Mean   :76.67   Mean   :8.667                     \n##  3rd Qu.:179.8   3rd Qu.:79.00   3rd Qu.:9.000                     \n##  Max.   :184.0   Max.   :80.00   Max.   :9.500\n\n\nPour le second fichier on fait :\n\n\ndata2 &lt;- read.csv(\"data/mydata2.csv\",sep=\"\",na.strings = \".\")\ndata2$sex &lt;- recode_factor(data2$sex,\"F\"=\"woman\",\"M\"=\"man\")\ndata2\n##   height weight size   sex\n## 1  184.0     80  9.5   man\n## 2  175.5     78  8.5   man\n## 3     NA     72  8.0   man\n## 4  178.0     NA  7.0 woman\nsummary(data2)\n##      height          weight           size         sex   \n##  Min.   :175.5   Min.   :72.00   Min.   :7.00   woman:1  \n##  1st Qu.:176.8   1st Qu.:75.00   1st Qu.:7.75   man  :3  \n##  Median :178.0   Median :78.00   Median :8.25            \n##  Mean   :179.2   Mean   :76.67   Mean   :8.25            \n##  3rd Qu.:181.0   3rd Qu.:79.00   3rd Qu.:8.75            \n##  Max.   :184.0   Max.   :80.00   Max.   :9.50            \n##  NA's   :1       NA's   :1\n\n\n\nExercice 3.3 (Jointure de tables) On considère les 3 jeux de données suivants, au format tibble :\n\ndf1 &lt;- tibble(name=c(\"Mary\",\"Peter\",\"John\",\"July\"),age=c(18,25,21,43))\ndf2 &lt;- tibble(name=c(\"Zac\",\"Julian\"),age=c(23,48))\ndf3 &lt;- tibble(size=c(154,178,182,134,142),name1=c(\"Peter\",\"Mary\",\"July\",\"John\",\"stef\"))\ndf1\n## # A tibble: 4 × 2\n##   name    age\n##   &lt;chr&gt; &lt;dbl&gt;\n## 1 Mary     18\n## 2 Peter    25\n## 3 John     21\n## 4 July     43\ndf2\n## # A tibble: 2 × 2\n##   name     age\n##   &lt;chr&gt;  &lt;dbl&gt;\n## 1 Zac       23\n## 2 Julian    48\ndf3\n## # A tibble: 5 × 2\n##    size name1\n##   &lt;dbl&gt; &lt;chr&gt;\n## 1   154 Peter\n## 2   178 Mary \n## 3   182 July \n## 4   134 John \n## 5   142 stef\n\nOn souhaite assembler ces tables en utilisant les fonctions de jointure du tidyverse (left_join, full_join par exemple). On pourra consulter la cheatsheet Data transformation with dplyr (help -&gt; cheatsheets -&gt; …).\n\nAssembler df1 avec df2 en utilisant bind_rows et calculer la moyenne de la variable age. On appellera df cette nouvelle table.\n\ndf &lt;- bind_rows(df1,df2)\nmean(df$age)\n## [1] 29.66667\n\nAssembler df avec df3 en utilisant full_join.\n\na1 &lt;- full_join(df,df3,by=c(\"name\"=\"name1\"))\na1\n## # A tibble: 7 × 3\n##   name     age  size\n##   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mary      18   178\n## 2 Peter     25   154\n## 3 John      21   134\n## 4 July      43   182\n## 5 Zac       23    NA\n## 6 Julian    48    NA\n## 7 stef      NA   142\n\nFaire la même chose avec inner_join.\n\na2 &lt;- inner_join(df,df3,by=c(\"name\"=\"name1\"))\na2\n## # A tibble: 4 × 3\n##   name    age  size\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mary     18   178\n## 2 Peter    25   154\n## 3 John     21   134\n## 4 July     43   182\n\nExpliquer les différences entre full_join et inner_join.\n\ninner_join retient uniquement les individus pour lesquels age et size ont été observés. full_join garde tous les individus, des NA sont ajoutés lorsque la variable n’est pas observée."
  },
  {
    "objectID": "03-dplyr.html#le-package-dplyr",
    "href": "03-dplyr.html#le-package-dplyr",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.2 Le package dplyr",
    "text": "3.2 Le package dplyr\ndplyr est un package du tidyverse qui permet de faciliter la manipulation des données. Il propose une syntaxe claire (basée sur une grammaire) pour travailler sur les données. On pourra trouver des informations à cet url https://spark.rstudio.com/dplyr.html ou sur la cheatsheet.\nNous avons vu quelques opérations standards pour manipuler les données. Par exemple, on peut obtenir les Longitude et Latitude des piscines ayant une Longitude supérieure à 153 avec\n\npiscines[piscines$Longitude&gt;153,c(\"Longitude\",\"Latitude\")]\n## # A tibble: 16 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.5\n##  3      153.    -27.4\n##  4      153.    -27.5\n##  5      153.    -27.5\n##  6      153.    -27.5\n##  7      153.    -27.6\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.5\n## 11      153.    -27.5\n## 12      153.    -27.4\n## 13      153.    -27.6\n## 14      153.    -27.3\n## 15      153.    -27.5\n## 16      153.    -27.5\n\ndplyr propose de faire la même chose avec une syntaxe plus claire\n\nlibrary(tidyverse) #ou library(dplyr)\npiscines |&gt; select(Longitude,Latitude) |&gt; filter(Longitude&gt;153)\n## # A tibble: 16 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.5\n##  3      153.    -27.4\n##  4      153.    -27.5\n##  5      153.    -27.5\n##  6      153.    -27.5\n##  7      153.    -27.6\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.5\n## 11      153.    -27.5\n## 12      153.    -27.4\n## 13      153.    -27.6\n## 14      153.    -27.3\n## 15      153.    -27.5\n## 16      153.    -27.5\n\nLe code est plus efficace et facile à lire.\ndplyr propose une grammaire dont les principaux verbes sont :\n\nselect() : sélectionner des colonnes (variables)\nfilter() : filtrer des lignes (individus)\narrange() : ordonner des lignes\nmutate() : créer des nouvelles colonnes (nouvelles variables)\nsummarise() : calculer des résumés numériques (ou résumés statistiques)\ngroup_by() : effectuer des opérations pour des groupes d’individus\n\nNous les présentons dans la partie suivante.\n\n3.2.1 Les principaux verbes dplyr\n\nLe verbe select()\nIl permet de sélectionner des variables (colonnes) :\n\nselect(df, VAR1, VAR2, ...)\n\nPar exemple,\n\ncoord &lt;- select(piscines, Latitude, Longitude)\nhead(piscines, n=2)\n## # A tibble: 2 × 4\n##   Name                        Address                         Latitude Longitude\n##   &lt;chr&gt;                       &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;\n## 1 Acacia Ridge Leisure Centre 1391 Beaudesert Road, Acacia R…    -27.6      153.\n## 2 Bellbowrie Pool             Sugarwood Street, Bellbowrie       -27.6      153.\nhead(coord, n=2)\n## # A tibble: 2 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.6      153.\n## 2    -27.6      153.\n\nOn peut utiliser les helper functions (begins_with, end_with, contains, matches) pour des sélections plus précises basées sur le nom des variables.\n\ncoord &lt;- select(piscines, ends_with(\"tude\"))\nhead(coord, n=2)\n## # A tibble: 2 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.6      153.\n## 2    -27.6      153.\n\n\n\nLe verbe mutate()\nIl permet de créer des nouvelles variables\n\nmutate(df, NEW.VAR = expression(VAR1, VAR2, ...))\n\nPar exemple\n\ndf &lt;- mutate(piscines, phrase=paste(\"Swimming pool\", Name, \"is located at the address\", Address))\nselect(df,phrase)\n## # A tibble: 20 × 1\n##    phrase                                                                       \n##    &lt;chr&gt;                                                                        \n##  1 Swimming pool Acacia Ridge Leisure Centre is located at the address 1391 Bea…\n##  2 Swimming pool Bellbowrie Pool is located at the address Sugarwood Street, Be…\n##  3 Swimming pool Carole Park is located at the address Cnr Boundary Road and Wa…\n##  4 Swimming pool Centenary Pool (inner City) is located at the address 400 Greg…\n##  5 Swimming pool Chermside Pool is located at the address 375 Hamilton Road, Ch…\n##  6 Swimming pool Colmslie Pool (Morningside) is located at the address 400 Lytt…\n##  7 Swimming pool Spring Hill Baths (inner City) is located at the address 14 To…\n##  8 Swimming pool Dunlop Park Pool (Corinda) is located at the address 794 Oxley…\n##  9 Swimming pool Fortitude Valley Pool is located at the address 432 Wickham St…\n## 10 Swimming pool Hibiscus Sports Complex (upper MtGravatt) is located at the ad…\n## 11 Swimming pool Ithaca Pool ( Paddington) is located at the address 131 Caxton…\n## 12 Swimming pool Jindalee Pool is located at the address 11 Yallambee Road, Jin…\n## 13 Swimming pool Manly Pool is located at the address 1 Fairlead Crescent, Manly\n## 14 Swimming pool Mt Gravatt East Aquatic Centre is located at the address Cnr w…\n## 15 Swimming pool Musgrave Park Pool (South Brisbane) is located at the address …\n## 16 Swimming pool Newmarket Pool is located at the address 71 Alderson Stret, Ne…\n## 17 Swimming pool Runcorn Pool is located at the address 37 Bonemill Road, Runco…\n## 18 Swimming pool Sandgate Pool is located at the address 231 Flinders Parade, S…\n## 19 Swimming pool Langlands Parks Pool (Stones Corner) is located at the address…\n## 20 Swimming pool Yeronga Park Pool is located at the address 81 School Road, Ye…\n\nOn peut également créer plusieurs variables avec un seul mutate :\n\nmutate(piscines,\n       phrase = paste(\"Swimming pool\", Name, \"is located at the address\", Address),\n       unused = Longitude + Latitude\n)\n## # A tibble: 20 × 6\n##    Name                                 Address Latitude Longitude phrase unused\n##    &lt;chr&gt;                                &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n##  1 Acacia Ridge Leisure Centre          1391 B…    -27.6      153. Swimm…   125.\n##  2 Bellbowrie Pool                      Sugarw…    -27.6      153. Swimm…   125.\n##  3 Carole Park                          Cnr Bo…    -27.6      153. Swimm…   125.\n##  4 Centenary Pool (inner City)          400 Gr…    -27.5      153. Swimm…   126.\n##  5 Chermside Pool                       375 Ha…    -27.4      153. Swimm…   126.\n##  6 Colmslie Pool (Morningside)          400 Ly…    -27.5      153. Swimm…   126.\n##  7 Spring Hill Baths (inner City)       14 Tor…    -27.5      153. Swimm…   126.\n##  8 Dunlop Park Pool (Corinda)           794 Ox…    -27.5      153. Swimm…   125.\n##  9 Fortitude Valley Pool                432 Wi…    -27.5      153. Swimm…   126.\n## 10 Hibiscus Sports Complex (upper MtGr… 90 Klu…    -27.6      153. Swimm…   126.\n## 11 Ithaca Pool ( Paddington)            131 Ca…    -27.5      153. Swimm…   126.\n## 12 Jindalee Pool                        11 Yal…    -27.5      153. Swimm…   125.\n## 13 Manly Pool                           1 Fair…    -27.5      153. Swimm…   126.\n## 14 Mt Gravatt East Aquatic Centre       Cnr we…    -27.5      153. Swimm…   126.\n## 15 Musgrave Park Pool (South Brisbane)  100 Ed…    -27.5      153. Swimm…   126.\n## 16 Newmarket Pool                       71 Ald…    -27.4      153. Swimm…   126.\n## 17 Runcorn Pool                         37 Bon…    -27.6      153. Swimm…   125.\n## 18 Sandgate Pool                        231 Fl…    -27.3      153. Swimm…   126.\n## 19 Langlands Parks Pool (Stones Corner) 5 Pani…    -27.5      153. Swimm…   126.\n## 20 Yeronga Park Pool                    81 Sch…    -27.5      153. Swimm…   125.\n\n\n\nLe verbe filter()\nIl permet de sélectionner (filtrer) des individus (lignes) :\n\nfilter(df, TEST)\n\nPar exemple\n\np1 &lt;- filter(piscines, Longitude&gt;153.02)\nselect(p1,Longitude)\n## # A tibble: 12 × 1\n##    Longitude\n##        &lt;dbl&gt;\n##  1      153.\n##  2      153.\n##  3      153.\n##  4      153.\n##  5      153.\n##  6      153.\n##  7      153.\n##  8      153.\n##  9      153.\n## 10      153.\n## 11      153.\n## 12      153.\n\nou (on sélectionne les piscines dont le nom contient Pool)\n\ndf &lt;- filter(piscines, !grepl(\"Pool\", Name))\nselect(df,Name)\n## # A tibble: 5 × 1\n##   Name                                     \n##   &lt;chr&gt;                                    \n## 1 Acacia Ridge Leisure Centre              \n## 2 Carole Park                              \n## 3 Spring Hill Baths (inner City)           \n## 4 Hibiscus Sports Complex (upper MtGravatt)\n## 5 Mt Gravatt East Aquatic Centre\n\nou (on sélectionne les piscines avec une longitude plus grande que 153.02 ou une latitude plus petite que -27.488)\n\np2 &lt;- filter(piscines, Longitude&gt;153.02 | Latitude &lt; -27.488)\nselect(p2, Longitude, Latitude)\n## # A tibble: 17 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.6\n##  3      153.    -27.6\n##  4      153.    -27.5\n##  5      153.    -27.4\n##  6      153.    -27.5\n##  7      153.    -27.5\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.6\n## 11      153.    -27.5\n## 12      153.    -27.5\n## 13      153.    -27.5\n## 14      153.    -27.6\n## 15      153.    -27.3\n## 16      153.    -27.5\n## 17      153.    -27.5\n\nOn peut également utiliser la fonction slice pour choisir des individus à partir de leurs indices :\n\nslice(piscines,5:8)\n## # A tibble: 4 × 4\n##   Name                           Address                      Latitude Longitude\n##   &lt;chr&gt;                          &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt;\n## 1 Chermside Pool                 375 Hamilton Road, Chermside    -27.4      153.\n## 2 Colmslie Pool (Morningside)    400 Lytton Road, Morningside    -27.5      153.\n## 3 Spring Hill Baths (inner City) 14 Torrington Street, Sprin…    -27.5      153.\n## 4 Dunlop Park Pool (Corinda)     794 Oxley Road, Corinda         -27.5      153.\n\n\n\nLe verbe arrange()\nIl permet d’ordonner les individus en fonction d’une variable\n\narrange(df, VAR) #tri croissant\n\nou\n\narrange(df, desc(VAR)) #tri décroissant\n\nPar exemple\n\narrange(piscines, Longitude)\n## # A tibble: 20 × 4\n##    Name                                      Address          Latitude Longitude\n##    &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n##  1 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n##  2 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n##  3 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n##  4 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n##  5 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n##  6 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n##  7 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n##  8 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n##  9 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n## 10 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n## 11 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n## 12 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n## 13 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n## 14 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n## 15 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n## 16 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n## 17 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n## 18 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n## 19 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n## 20 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n\nou\n\narrange(piscines, desc(Longitude))\n## # A tibble: 20 × 4\n##    Name                                      Address          Latitude Longitude\n##    &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n##  1 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n##  2 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n##  3 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n##  4 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n##  5 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n##  6 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n##  7 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n##  8 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n##  9 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n## 10 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n## 11 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n## 12 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n## 13 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n## 14 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n## 15 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n## 16 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n## 17 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n## 18 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n## 19 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n## 20 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n\n\n\n\n3.2.2 Les verbes summarize et groub_by\nLes verbes précédents permettent de manipuler les données en sélectionnant des individus ou variables essentiellement. Ces deux nouveaux verbes vont permettre de calculer des indicateurs statistiques sur un jeu de données.\n\nLe verbe summarize (ou summarise)\nIl permet de créer des nouveaux jeux de données qui contiennent des résumés statistiques du jeu de données initial comme la moyenne, variance, médiane de variables. Par exemple\n\nsummarise(piscines,\n          mean_long = mean(Longitude),\n          med_lat = median(Latitude),\n          min_lat = min(Latitude),\n          sum_long = sum(Longitude)\n)\n## # A tibble: 1 × 4\n##   mean_long med_lat min_lat sum_long\n##       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n## 1      153.   -27.5   -27.6    3061.\n\ndplyr contient également les fonction suivantes (souvent utilisées en statistique) :\n\nn() : nombre de lignes (individus d’un jeu de données).\nn_distinct() : nombre d’éléments distincts dans un vecteur.\nfisrt() et last() : premier et dernier élément d’un vecteur.\n\nPar exemple, on obtient le nombre de piscines dans le jeu de données, et la longitude de la dernière piscine avec\n\nsummarise(piscines,n())\n## # A tibble: 1 × 1\n##   `n()`\n##   &lt;int&gt;\n## 1    20\nsummarise(piscines,last(Longitude))\n## # A tibble: 1 × 1\n##   `last(Longitude)`\n##               &lt;dbl&gt;\n## 1              153.\n\nOn peut aussi utiliser summarise_all, summarise_at qui vont permettre de répéter les mêmes opérations sur plusieurs variables. Par exemple\n\nsummarise_at(piscines,3:4,mean)\n## # A tibble: 1 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.5      153.\n\n\n\nRegrouper des données avec Group_by\ngroup_by permet d’appliquer une ou des opérations à des groupes de données (ou d’individus). Par exemple, imaginons que l’on souhaite calculer les longitudes moyennes des piscines scindées en 2 groupes : petites et grande latitudes. On créé d’abord une variable lat_dis qui permet d’identifier les latitudes (petite ou grande) :\n\nlat_mean &lt;- piscines |&gt; summarise(mean(Latitude))\npisc1 &lt;- piscines |&gt; mutate(lat_dis=factor(Latitude&gt;as.numeric(lat_mean)))\nlevels(pisc1$lat_dis) &lt;- c(\"Low\",\"High\")\n\nIl reste maintenant à utiliser group_by pour obtenir les longitudes moyennes des 2 groupes :\n\nsummarise(group_by(pisc1,lat_dis),mean_long=mean(Longitude))\n## # A tibble: 2 × 2\n##   lat_dis mean_long\n##   &lt;fct&gt;       &lt;dbl&gt;\n## 1 Low          153.\n## 2 High         153.\n\n\n\n\n3.2.3 Assembler des verbes avec l’opérateur de chainage |&gt;\nUn des principaux intérêts de dplyr est bien entendu d’utiliser plusieurs verbes pour arriver au résultat souhaité. C’est ce qui est fait plus haut et nous observons que la syntaxe n’est pas facile à lire. Le package propose un opérateur de chainage ou pipe opérateur qui permet de rentre cette syntaxe plus lisible. Cet opérateur consiste à décomposer le code étape par étape et à relier ces étapes par le symbole |&gt;. On peut par exemple réécrire l’exemple précédent avec :\n\nLe jeu de données\n\npisc1\n\nÉtape group_by\n\npisc1 |&gt; group_by(lat_dis)\n\nÉtape summarise\n\npisc1 |&gt; group_by(lat_dis) |&gt; summarise(mean_long=mean(Longitude))\n## # A tibble: 2 × 2\n##   lat_dis mean_long\n##   &lt;fct&gt;       &lt;dbl&gt;\n## 1 Low          153.\n## 2 High         153.\n\n\nqui donne le résultat souhaité.\nCet opérateur peut être utilisé pour toutes les fonctions R. Il revient à considérer comme premier argument du terme à droite du pipe le terme à gauche de ce dernier. Par exemple\n\nmean(1:10)\n## [1] 5.5\n1:10 |&gt; mean()\n## [1] 5.5\n\nIl est recommandé d’utiliser cet opérateur lorsque on chaîne les verbes dplyr, la syntaxe est beaucoup plus claire.\n\n\n3.2.4 Quelques exercices\n\nExercice 3.4 (Dplyr sur les iris de Fisher) On considère le jeu de données iris\n\niris &lt;- iris |&gt; as_tibble()\n\nRépondre aux questions suivantes en utilisant les verbes dplyr et l’opérateur |&gt;.\n\nSélectionner les variables Petal.Width et Species.\n\niris |&gt; select(Petal.Width,Species)\n## # A tibble: 150 × 2\n##    Petal.Width Species\n##          &lt;dbl&gt; &lt;fct&gt;  \n##  1         0.2 setosa \n##  2         0.2 setosa \n##  3         0.2 setosa \n##  4         0.2 setosa \n##  5         0.2 setosa \n##  6         0.4 setosa \n##  7         0.3 setosa \n##  8         0.2 setosa \n##  9         0.2 setosa \n## 10         0.1 setosa \n## # ℹ 140 more rows\n\nConstruire une table qui contient uniquement les iris d’espèce versicolor ou virginica (on pourra utiliser le symbole | pour la condition ou).\n\niris |&gt; filter(Species==\"versicolor\" | Species==\"virginica\")\n## # A tibble: 100 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n##  1          7           3.2          4.7         1.4 versicolor\n##  2          6.4         3.2          4.5         1.5 versicolor\n##  3          6.9         3.1          4.9         1.5 versicolor\n##  4          5.5         2.3          4           1.3 versicolor\n##  5          6.5         2.8          4.6         1.5 versicolor\n##  6          5.7         2.8          4.5         1.3 versicolor\n##  7          6.3         3.3          4.7         1.6 versicolor\n##  8          4.9         2.4          3.3         1   versicolor\n##  9          6.6         2.9          4.6         1.3 versicolor\n## 10          5.2         2.7          3.9         1.4 versicolor\n## # ℹ 90 more rows\n\n\nOn peut également conserver tous les iris à l’exception de l’espèce setosa :\n\n\niris |&gt; filter(Species!=\"setosa\")\n## # A tibble: 100 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n##  1          7           3.2          4.7         1.4 versicolor\n##  2          6.4         3.2          4.5         1.5 versicolor\n##  3          6.9         3.1          4.9         1.5 versicolor\n##  4          5.5         2.3          4           1.3 versicolor\n##  5          6.5         2.8          4.6         1.5 versicolor\n##  6          5.7         2.8          4.5         1.3 versicolor\n##  7          6.3         3.3          4.7         1.6 versicolor\n##  8          4.9         2.4          3.3         1   versicolor\n##  9          6.6         2.9          4.6         1.3 versicolor\n## 10          5.2         2.7          3.9         1.4 versicolor\n## # ℹ 90 more rows\n\nCalculer le nombre d’iris de l’espèce setosa en utilisant summarise.\n\niris |&gt; filter(Species==\"setosa\") |&gt; summarise(nb_setosa=n())\n## # A tibble: 1 × 1\n##   nb_setosa\n##       &lt;int&gt;\n## 1        50\n\nCalculer la moyenne de la variable Petal.Width pour les iris de l’espèce versicolor.\n\niris |&gt; filter(Species==\"versicolor\") |&gt;\n  summarise(Mean_PW=mean(Petal.Width))\n## # A tibble: 1 × 1\n##   Mean_PW\n##     &lt;dbl&gt;\n## 1    1.33\n\nAjouter dans le jeu de données la variable Sum_Petal qui correspond à la somme de Petal.Width et Sepal.Width.\n\niris1 &lt;- iris\niris1 |&gt; mutate(Sum_Petal=Petal.Width+Sepal.Width)\n## # A tibble: 150 × 6\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sum_Petal\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;\n##  1          5.1         3.5          1.4         0.2 setosa        3.7\n##  2          4.9         3            1.4         0.2 setosa        3.2\n##  3          4.7         3.2          1.3         0.2 setosa        3.4\n##  4          4.6         3.1          1.5         0.2 setosa        3.3\n##  5          5           3.6          1.4         0.2 setosa        3.8\n##  6          5.4         3.9          1.7         0.4 setosa        4.3\n##  7          4.6         3.4          1.4         0.3 setosa        3.7\n##  8          5           3.4          1.5         0.2 setosa        3.6\n##  9          4.4         2.9          1.4         0.2 setosa        3.1\n## 10          4.9         3.1          1.5         0.1 setosa        3.2\n## # ℹ 140 more rows\n\nCalculer la moyenne et la variance de la variable Petal.Length pour chaque espèce (on pourra utiliser group_by).\n\niris |&gt; group_by(Species) |&gt;\n  summarise(mean_PL=mean(Petal.Length),var_PL=var(Petal.Length)) |&gt;\n  mutate(var_PL=round(var_PL,3))\n## # A tibble: 3 × 3\n##   Species    mean_PL var_PL\n##   &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n## 1 setosa        1.46  0.03 \n## 2 versicolor    4.26  0.221\n## 3 virginica     5.55  0.305\n\n\n\n\nExercice 3.5 (Traffic aérien aux USA) On considère la table hflights qui contient des informations sur les vols au départ des aéroports Houston airports IAH (George Bush Intercontinental) et HOU (Houston Hobby):\n\nlibrary(hflights)\nhflights &lt;- as_tibble(hflights)\n\nLa variable Unique Carrier renseigne sur la compagnie du vol. On recode cette variable afin que la compagnie soit plus explicite :\n\nlut1 &lt;- c(\"AA\" = \"American\", \"AS\" = \"Alaska\", \"B6\" = \"JetBlue\", \"CO\" = \"Continental\",\n         \"DL\" = \"Delta\", \"OO\" = \"SkyWest\", \"UA\" = \"United\", \"US\" = \"US_Airways\", \n         \"WN\" = \"Southwest\", \"EV\" = \"Atlantic_Southeast\", \"F9\" = \"Frontier\", \n         \"FL\" = \"AirTran\", \"MQ\" = \"American_Eagle\", \"XE\" = \"ExpressJet\", \"YV\" = \"Mesa\")\n\nOn fait de même pour la variable CancellationCode :\n\nlut2 &lt;- c(\"A\" = \"carrier\", \"B\" = \"weather\", \"C\" = \"FFA\", \"D\" = \"security\", \"E\" = \"not cancelled\")\n\nOn effectue maintenant les changements dans la table pour obtenir une nouvelle version de hflights :\n\nhflights1 &lt;- hflights\nhflights1$UniqueCarrier &lt;- lut1[hflights1$UniqueCarrier]\nhflights1$CancellationCode[hflights1$CancellationCode==\"\"] &lt;- \"Z\"\nhflights1$CancellationCode &lt;- lut2[hflights1$CancellationCode]\n\nA partir de maintenant, on travaille avec hflights1.\n\nSélectionner les variables qui se situent entre Origin et Cancelled de différentes façons.\n\nind &lt;- match(c(\"Origin\",\"Cancelled\"),names(hflights1))\nhflights1 |&gt; select(seq(ind[1],ind[2]))\n## # A tibble: 227,496 × 6\n##    Origin Dest  Distance TaxiIn TaxiOut Cancelled\n##    &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;   &lt;int&gt;     &lt;int&gt;\n##  1 IAH    DFW        224      7      13         0\n##  2 IAH    DFW        224      6       9         0\n##  3 IAH    DFW        224      5      17         0\n##  4 IAH    DFW        224      9      22         0\n##  5 IAH    DFW        224      9       9         0\n##  6 IAH    DFW        224      6      13         0\n##  7 IAH    DFW        224     12      15         0\n##  8 IAH    DFW        224      7      12         0\n##  9 IAH    DFW        224      8      22         0\n## 10 IAH    DFW        224      6      19         0\n## # ℹ 227,486 more rows\n#ou\nhflights1 |&gt; select(Origin:Cancelled) \n## # A tibble: 227,496 × 6\n##    Origin Dest  Distance TaxiIn TaxiOut Cancelled\n##    &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;   &lt;int&gt;     &lt;int&gt;\n##  1 IAH    DFW        224      7      13         0\n##  2 IAH    DFW        224      6       9         0\n##  3 IAH    DFW        224      5      17         0\n##  4 IAH    DFW        224      9      22         0\n##  5 IAH    DFW        224      9       9         0\n##  6 IAH    DFW        224      6      13         0\n##  7 IAH    DFW        224     12      15         0\n##  8 IAH    DFW        224      7      12         0\n##  9 IAH    DFW        224      8      22         0\n## 10 IAH    DFW        224      6      19         0\n## # ℹ 227,486 more rows\n\nSélectionner les variables DepTime, ArrTime, ActualElapsedTime, AirTime, ArrDelay et DepDelay. On pourra remarquer que toutes ces variables contiennent les chaînes de caractère Time ou Delay et utiliser la helper function contains().\n\nhflights1 |&gt; select(contains(\"Time\"),contains(\"Delay\"))\n## # A tibble: 227,496 × 6\n##    DepTime ArrTime ActualElapsedTime AirTime ArrDelay DepDelay\n##      &lt;int&gt;   &lt;int&gt;             &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n##  1    1400    1500                60      40      -10        0\n##  2    1401    1501                60      45       -9        1\n##  3    1352    1502                70      48       -8       -8\n##  4    1403    1513                70      39        3        3\n##  5    1405    1507                62      44       -3        5\n##  6    1359    1503                64      45       -7       -1\n##  7    1359    1509                70      43       -1       -1\n##  8    1355    1454                59      40      -16       -5\n##  9    1443    1554                71      41       44       43\n## 10    1443    1553                70      45       43       43\n## # ℹ 227,486 more rows\n#ou\nhflights1 |&gt; select(contains(c(\"Time\",\"Delay\")))\n## # A tibble: 227,496 × 6\n##    DepTime ArrTime ActualElapsedTime AirTime ArrDelay DepDelay\n##      &lt;int&gt;   &lt;int&gt;             &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n##  1    1400    1500                60      40      -10        0\n##  2    1401    1501                60      45       -9        1\n##  3    1352    1502                70      48       -8       -8\n##  4    1403    1513                70      39        3        3\n##  5    1405    1507                62      44       -3        5\n##  6    1359    1503                64      45       -7       -1\n##  7    1359    1509                70      43       -1       -1\n##  8    1355    1454                59      40      -16       -5\n##  9    1443    1554                71      41       44       43\n## 10    1443    1553                70      45       43       43\n## # ℹ 227,486 more rows\n\nAjouter une variable ActualGroundTime qui correspond à ActualElapsedTime moins AirTime.\n\nhflights2 &lt;- hflights1 |&gt; mutate(ActualGroundTime=ActualElapsedTime-AirTime)\nhead(hflights2)\n## # A tibble: 6 × 22\n##    Year Month DayofMonth DayOfWeek DepTime ArrTime UniqueCarrier FlightNum\n##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;chr&gt;             &lt;int&gt;\n## 1  2011     1          1         6    1400    1500 American            428\n## 2  2011     1          2         7    1401    1501 American            428\n## 3  2011     1          3         1    1352    1502 American            428\n## 4  2011     1          4         2    1403    1513 American            428\n## 5  2011     1          5         3    1405    1507 American            428\n## 6  2011     1          6         4    1359    1503 American            428\n## # ℹ 14 more variables: TailNum &lt;chr&gt;, ActualElapsedTime &lt;int&gt;, AirTime &lt;int&gt;,\n## #   ArrDelay &lt;int&gt;, DepDelay &lt;int&gt;, Origin &lt;chr&gt;, Dest &lt;chr&gt;, Distance &lt;int&gt;,\n## #   TaxiIn &lt;int&gt;, TaxiOut &lt;int&gt;, Cancelled &lt;int&gt;, CancellationCode &lt;chr&gt;,\n## #   Diverted &lt;int&gt;, ActualGroundTime &lt;int&gt;\n\nAjouter la variable AverageSpeed (=Distance/AirTime) et ordonner la table selon les valeurs décroissantes de cette variable.\n\nhflights3 &lt;- hflights2 |&gt; \n  mutate(AverageSpeed=Distance/AirTime) |&gt;\n  arrange(desc(AverageSpeed))\n\nSélectionner les vols à destination de JFK.\n\nfilter(hflights3,Dest==\"JFK\")\n## # A tibble: 695 × 23\n##     Year Month DayofMonth DayOfWeek DepTime ArrTime UniqueCarrier FlightNum\n##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;chr&gt;             &lt;int&gt;\n##  1  2011     2          7         1     659    1045 JetBlue             620\n##  2  2011     2          6         7     700    1045 JetBlue             620\n##  3  2011     2          5         6     700    1113 JetBlue             620\n##  4  2011     2          6         7    1529    1917 JetBlue             624\n##  5  2011     1         24         1     707    1059 JetBlue             620\n##  6  2011     1         24         1    1532    1923 JetBlue             624\n##  7  2011     2         12         6     659    1105 JetBlue             620\n##  8  2011    10         19         3     644    1043 JetBlue             620\n##  9  2011    11         10         4    1629    2027 JetBlue             622\n## 10  2011     2          8         2     654    1049 JetBlue             620\n## # ℹ 685 more rows\n## # ℹ 15 more variables: TailNum &lt;chr&gt;, ActualElapsedTime &lt;int&gt;, AirTime &lt;int&gt;,\n## #   ArrDelay &lt;int&gt;, DepDelay &lt;int&gt;, Origin &lt;chr&gt;, Dest &lt;chr&gt;, Distance &lt;int&gt;,\n## #   TaxiIn &lt;int&gt;, TaxiOut &lt;int&gt;, Cancelled &lt;int&gt;, CancellationCode &lt;chr&gt;,\n## #   Diverted &lt;int&gt;, ActualGroundTime &lt;int&gt;, AverageSpeed &lt;dbl&gt;\n\nCalculer le nombre de vols à destination de JFK.\n\nhflights3 |&gt; filter(Dest==\"JFK\") |&gt; summarise(numb_to_JFK=n())\n## # A tibble: 1 × 1\n##   numb_to_JFK\n##         &lt;int&gt;\n## 1         695\n\nCréer un résumé de hflights1 qui contient :\n\nn_flights : le nombre total de vols ;\nn_dest: le nombre total de destinations ;\nn_carrier : le nombre total de compagnies.\n\nOn pourra utiliser n_distinct pour les deux derniers résumés statistiques.\n\nhflights1 |&gt; summarize(n_flights=n(),\n                       n_dest=n_distinct(Dest),\n                       n_carrier=n_distinct(UniqueCarrier))\n## # A tibble: 1 × 3\n##   n_flights n_dest n_carrier\n##       &lt;int&gt;  &lt;int&gt;     &lt;int&gt;\n## 1    227496    116        15\n\nCréer un résumé de hflights1 qui contient, pour les vols de la compagnie American,\n\nle nombre total de vols ;\nle nombre total de vols annulés ;\nla valeur moyenne de ArrDelay (attention à la gestion des NA…).\n\n\nhflights1 |&gt; filter(UniqueCarrier==\"American\") |&gt; \n  summarize(n_fligths_Am=n(),\n            n_can_Am=sum(Cancelled),\n            mean_ArrDelay_am=mean(ArrDelay,na.rm=TRUE))\n## # A tibble: 1 × 3\n##   n_fligths_Am n_can_Am mean_ArrDelay_am\n##          &lt;int&gt;    &lt;int&gt;            &lt;dbl&gt;\n## 1         3244       60            0.892\n\nCalculer pour chaque compagnie :\n\nle nombre total de vols ;\nLa valeur moyenne de AirTime.\n\n\nhflights1 |&gt; group_by(UniqueCarrier) |&gt;\n  summarise(n_flights=n(),\n            mean_AirTime=mean(AirTime,na.rm=TRUE))\n## # A tibble: 15 × 3\n##    UniqueCarrier      n_flights mean_AirTime\n##    &lt;chr&gt;                  &lt;int&gt;        &lt;dbl&gt;\n##  1 AirTran                 2139         92.7\n##  2 Alaska                   365        254. \n##  3 American                3244         69.7\n##  4 American_Eagle          4648         93.8\n##  5 Atlantic_Southeast      2204        104. \n##  6 Continental            70032        145. \n##  7 Delta                   2641         97.8\n##  8 ExpressJet             73053         83.2\n##  9 Frontier                 838        125. \n## 10 JetBlue                  695        184. \n## 11 Mesa                      79        122. \n## 12 SkyWest                16061        113. \n## 13 Southwest              45343         86.7\n## 14 US_Airways              4082        134. \n## 15 United                  2072        157.\n\nOrdonner les compagnies en fonction des retards moyens au départ.\n\nhflights1 |&gt; \n  group_by(UniqueCarrier) |&gt;\n  filter(!is.na(DepDelay) & DepDelay&gt;0) |&gt;\n  summarise(meanDepDelay = mean(DepDelay)) |&gt;\n  arrange(meanDepDelay)\n## # A tibble: 15 × 2\n##    UniqueCarrier      meanDepDelay\n##    &lt;chr&gt;                     &lt;dbl&gt;\n##  1 Continental                17.9\n##  2 Alaska                     20.8\n##  3 Southwest                  21.9\n##  4 Frontier                   22.7\n##  5 Mesa                       24.5\n##  6 SkyWest                    24.6\n##  7 American                   24.7\n##  8 US_Airways                 26.5\n##  9 ExpressJet                 26.9\n## 10 United                     28.8\n## 11 Delta                      32.4\n## 12 AirTran                    33.4\n## 13 American_Eagle             37.9\n## 14 JetBlue                    43.5\n## 15 Atlantic_Southeast         49.3\n\n\n\n\nExercice 3.6 (Tournois du grand chelem au tennis) On considère le données sur les résultats de tennis dans les tournois du grand chelem en 2013. Les données, ainsi que le descriptif des variables, se trouvent à l’adresse https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics.\nOn s’intéresse d’abord au tournoi masculin de Roland Garros. On répondra aux questions à l’aide des verbes dplyr.\n\nImporter les données.\n\nFrenchOpen_men_2013 &lt;- read_csv(\"data/FrenchOpen-men-2013.csv\")\nRG2013 &lt;- FrenchOpen_men_2013\nRG2013\n## # A tibble: 125 × 42\n##    Player1  Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1 ACE.1 DBF.1\n##    &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n##  1 Pablo C… Roger …     1      0     0     3    62    27    38    11     1     3\n##  2 Somdev … Daniel…     1      1     3     0    62    54    38    22     7     3\n##  3 Tobias … Paolo …     1      1     3     2    62    53    38    15     4     6\n##  4 Julien … Ricard…     1      1     3     1    72    87    28    19    14     2\n##  5 Lukas L… Sam Qu…     1      0     0     3    52    31    48    22     4     4\n##  6 Jan Haj… Denis …     1      1     3     1    70    58    30    18     4     4\n##  7 Adrian … Pablo …     1      0     2     3    63    71    37    38     5     5\n##  8 Gilles … Lleyto…     1      1     3     2    59    42    41    25     7     2\n##  9 Philipp… Marin …     1      0     0     3    56    27    44    13     0     6\n## 10 Radek S… Nick K…     1      0     0     3    63    62    37    29     5     4\n## # ℹ 115 more rows\n## # ℹ 30 more variables: WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;, BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;,\n## #   NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;, ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;,\n## #   ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;, FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;,\n## #   SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;, DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;,\n## #   UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;, NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;,\n## #   TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;, ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, …\n\nAfficher le nom des adversaires de Roger Federer.\n\nRG2013 |&gt; filter(Player1==\"Roger Federer\" | Player2==\"Roger Federer\") |&gt;\n  select(Player1,Player2)\n## # A tibble: 5 × 2\n##   Player1             Player2      \n##   &lt;chr&gt;               &lt;chr&gt;        \n## 1 Pablo Carreno-Busta Roger Federer\n## 2 Somdev Devvarman    Roger Federer\n## 3 Julien Benneteau    Roger Federer\n## 4 Gilles Simon        Roger Federer\n## 5 Jo-Wilfried Tsonga  Roger Federer\n\nAfficher le nom des demi-finalistes (ceux qui ont atteint le 6ème tour).\n\nRG2013 |&gt; filter(Round==6) |&gt; select(Player1,Player2)\n## # A tibble: 2 × 2\n##   Player1        Player2           \n##   &lt;chr&gt;          &lt;chr&gt;             \n## 1 David Ferrer   Jo-Wilfried Tsonga\n## 2 Novak Djokovic Rafael Nadal\n\nCombien y a t-il eu de points disputés en moyenne par match ? Il faudra penser à ajouter dans la table une variable correspondant au nombre de points de chaque match (verbe mutate).\n\nRG2013 |&gt; mutate(nb_points=TPW.1+TPW.2) |&gt; select(nb_points) |&gt; summarize_all(mean)\n## # A tibble: 1 × 1\n##   nb_points\n##       &lt;dbl&gt;\n## 1      219.\n\nCombien y a t-il eu d’aces par match en moyenne ?\n\nRG2013 |&gt; mutate(nb_aces=ACE.1+ACE.2) |&gt; summarize(mean_aces=mean(nb_aces))\n## # A tibble: 1 × 1\n##   mean_aces\n##       &lt;dbl&gt;\n## 1      12.7\n\nCombien y a t-il eu d’aces par match en moyenne à chaque tour ?\n\nRG2013 |&gt; group_by(Round) |&gt; mutate(nb_aces=ACE.1+ACE.2) |&gt;\n  summarize(mean_aces=mean(nb_aces))\n## # A tibble: 7 × 2\n##   Round mean_aces\n##   &lt;dbl&gt;     &lt;dbl&gt;\n## 1     1     13.5 \n## 2     2     13.2 \n## 3     3     12.6 \n## 4     4      9.12\n## 5     5      7   \n## 6     6     10   \n## 7     7      6\n\nCombien y a t-il eu de doubles fautes au total dans le tournoi (attention aux données manquantes, taper help(sum) pour voir comment les gérer) ?\n\nRG2013 |&gt; mutate(nb_df=DBF.1+DBF.2) |&gt; \n  summarize(nb_dbfaults=sum(nb_df,na.rm=TRUE))\n## # A tibble: 1 × 1\n##   nb_dbfaults\n##         &lt;dbl&gt;\n## 1         812\n\nImporter les données pour le tournoi masculin de Wimbledon 2013.\n\nWIMB2013 &lt;- read_csv(\"data/Wimbledon-men-2013.csv\")\nWIMB2013\n## # A tibble: 114 × 42\n##    Player1  Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1 ACE.1 DBF.1\n##    &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n##  1 B.Becker A.Murr…     1      0     0     3    59    29    41    14     5     1\n##  2 J.Ward   Y-H.Lu      1      0     1     3    62    77    38    35    18     4\n##  3 N.Mahut  J.Hajek     1      1     3     0    72    44    28    10    17     3\n##  4 T.Robre… A.Bogo…     1      1     3     0    77    40    23    12     6     0\n##  5 R.Haase  M.Youz…     1      0     0     3    68    61    32    15     7     2\n##  6 M.Gicqu… V.Posp…     1      0     0     3    59    41    41    27     7     6\n##  7 A.Kuzne… A.Mont…     1      1     3     1    63    56    37    21    21     3\n##  8 J.Tipsa… V.Troi…     1      0     0     3    61    47    39    21     3     1\n##  9 M.Baghd… M.Cilic     1      0     0     3    61    31    39    16     4     5\n## 10 K.De Sc… P.Lore…     1      1     3     0    67    56    33    21    22     6\n## # ℹ 104 more rows\n## # ℹ 30 more variables: WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;, BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;,\n## #   NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;lgl&gt;, ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;,\n## #   ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;, FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;,\n## #   SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;, DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;,\n## #   UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;, NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;,\n## #   TPW.2 &lt;lgl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;, ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, …\n\nConcaténer les tables en ajoutant une variable permettant d’identifier le tournoi. On pourra utiliser bind_rows abev l’option .id.\n\nRG_WIMB2013 &lt;- bind_rows(\"RG\"=RG2013,\"WIMB\"=WIMB2013,.id=\"Tournament\")\n\nAfficher les matchs de Federer pour chaque tournoi.\n\nRG_WIMB2013  |&gt; filter(Player1==\"Roger Federer\" | \n                      Player2==\"Roger Federer\" |\n                      Player1==\"R.Federer\" | \n                      Player2==\"R.Federer\") \n## # A tibble: 7 × 43\n##   Tournament Player1    Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1\n##   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 RG         Pablo Car… Roger …     1      0     0     3    62    27    38    11\n## 2 RG         Somdev De… Roger …     2      0     0     3    61    19    39    16\n## 3 RG         Julien Be… Roger …     3      0     0     3    82    41    18     8\n## 4 RG         Gilles Si… Roger …     4      0     2     3    61    65    39    28\n## 5 RG         Jo-Wilfri… Roger …     5      1     3     0    75    46    25    10\n## 6 WIMB       V.Hanescu  R.Fede…     1      0     0     3    85    26    15     3\n## 7 WIMB       S.Stakhov… R.Fede…     2      1     3     1    66    83    34    36\n## # ℹ 32 more variables: ACE.1 &lt;dbl&gt;, DBF.1 &lt;dbl&gt;, WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;,\n## #   BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;, NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;,\n## #   ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;, ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;,\n## #   FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;, SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;,\n## #   DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;, UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;,\n## #   NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;, TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;,\n## #   ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, ST5.2 &lt;dbl&gt;\n\nou\n\nRG_WIMB2013  |&gt; filter(grepl(\"Federer\",Player2) | grepl(\"Federer\",Player2))\n## # A tibble: 7 × 43\n##   Tournament Player1    Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1\n##   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 RG         Pablo Car… Roger …     1      0     0     3    62    27    38    11\n## 2 RG         Somdev De… Roger …     2      0     0     3    61    19    39    16\n## 3 RG         Julien Be… Roger …     3      0     0     3    82    41    18     8\n## 4 RG         Gilles Si… Roger …     4      0     2     3    61    65    39    28\n## 5 RG         Jo-Wilfri… Roger …     5      1     3     0    75    46    25    10\n## 6 WIMB       V.Hanescu  R.Fede…     1      0     0     3    85    26    15     3\n## 7 WIMB       S.Stakhov… R.Fede…     2      1     3     1    66    83    34    36\n## # ℹ 32 more variables: ACE.1 &lt;dbl&gt;, DBF.1 &lt;dbl&gt;, WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;,\n## #   BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;, NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;,\n## #   ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;, ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;,\n## #   FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;, SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;,\n## #   DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;, UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;,\n## #   NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;, TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;,\n## #   ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, ST5.2 &lt;dbl&gt;\n\nComparer les nombres d’aces par matchs à chaque tour pour les tournois de Roland Garros et Wimbledon.\n\nRG_WIMB2013 |&gt; group_by(Tournament,Round) |&gt; \n  mutate(nb_aces=ACE.1+ACE.2) |&gt; summarize(mean_ace=mean(nb_aces))\n## # A tibble: 14 × 3\n## # Groups:   Tournament [2]\n##    Tournament Round mean_ace\n##    &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n##  1 RG             1    13.5 \n##  2 RG             2    13.2 \n##  3 RG             3    12.6 \n##  4 RG             4     9.12\n##  5 RG             5     7   \n##  6 RG             6    10   \n##  7 RG             7     6   \n##  8 WIMB           1    21.1 \n##  9 WIMB           2    23.9 \n## 10 WIMB           3    24   \n## 11 WIMB           4    24.4 \n## 12 WIMB           5    26.5 \n## 13 WIMB           6    27.5 \n## 14 WIMB           7    13\n\nou pour une présentation plus synthétique\n\nRG_WIMB2013 |&gt; group_by(Tournament,Round) |&gt; \n  mutate(nb_aces=ACE.1+ACE.2) |&gt; \n  summarize(mean_ace=mean(nb_aces)) |&gt;\n  pivot_wider(names_from = \"Round\",values_from = \"mean_ace\")\n## # A tibble: 2 × 8\n## # Groups:   Tournament [2]\n##   Tournament   `1`   `2`   `3`   `4`   `5`   `6`   `7`\n##   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 RG          13.5  13.2  12.6  9.12   7    10       6\n## 2 WIMB        21.1  23.9  24   24.4   26.5  27.5    13\n\n\n\n\n\n3.2.5 Compléments : Tidy data avec tidyr\nL’utilisation de dplyr et de ggplot (que nous verrons dans la partie suivante) suppose que les données sont présentées sous un format adéquat : une ligne est un individu et une colonne une variable, on parle alors de tidy data. Cette représentation peut dépendre du contexte, et surtout de ce que l’on souhaite faire avec les données. Considérons par exemple le tableau suivant qui présente les taux de chômage des départements français en 2002, 2006, 2011\n\ndf &lt;- read_delim(\"data/tauxchomage.csv\",delim=\";\") |&gt; select(-1)\ndf\n## # A tibble: 96 × 4\n##    NOM_DPT                 TCHOMB1T01 TCHOMB1T06 TCHOMB1T11\n##    &lt;chr&gt;                        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n##  1 Ain                            3.9        5.9        6.6\n##  2 Aisne                         10.6       12         13.2\n##  3 Allier                         9          9.2        9.7\n##  4 Alpes-de-Haute-Provence        9.5        9.7       10.3\n##  5 Hautes-Alpes                   7.1        7.7        8.3\n##  6 Alpes-Maritimes                9.1        8.9        9.2\n##  7 Ardèche                        8.1        9.6        9.7\n##  8 Ardennes                      11.5       12.8       10.9\n##  9 Ariège                         9.2       10.1       10.6\n## 10 Aube                           8.2       10         10  \n## # ℹ 86 more rows\n\nPrésenté ainsi ce tableau comporte 4 variables (en comptant l’identifiant du département). Dans certaines situations, on peut préférer une structure à 3 variables :\n\nle département\nl’année\nle taux de chômage\n\nNous verrons qu’il n’est par exemple pas possible de faire un boxplot permettant de visualiser la distribution du taux de chômage en fonction de l’année à l’aide de ggplot2. Pour passer à ce format il est nécessaire d’assembler les 3 colonnes correspondant aux taux de chômage en une seule colonne et ajouter une colonne qui permette d’identifier l’année. La table obtenue aura plus de lignes, on parle de format long. La fonction pivot_longer du package tidyr permet de faire cette transformation :\n\ndf1 &lt;- df |&gt; pivot_longer(-NOM_DPT,names_to=\"Année\",values_to=\"TCHOM\") |&gt; \n  mutate(Année=fct_recode(Année,\"2001\"=\"TCHOMB1T01\",\"2006\"=\"TCHOMB1T06\",\"2011\"=\"TCHOMB1T11\"))\ndf1\n## # A tibble: 288 × 3\n##    NOM_DPT                 Année TCHOM\n##    &lt;chr&gt;                   &lt;fct&gt; &lt;dbl&gt;\n##  1 Ain                     2001    3.9\n##  2 Ain                     2006    5.9\n##  3 Ain                     2011    6.6\n##  4 Aisne                   2001   10.6\n##  5 Aisne                   2006   12  \n##  6 Aisne                   2011   13.2\n##  7 Allier                  2001    9  \n##  8 Allier                  2006    9.2\n##  9 Allier                  2011    9.7\n## 10 Alpes-de-Haute-Provence 2001    9.5\n## # ℹ 278 more rows\n\nIl sera alors aisé de faire le boxplot souhaité avec\n\nggplot(df1)+aes(x=Année,y=TCHOM)+geom_boxplot()\n\n\n\n\nL’opération inverse peut être effectuée avec pivot_wider :\n\ndf1 |&gt; pivot_wider(names_from=\"Année\",values_from=\"TCHOM\")\n## # A tibble: 96 × 4\n##    NOM_DPT                 `2001` `2006` `2011`\n##    &lt;chr&gt;                    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n##  1 Ain                        3.9    5.9    6.6\n##  2 Aisne                     10.6   12     13.2\n##  3 Allier                     9      9.2    9.7\n##  4 Alpes-de-Haute-Provence    9.5    9.7   10.3\n##  5 Hautes-Alpes               7.1    7.7    8.3\n##  6 Alpes-Maritimes            9.1    8.9    9.2\n##  7 Ardèche                    8.1    9.6    9.7\n##  8 Ardennes                  11.5   12.8   10.9\n##  9 Ariège                     9.2   10.1   10.6\n## 10 Aube                       8.2   10     10  \n## # ℹ 86 more rows\n\nLe package tidyr possède plusieurs autres verbes qui pourront aider l’utilisateur à mettre la table sous le meilleur format pour les analyses. Citons par exemple le verbe separate qui va séparer une colonne en plusieurs :\n\n(df &lt;- tibble(date=as.Date(c(\"01/03/2015\",\"05/18/2017\",\n                             \"09/14/2018\"),\"%m/%d/%Y\"),\n              temp=c(18,21,15)))\n## # A tibble: 3 × 2\n##   date        temp\n##   &lt;date&gt;     &lt;dbl&gt;\n## 1 2015-01-03    18\n## 2 2017-05-18    21\n## 3 2018-09-14    15\n (df1 &lt;- df |&gt; separate_wider_delim(date,delim=\"-\",\n                                       names=c(\"year\",\"month\",\"day\")))\n## # A tibble: 3 × 4\n##   year  month day    temp\n##   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n## 1 2015  01    03       18\n## 2 2017  05    18       21\n## 3 2018  09    14       15\n\nou le verbe unite qui fera l’opération inverse\n\ndf1 |&gt; \n  unite(date,year,month,day,sep=\"/\") |&gt;\n  mutate(date1=lubridate::as_date(date))\n## # A tibble: 3 × 3\n##   date        temp date1     \n##   &lt;chr&gt;      &lt;dbl&gt; &lt;date&gt;    \n## 1 2015/01/03    18 2015-01-03\n## 2 2017/05/18    21 2017-05-18\n## 3 2018/09/14    15 2018-09-14\n\nCitons enfin les verbes :\n\nseparate_longer_delim qui permettra de séparer des informations en plusieurs lignes ;\nseparate_wider_regex pour créer de nouvelles colonnes ;\ncomplete pour ajouter des lignes dans un tableau, par exemple des non réponses à un questionnaire."
  },
  {
    "objectID": "031-programmer.html#structures-de-contrôle",
    "href": "031-programmer.html#structures-de-contrôle",
    "title": "4  Programmer",
    "section": "4.1 Structures de contrôle",
    "text": "4.1 Structures de contrôle\nOn énumère les principales structures :\n\nBoucles for :\n\nfor (i in vecteur){\n  expr1\n  expr2\n  ...\n}\n\nPar exemple\n\nfor (i in 1:3){print(i)}\n## [1] 1\n## [1] 2\n## [1] 3\nfor (i in c(\"lundi\",\"mardi\",\"mercredi\")){print(i)}\n## [1] \"lundi\"\n## [1] \"mardi\"\n## [1] \"mercredi\"\n\nCondition while\n\nwhile (condition) {expression}\n\nPar exemple :\n\ni &lt;- 1\nwhile (i&lt;=3) {\n  print(i)\n  i &lt;- i+1\n}\n## [1] 1\n## [1] 2\n## [1] 3\n\nCondition if else\n\nif (condition){\n  expr1\n  ...\n} else {\n  expre2\n  ...\n}\n\nPar exemple :\n\na &lt;- -2\nif (a&gt;0){\n  a &lt;- a+1\n} else {\n  a &lt;- a-1\n}\nprint(a)\n## [1] -3\n\nswitch\n\nswitch(expression,\n       \"cond1\" = action1,\n       \"cond2\" = action2,\n       ...)\n\nPar exemple :\n\nX &lt;- matrix(0,nrow = 5,ncol = 5)\nswitch(class(X)[1],\n       \"matrix\"=print(\"X est une matrice\"),\n       \"data.frame\"=print(\"X est un data.frame\"),\n       \"numeric\"=print(\"X est de classe numérique\"))\n## [1] \"X est une matrice\""
  },
  {
    "objectID": "031-programmer.html#écrire-une-fonction",
    "href": "031-programmer.html#écrire-une-fonction",
    "title": "4  Programmer",
    "section": "4.2 Écrire une fonction",
    "text": "4.2 Écrire une fonction\nOn peut définir sa propre fonction dans un objet avec function :\n\nmafonct &lt;- function(param1,param2,...){\n  expr1\n  expr2\n  return(...)\n  }\n\nConstruisons par exemple la fonction factorielle qui calcule la factorielle d’un entier n :\n\nfactorielle &lt;- function(n){\n  return(prod(1:n))\n  }\n\nOn peut la tester\n\nfactorielle(5)\n## [1] 120\n\nOn propose d’améliorer cette fonction en spécifiant des messages d’erreur ou d’alerte :\n\nfactorielle &lt;- function(n){\n  if (n&lt;=0) stop(\"l'entier doit être strictement positif\")\n  if (ceiling(n)!=n) warning(paste(\"arrondi de\",n,\"en\",ceiling(n)))\n  return(prod(1:ceiling(n)))\n  }\n\nOn a alors un message d’erreur lorsque le paramètre est négatif\n\nfactorielle(-2)\n## Error in factorielle(-2): l'entier doit être strictement positif\n\nou un avertissement si ce n’est pas un entier\n\nfactorielle(2.8)\n## Warning in factorielle(2.8): arrondi de 2.8 en 3\n## [1] 6"
  },
  {
    "objectID": "031-programmer.html#les-fonctions-map",
    "href": "031-programmer.html#les-fonctions-map",
    "title": "4  Programmer",
    "section": "4.3 Les fonctions map",
    "text": "4.3 Les fonctions map\nCes fonctions appartiennent au package purrr du tidyverse. Elles permettent d’appliquer des fonctions à des listes et donc à des tibbles. On peut les voir comme des versions améliorées des fonctions apply. On peut par exemple retrouver les sorties de\n\napply(iris[,-5],2,mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\navec\n\nmap(iris[,-5],mean)\n## $Sepal.Length\n## [1] 5.843333\n## \n## $Sepal.Width\n## [1] 3.057333\n## \n## $Petal.Length\n## [1] 3.758\n## \n## $Petal.Width\n## [1] 1.199333\n\nou encore\n\nmap_dbl(iris[,-5],mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\nqui renvoie un vecteur de classe numeric plutôt qu’une liste. On peut citer également les fonctions map_lgl, map_chr, map_dbl qui retournent des vecteurs de logiques, de caractères ou d’entiers.\nDans le même style, on dispose des fonctions map2_... pour appliquer des fonctions à des paires d’éléments de listes. On peut par exemple sommer les élément de deux listes avec\n\nl1 &lt;- list(1,2,3)\nl2 &lt;- list(4,5,6)\nmap2(l1,l2,`+`)\n## [[1]]\n## [1] 5\n## \n## [[2]]\n## [1] 7\n## \n## [[3]]\n## [1] 9\n#ou pour obtenir un vecteur\nmap2_dbl(l1,l2,`+`)\n## [1] 5 7 9\n\nIl est également possible de spécifier explicitement sa propre fonction lorsqu’elle n’existe pas\n\nset.seed(123)\ntbl1 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\ntbl2 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\nmap2_dbl(tbl1,tbl2,function(d1,d2) mean(rbind(d1,d2)))\n##       age    taille \n##  38.21492 164.83358\n\nLa syntaxe peut paraître un peu lourde, avec notamment l’utilisation de function. On utilise régulièrement des fonctions anonymes qui peuvent se définir à l’aide d’une formule :\n\nmap2_dbl(tbl1,tbl2,~mean(rbind(.x,.y)))\n##       age    taille \n##  38.21492 164.83358\n\nou en spécifiant explicitement les arguments\n\nmap2_dbl(tbl1,tbl2,\\(d1,d2) mean(rbind(d1,d2)))\n##       age    taille \n##  38.21492 164.83358\n\nNotons enfin que l’utilisation des fonctions anonymes diffèrent lorsqu’on chaîne les opérations avec le pipe de la distribution de R de base |&gt; ou avec celui de dplyr %&gt;% :\n\nset.seed(123)\nX1 &lt;- rnorm(100)\nc(0.25,0.5,0.75) %&gt;% quantile(X1,probs = .)\n##         25%         50%         75% \n## -0.49385424  0.06175631  0.69181917\nc(0.25,0.5,0.75) |&gt; quantile(X1,probs = .)\n## Error in if (na.rm) x &lt;- x[!is.na(x)] else if (anyNA(x)) stop(\"missing values and NaN's not allowed if 'na.rm' is FALSE\"): the condition has length &gt; 1\n\nLe . permet d’indiquer la place de la quantité à gauche du pipe %&gt;%. Lorsqu’on utilise |&gt;, il faut utiliser une fonction anonyme :\n\nc(0.25,0.5,0.75) |&gt; (\\(p) quantile(X1,probs = p))()\n##         25%         50%         75% \n## -0.49385424  0.06175631  0.69181917"
  },
  {
    "objectID": "031-programmer.html#exercices",
    "href": "031-programmer.html#exercices",
    "title": "4  Programmer",
    "section": "4.4 Exercices",
    "text": "4.4 Exercices\n\nExercice 4.1 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui admet en entrée un entier positif n et qui renvoie la somme des entiers qui vont de 1 à n.\n\nmasomme &lt;- function(n){\n  sum(1:n)\n}\nmasomme(5)\n## [1] 15\n\nÉcrire une fonction qui remplace les données manquantes d’un jeu de données par la moyenne ou la médiane de la variable. Choisir la moyenne ou la médiane doit être un paramètre de la fonction. On pourra tester la fonction sur le tibble suivant :\n\nset.seed(123)\ntbl &lt;- tibble(X1=as.numeric(sample(10,5)),X2=as.numeric(sample(10,5)))\ntbl[3,1] &lt;- NA;tbl[4,2] &lt;- NA\ntbl\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     3     5\n## 2    10     4\n## 3    NA     6\n## 4     8    NA\n## 5     6     1\n\n\nimputation &lt;- function(tbl,choix=\"moyenne\"){\n  if (choix==\"moyenne\"){\n    moy &lt;- map_dbl(tbl,\\(x) mean(x,na.rm = TRUE)) |&gt; as.numeric()\n    for (i in 1:ncol(tbl)){\n      tbl[is.na(tbl[,i]),i] &lt;- as.numeric(moy[i])\n      }\n    } else {\n      med &lt;- map_dbl(tbl,\\(x) median(x,na.rm = TRUE)) |&gt; as.numeric()\n      for (i in 1:ncol(tbl)){\n        tbl[is.na(tbl[,i]),i] &lt;- med[i]\n      }\n    }\n  return(tbl)\n}\nimputation(tbl)\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  3        5\n## 2 10        4\n## 3  6.75     6\n## 4  8        4\n## 5  6        1\nimputation(tbl,choix=\"mediane\")\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     3   5  \n## 2    10   4  \n## 3     7   6  \n## 4     8   4.5\n## 5     6   1\n\n\nOn peut également utiliser la fonction replace_na de tidyr :\n\n\nimputation1 &lt;- function(tbl,choix=\"moyenne\"){\n  if (choix==\"moyenne\"){\n    moy &lt;- map_dfc(tbl,\\(x) mean(x,na.rm = TRUE)) \n    tbl1 &lt;- map2_df(tbl,moy,\\(x,y) replace_na(x,y))\n    } else {\n      med &lt;- map_dfc(tbl,\\(x) median(x,na.rm = TRUE))\n      tbl1 &lt;- map2_df(tbl,med,\\(x,y) replace_na(x,y))\n    }\n  return(tbl1)\n}\nimputation1(tbl)\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  3        5\n## 2 10        4\n## 3  6.75     6\n## 4  8        4\n## 5  6        1\nimputation1(tbl,choix=\"mediane\")\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     3   5  \n## 2    10   4  \n## 3     7   6  \n## 4     8   4.5\n## 5     6   1\n\n\n\n\nExercice 4.2 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui calcule la moyenne et la variance des colonnes d’un jeu de données qui ne contient que des variables continues. On utilisera une boucle for et on testera la fonction sur les 4 premières colonnes des données iris.\n\nmoy_var &lt;- function(tbl){\n  p &lt;- ncol(tbl)\n  moyenne &lt;- rep(0,p)\n  variance &lt;- rep(0,p)\n  for (i in 1:ncol(tbl)){\n    moyenne[i] &lt;- mean(tbl[,i])\n    variance[i] &lt;- var(tbl[,i])\n  }\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n## $moy\n## [1] 5.843333 3.057333 3.758000 1.199333\n## \n## $var\n## [1] 0.6856935 0.1899794 3.1162779 0.5810063\n\nMême question en utilisant la fonction apply.\n\nmoy_var &lt;- function(tbl){\n  moyenne &lt;- apply(tbl,2,mean)\n  variance &lt;- apply(tbl,2,var)\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n## $moy\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333 \n## \n## $var\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##    0.6856935    0.1899794    3.1162779    0.5810063\n\nMême question en utilisant une fonction map_....\n\nmoy_var &lt;- function(tbl){\n  moyenne &lt;- map_dbl(tbl,mean)\n  variance &lt;- map_dbl(tbl,var)\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n## $moy\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333 \n## \n## $var\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##    0.6856935    0.1899794    3.1162779    0.5810063\n\n\nou encore\n\n\nmoy_var &lt;- function(tbl){\n  map(tbl,\\(x) c(moy=mean(x),var=var(x))) |&gt; as_tibble()\n}\nmoy_var(iris[,1:4])\n## # A tibble: 2 × 4\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width\n##          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n## 1        5.84        3.06          3.76       1.20 \n## 2        0.686       0.190         3.12       0.581\n\nUtiliser la méthode de votre choix pour un tibble qui peut comporter des variables qualitatives. La fonction renverra un warning qui liste les variables qualitatives.\n\nmoy_var &lt;- function(tbl){\n  nature &lt;- map_chr(tbl,class)\n  if (any(nature!=\"numeric\")){\n    warning(paste(\"Variable(s)\",names(tbl)[nature!=\"numeric\"],\"non continue(s)\"))\n  }\n  res &lt;- map(tbl[,nature==\"numeric\"],\\(x) c(moy=mean(x),var=var(x))) |&gt;\n    as_tibble()\n  return(res)\n}\nmoy_var(iris)\n## Warning in moy_var(iris): Variable(s) Species non continue(s)\n## # A tibble: 2 × 4\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width\n##          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n## 1        5.84        3.06          3.76       1.20 \n## 2        0.686       0.190         3.12       0.581"
  },
  {
    "objectID": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "href": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.1 Fonctions graphiques conventionnelles",
    "text": "5.1 Fonctions graphiques conventionnelles\nPour commencer il est intéressant d’examiner quelques exemples de représentations graphiques construits avec R. On peut les obtenir à l’aide de la fonction demo.\n\ndemo(graphics)\n\n\n5.1.1 La fonction plot\nC’est une fonction générique que l’on peut utiliser pour représenter différents types de données. L’utilisation standard consiste à visualiser une variable y en fonction d’une variable x. On peut par exemple obtenir le graphe de la fonction \\(x\\mapsto \\sin(2\\pi x)\\) sur \\([0,1]\\), à l’aide de\n\nx &lt;- seq(-2*pi,2*pi,by=0.05)\ny &lt;- sin(x)\nplot(x,y) #points (par défaut)\n\n\n\nplot(x,y,type=\"l\") #représentation sous forme de ligne\n\n\n\n\nNous proposons des exemples de représentations de variables quantitatives et qualitatives à travers du jeu de données ozone.txt que l’on importe avec\n\nozone &lt;- read.table(\"data/ozone.txt\")\nsummary(ozone)\n##      maxO3              T9             T12             T15       \n##  Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n##  1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n##  Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n##  Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n##  3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n##  Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n##       Ne9             Ne12            Ne15           Vx9         \n##  Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n##  1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n##  Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n##  Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n##  3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n##  Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n##       Vx12             Vx15            maxO3v           vent          \n##  Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n##  1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n##  Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n##  Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n##  3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n##  Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n##     pluie          \n##  Length:112        \n##  Class :character  \n##  Mode  :character  \n##                    \n##                    \n## \n\nOn visualise tout d’abord 2 variables quantitatives à l’aide d’un nuage de points : la concentration en ozone maximale maxO3 en fonction de la température à 12h T12.\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"])\n\n\n\n\nComme les deux variables appartiennent au même jeu de données, on peut obtenir la même représentation à l’aide d’une sytaxe plus claire qui ajoute automatiquement les noms des variables sur les axes :\n\nplot(maxO3~T12,data=ozone)\n\n\n\n\nUne autre façon de faire (moins naturelle) :\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"],xlab=\"T12\",ylab=\"maxO3\")\n\n\n\n\nIl existe des fonctions spécifiques pour chaque type de graphes, par exemple histogram, barplot et boxplot :\n\nhist(ozone$maxO3,main=\"Histogram\")\n\n\n\nbarplot(table(ozone$vent)/nrow(ozone),col=\"blue\")\n\n\n\nboxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n5.1.2 Graphes interactifs avec rAmCharts\nOn peut utiliser ce package pour obtenir des graphes dynamiques. L’utilisation est relativement simple, il suffit d’ajouter le préfixe am devant le nom de la fonction :\n\nlibrary(rAmCharts)\namHist(ozone$maxO3)\n\n\n\n\namPlot(ozone,col=c(\"T9\",\"T12\"))\n\n\n\n\namBoxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n\n5.1.3 Quelques exercices\n\nExercice 5.1 (Premier graphe) On s’intéresse à quelques graphes simples.\n\nTracer la fonction sinus entre \\(0\\) et \\(2\\pi\\).\n\nx &lt;- seq(0,2*pi,length=1000)\nplot(x,sin(x),type=\"l\")\n\n\n\n\nA l’aide de la fonction title ajouter le titre Représentation de la fonction sinus.\n\ntitle(\"Représentation de la fonction sinus\")\n\n\n\n\n\n\n\n\n\nExercice 5.2 (Tracé de densités) On souhaite ici visualiser et comparer des densités de probabilité.\n\nTracer la densité de la loi normale centrée réduite entre \\(-4\\) et 4 (utiliser dnorm).\n\nx &lt;- seq(-4,4,by=0.01)\nplot(x,dnorm(x),type=\"l\")\n\n\n\n\nAjouter une ligne verticale (en tirets) qui passe par \\(x=0\\) (utiliser abline avec l’option lty=2).\n\nabline(v=0,lty=2)\n\n\n\n\n\n\nSur le même graphe, ajouter les densités de loi la de Student à 5 et 30 degrés de liberté (utiliser dt). On utilisera la fonction lines et des couleurs différentes pour chaque densité.\n\nlines(x,dt(x,5),col=2)\nlines(x,dt(x,30),col=3)\n\n\n\n\n\n\nAjouter une légende qui permette d’identifier chaque densité (fonction legend).\n\nlegend(\"topleft\",legend=c(\"Normal\",\"Student(5)\",\"Student(30)\"),\n   col=1:3,lty=1)\n\n\n\n\n\n\n\n\n\nExercice 5.3 (Tâches solaires) On souhaite ici visualiser une série temporelle.\n\nImporter la série taches_solaires.csv qui donne, date par date, un nombre de taches solaires observées.\n\ntaches &lt;- read.table(\"data/taches_solaires.csv\",sep=\";\",header=TRUE,dec=\",\")\n\nA l’aide de la fonction cut_interval du package ggplot2, créer un facteur qui sépare l’intervalle d’années d’observation en 8 intervalles de tailles à peu près égales. On appellera periode ce facteur.\n\nperiode &lt;- ggplot2::cut_interval(taches$annee,n=8)\n\nUtiliser les levels suivants pour le facteur periode.\n\ncouleurs &lt;- c(\"yellow\", \"magenta\", \"orange\", \"cyan\",\n          \"grey\", \"red\", \"green\", \"blue\")\n\n\nlevels(periode) &lt;- couleurs\n\nExpliquer la sortie de la fonction\n\ncoordx &lt;- seq(along=taches[,1])\n\n\nOn crée une séquence avec un pas de 1 de longueur égale à la dimension de taches[,1].\n\nVisualiser la série du nombre de taches en utilisant une couleur différente pour chaque période.\n\nplot(coordx,taches[,1],xlab=\"Temps\",ylab=\"Nombre de taches\",\n col=periode,type=\"p\",pch=\"+\")\n\n\n\n\n\n\n\nExercice 5.4 (Layout) On reprend le jeu de données sur l’ozone. A l’aide de la fonction layout séparer la fenêtre graphique en deux lignes avec\n\nun graphe sur la première ligne (nuage de points maxO3 vs T12)\n2 graphes sur la deuxième ligne (histogramme de T12 et boxplot de maxO3).\n\nlayout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))\nplot(maxO3~T12,data=ozone)\nhist(ozone$T12)\nboxplot(ozone$maxO3)"
  },
  {
    "objectID": "04-ggplot.html#la-grammaire-ggplot2",
    "href": "04-ggplot.html#la-grammaire-ggplot2",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.2 La grammaire ggplot2",
    "text": "5.2 La grammaire ggplot2\nCe package propose de définir des graphes sur R en utilisant une grammaire des graphiques (tout comme dplyr pour manipuler les données). On peut trouver de la documentation sur ce package aux url https://ggplot2.tidyverse.org et https://ggplot2-book.org/index.html\n\n5.2.1 Premiers graphes ggplot2\nNous considérons un sous échantillon du jeu de données diamonds du package ggplot2 (que l’on peut également charger avec le package tidyverse).\n\nlibrary(tidyverse)\nset.seed(1234)\ndiamonds2 &lt;- diamonds[sample(nrow(diamonds),5000),] \nsummary(diamonds2)\n##      carat               cut       color       clarity         depth      \n##  Min.   :0.2000   Fair     : 158   D: 640   SI1    :1189   Min.   :43.00  \n##  1st Qu.:0.4000   Good     : 455   E: 916   VS2    :1157   1st Qu.:61.10  \n##  Median :0.7000   Very Good:1094   F: 900   SI2    : 876   Median :61.80  \n##  Mean   :0.7969   Premium  :1280   G:1018   VS1    : 738   Mean   :61.76  \n##  3rd Qu.:1.0400   Ideal    :2013   H: 775   VVS2   : 470   3rd Qu.:62.50  \n##  Max.   :4.1300                    I: 481   VVS1   : 326   Max.   :71.60  \n##                                    J: 270   (Other): 244                  \n##      table           price             x                y        \n##  Min.   :49.00   Min.   :  365   Min.   : 0.000   Min.   :3.720  \n##  1st Qu.:56.00   1st Qu.:  945   1st Qu.: 4.720   1st Qu.:4.720  \n##  Median :57.00   Median : 2376   Median : 5.690   Median :5.700  \n##  Mean   :57.43   Mean   : 3917   Mean   : 5.728   Mean   :5.731  \n##  3rd Qu.:59.00   3rd Qu.: 5294   3rd Qu.: 6.530   3rd Qu.:6.520  \n##  Max.   :95.00   Max.   :18757   Max.   :10.000   Max.   :9.850  \n##                                                                  \n##        z        \n##  Min.   :0.000  \n##  1st Qu.:2.920  \n##  Median :3.520  \n##  Mean   :3.538  \n##  3rd Qu.:4.030  \n##  Max.   :6.430  \n## \nhelp(diamonds)\n\nUn graphe ggplot est défini à partir de couches que l’on assemblera avec l’opérateur +. Il faut a minima spécifier :\n\nles données\nles variables que l’on souhaite représenter\nle type de représentation (nuage de points, boxplot…).\n\nIl existe un verbe pour définir chacune de ces couches :\n\nggplot pour les données\naes (aesthetics) pour les variables\ngeom_ pour le type de représentation.\n\nOn peut obtenir le nuage de points carat vs price avec la fonction plot :\n\nplot(price~carat,data=diamonds2)\n\n\n\n\nAvec ggplot, on va faire\n\nggplot(diamonds2) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point() #bon\n\n\n\n\n\nExercice 5.5 (Premiers graphes ggplot) \n\n\nTracer l’histogramme de la variable carat (utiliser geom_histogram).\n\nggplot(diamonds2)+aes(x=carat)+geom_histogram()\n\n\n\n\nMême question en utilisant 10 classes pour l’histogramme (help(geom_histogram)).\n\nggplot(diamonds2)+aes(x=carat)+geom_histogram(bins=10)\n\n\n\n\nTracer le diagramme en barres de la variable cut (utiliser geom_bar).\n\nggplot(diamonds2)+aes(x=cut)+geom_bar()\n\n\n\n\n\n\nLa syntaxe ggplot est définie à partir d’éléments indépendants qui définissent la grammaire de ggplot. Les principaux verbes sont :\n\nData (ggplot) : les données au format dataframe ou tibble\nAesthetics (aes) : pour sépecifier les variables à représenter dans le graphe.\nGeometrics (geom_...) : le type de graphe (nuage de points, histogramme…).\nStatistics (stat_...) : utile pour spécifier des transformations des données nécessaires pour obtenir le graphe.\nScales (scale_...) : pour controler les paramètres permettant d’affiner le graphe (changement de couleurs, paramètres des axes…).\n\nTous ces éléments sont reliés avec le symbole +.\n\n\n5.2.2 Data et aesthetics\nCes deux verbes sont à utiliser pour tous les graphes ggplot. Le verbe ggplot sert à spécifier le jeu de données que l’on souhaite utiliser. Si le code est bien fait, nous n’aurons plus à utiliser le nom du jeu de données par la suite pour construire le graphe. Le verbe aes est quant à lui utile pour spécifier les variables que l’on souhaite visualiser. Par exemple, pour le nuage de points price vs carat la syntaxe débute avec\n\nggplot(diamonds2)+aes(x=carat,y=price)\n\nLes variables peuvent également être utilisées pour colorier des points ou des barres, définir des tailles… Dans ce cas on pourra renseigner les options color, size, fill dans la fonction aes. Par exemple\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)\n\n\n\n5.2.3 Geometrics\nCe verbe décrira le type de représentation souhaité. Pour un nuage de points, on utilisera par exemple geom_point :\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\n\n\n\n\nOn observe que ggplot ajoute la légende automatiquement. Voici les principaux exemples de geometrics :\n\n\nTable 5.1: Principaux geometrics\n\n\n\n\n\n\n\nGeom\nDescription\nAesthetics\n\n\n\n\ngeom_point()\nnuage de points\nx, y, shape, fill\n\n\ngeom_line()\nLigne (ordonnée selon x)\nx, y, linetype\n\n\ngeom_abline()\nLigne\nslope, intercept\n\n\ngeom_path()\nLigne (ordonnée par l’index)\nx, y, linetype\n\n\ngeom_text()\nTexte\nx, y, label, hjust, vjust\n\n\ngeom_rect()\nRectangle\nxmin, xmax, ymin, ymax, fill, linetype\n\n\ngeom_polygon()\nPolygone\nx, y, fill, linetype\n\n\ngeom_segment()\nSegment\nx, y, xend, yend, fill, linetype\n\n\ngeom_bar()\nDiagramme en barres\nx, fill, linetype, weight\n\n\ngeom_histogram()\nHistogramme\nx, fill, linetype, weight\n\n\ngeom_boxplot()\nBoxplot\nx, fill, weight\n\n\ngeom_density()\nDensité\nx, y, fill, linetype\n\n\ngeom_contour()\nLignes de contour\nx, y, fill, linetype\n\n\ngeom_smooth()\nLisseur (linéaire ou non linéaire)\nx, y, fill, linetype\n\n\nTous\n\ncolor, size, group\n\n\n\n\n\nExercice 5.6 (Diagrammes en barres) On étudie différentes façons de changer la couleur dans un diagramme en barres.\n\nTracer le diagramme en barres de la variable cut avec des barres bleues.\n\nggplot(diamonds2)+aes(x=cut)+geom_bar(fill=\"blue\")\n\n\n\n\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité de cut ainsi qu’une légende qui permet de repérer la couleur.\n\nggplot(diamonds2)+aes(x=cut,fill=cut)+geom_bar()\n\n\n\n\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité que vous choisirez (et sans légende).\n\nOn peut ajouter l’option show.legend = FALSE dans geom_bar :\n\n\nggplot(diamonds2)+aes(x=cut,fill=cut)+geom_bar(show.legend = FALSE)\n\n\n\n\n\nou spécifier directement les couleurs (toujours dans geom_bar) :\n\n\nggplot(diamonds2)+aes(x=cut)+geom_bar(fill=c(\"blue\",\"red\",\"green\",\"yellow\",\"black\"))\n\n\n\n\n\n\n\n\n5.2.4 Statistics\nCertains graphes nécessitent des calculs d’indicateurs statistiques pour être tracé. C’est par exemple le cas pour le diagramme en barres et l’histogramme où il faut calculer des hauteurs de rectangles ou barres. On peut spécifier les transformations simples facilement, par exemple\n\nD &lt;- data.frame(X=seq(-2*pi,2*pi,by=0.01))\nggplot(D)+aes(x=X,y=sin(X))+geom_line()\n\n\n\n\nLa transformation est spécifiée dans la fonction aes. Pour des transformations plus complexes, nous devons utiliser le verbe statistics. Une fonction stat_ permet de définir des nouvelles variables à partir du jeu de données initial, il est ensuite possible de représenter ces nouvelles variables. Par exemple, la fonction stat_bin, qui est utilisée par défaut pour construire des histogrammes, calcule les variables suivantes :\n\ncount, le nombre d’observations dans chaque classes.\ndensity, la valeur de la densité des observations dans chaque classe (fréqunce divisée par largeur de la classe).\nx, le centre de la classe.\n\nPar défaut geom_histogram fait appel à cette fonction stat_bin grâce à l’option stat=\"bin\". On visualise ainsi sur l’axe \\(y\\) le nombre d’observations dans chaque classe (la variable count).\n\nggplot(diamonds2)+aes(x=price)+geom_histogram(bins=40)\n\n\n\n\nSi on souhaite une autre variable issue de stat_bin, comme par exemple la densité, il faudra utiliser\n\nggplot(diamonds2)+aes(x=price,y=..density..)+geom_histogram(bins=40)\n\n\n\n\nLes fonctions stat_ peuvent être utilisées à la place des geom_ pour certaines représentations. Chaque fonction stat_ possède par défaut un geom_ et réciproquement. On peut par exemple obtenir le même graphe que précédemment avec\n\nggplot(diamonds2)+aes(x=price,y=..density..)+stat_bin()\n\nVoici quelques exemple de fonctions stat_\n\n\nTable 5.2: Exemple de statistics\n\n\nStat\nDescription\nParamètres\n\n\n\n\nstat_identity()\naucune transformation\n\n\n\nstat_bin()\nCount\nbinwidth, origin\n\n\nstat_density()\nDensity\nadjust, kernel\n\n\nstat_smooth()\nSmoother\nmethod, se\n\n\nstat_boxplot()\nBoxplot\ncoef\n\n\n\n\nstat et geom ne sont pas toujours simples à combiner. Nous recommandons d’utiliser geom lorsqu’on débute avec ggplot, les statisticspar défaut ne doivent en effet être changés que rarement.\n\nExercice 5.7 (Diagramme en barres “très simple”…) On considère une variable qualitative \\(X\\) dont la loi est donnée par \\[P(X=\\text{red})=0.3,\\ P(X=\\text{blue})=0.2,\\ P(X=\\text{green})=0.4,\\ P(X=\\text{black})=0.1\\] Représenter cette distribution de probabilité avec un diagramme en barres.\n\nLa difficulté ici vient du fait que les hauteurs de barre sont données : il ne faut pas les calculer à partir des données. On n’a donc pas à utiliser stat_count de geom_bar, if faut faire appel à stat_identity:\n\n\ndf &lt;- data.frame(var=c(\"red\",\"blue\",\"green\",\"black\"),prob=c(0.3,0.2,0.4,0.1))\nggplot(df)+aes(x=var,y=prob)+geom_bar(stat=\"identity\")+xlab(\"\")\n\n\n\n\n\nOn peut aussi utiliser l’aes weight :\n\n\nggplot(df)+aes(x=var,weight=prob)+geom_bar()+ylab(\"prob\")\n\n\n\n\n\n\nExercice 5.8 (Lissage) On étudie différentes façons de visualiser un lissage.\n\nReprésenter le lissage non linéaire de la variable price contre la variable carat à l’aide de geom_smooth puis de stat_smooth.\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_smooth(method=\"loess\")\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+stat_smooth(method=\"loess\")\n\n\n\n\nMême question mais avec une ligne en pointillés à la place d’un trait plein.\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_smooth(method=\"loess\",linetype=\"dotted\")\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+stat_smooth(method=\"loess\",geom=\"point\")\n\n\n\n\n\n\n\n\n5.2.5 Scales\nLes échelles (scales) controlent tout un tas d’options telles que des changements de couleurs, d’échelles ou de limites d’axes, de symboles, etc… L’utilisation n’est pas simple et nécessite de la pratique. On utilise généralement ce verbe à la dernière étape de construction du graphe. La syntaxe est définie comme suit :\n\ndébut : scale_.\najout de l’aesthetics que l’on souhaite modifier (color_, fill_, x_).\nfin : nom de l’échelle (manual, identity…)\n\nPar exemple,\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()+\n  scale_color_manual(values=c(\"Fair\"=\"black\",\"Good\"=\"yellow\",\n                              \"Very Good\"=\"blue\",\"Premium\"=\"red\",\"Ideal\"=\"green\"))\n\n\n\n\nVoici quelques exemples des principales échelles :\n\n\nTable 5.3: Exemples d’échelles\n\n\naes\nDiscret\nContinu\n\n\n\n\nCouleur (color et fill)\nbrewer\ngradient\n\n\n-\ngrey\ngradient2\n\n\n-\nhue\ngradientn\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nPosition (x et y)\ndiscrete\ncontinous\n\n\n-\n\ndate\n\n\nForme\nshape\n\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nTaille\nidentity\nsize\n\n\n-\nmanual\n\n\n\n\n\nNous présentons quelques exemples d’utilisation des échelles :\n\nCouleur dans un diagramme en barres\n\np1 &lt;- ggplot(diamonds2)+aes(x=cut)+geom_bar(aes(fill=cut))\np1\n\n\n\n\nOn change la couleur en utilisant la palette Purples :\n\np1+scale_fill_brewer(palette=\"Purples\")\n\n\n\n\nGradient de couleurs pour un nuage de points :\n\np2 &lt;- ggplot(diamonds2)+aes(x=carat,y=price)+geom_point(aes(color=depth))\np2\n\n\n\n\nOn change le gradient de couleur\n\np2+scale_color_gradient(low=\"red\",high=\"yellow\")\n\n\n\n\nModifications sur les axes\n\np2+scale_x_continuous(breaks=seq(0.5,3,by=0.5))+\n  scale_y_continuous(name=\"prix\")+\n  scale_color_gradient(\"Profondeur\")\n\n\n\n\n\n\n\n5.2.6 Group et facets\nggplot permet de faire des représentations pour des groupes d’individus. On procède généralement de deux façons différentes :\n\nvisualisation de sous groupes sur le même graphe, on utilise l’option group dans le verbe aes ;\nvisualisation de sous groupes sur des graphes différents, on utilise le verbe facet_wrap ou facet_grid.\n\nReprésentons ici (sur le même graphe) le lisseur price vs carat pour chaque modalité de cut\n\nggplot(diamonds2)+aes(x=carat,y=price,group=cut)+\n  geom_smooth(method=\"loess\")\n\n\n\n\nPour obtenir cette représentation sur plusieurs fenêtres, on utilise\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut,nrow=1)\n\n\n\n\nfacet_grid et facet_wrap font des choses proches mais divisent la fenêtre d’une façon différente :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_grid(color~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_wrap(color~cut)"
  },
  {
    "objectID": "04-ggplot.html#compléments",
    "href": "04-ggplot.html#compléments",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.3 Compléments",
    "text": "5.3 Compléments\nLa syntaxe ggplot est définie selon le schéma :\n\nggplot()+aes()+geom_()+scale_()\n\nElle est très flexible, on peut par exemple spécifier les variables de aes dans les verbes ggplot ou geom_ :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()\n\n\n\nggplot(diamonds2,aes(x=carat,y=price))+geom_point()\n\n\n\nggplot(diamonds2)+geom_point(aes(x=carat,y=price))\n\n\n\n\nCeci peut se révéler très utile lorsqu’on utilise des aes différents dans les geom_.\nOn peut aussi construire un graphe à l’aide de différents jeux de données :\n\nX &lt;- seq(-2*pi,2*pi,by=0.001)\nY1 &lt;- cos(X)\nY2 &lt;- sin(X)\ndonnees1 &lt;- data.frame(X,Y1)\ndonnees2 &lt;- data.frame(X,Y2)\nggplot(donnees1)+geom_line(aes(x=X,y=Y1))+\n  geom_line(data=donnees2,aes(x=X,y=Y2),color=\"red\")\n\n\n\n\nIl existe d’autres fonctions ggplot :\n\nggtitle pour ajouter un titre.\nggsave pour sauver un graphe.\ntheme_ pour changer le theme du graphe.\n\n\np &lt;- ggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\np+theme_bw()\n\n\n\np+theme_classic()\n\n\n\np+theme_grey()\n\n\n\np+theme_bw()\n\n\n\n\nD’autres thèmes sont disponibles dans le package ggtheme. On pourra également parler de la fonction set_theme qui permet de modifier le thème par défaut pour un document quarto."
  },
  {
    "objectID": "04-ggplot.html#quelques-exercices-supplémentaires",
    "href": "04-ggplot.html#quelques-exercices-supplémentaires",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.4 Quelques exercices supplémentaires",
    "text": "5.4 Quelques exercices supplémentaires\n\nExercice 5.9 (Fonctions cosinus et sinus) L’objectif est de visualiser les fonctions sinus et cosinus de plusieurs façons.\n\nTracer les fonctions sinus et cosinus. On utilisera tout d’abord les deux jeux de données suivants (un pour le sinus, l’autre pour le cosinus) :\n\ndonnees1 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X))\ndonnees2 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   sin=sin(X))\n\n\nggplot(donnees1)+geom_line(aes(x=X,y=cos))+\n  geom_line(data=donnees2,aes(x=X,y=sin),color=\"red\")\n\n\n\n\nFaire la même chose avec le jeu de données suivent qui regroupe les informations du cosinus et du sinus (on pourra ajouter une légende) :\n\ndonnees &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X),sin=sin(X))\n\n\nggplot(donnees)+aes(x=X,y=cos)+geom_line()+\n  geom_line(aes(y=sin),color=\"red\")\n\n\n\n#ou pour la légende\nggplot(donnees)+aes(x=X,y=cos)+geom_line(aes(color=\"cos\"))+\n  geom_line(aes(y=sin,color=\"sin\"))+labs(color=\"Fonction\")\n\n\n\n\nFaire la même chose avec un jeu de données et un seul appel à geom_line. On pourra utiliser la fonction pivot_longer du tidyverse.\n\ndf1 &lt;- donnees |&gt; \n  pivot_longer(cols=c(cos,sin),\n               names_to = \"Fonction\",\n               values_to = \"value\")\n#ou\ndf1 &lt;- donnees |&gt; \n  pivot_longer(cols=-X,\n               names_to = \"Fonction\",\n               values_to = \"value\")\nggplot(df1)+aes(x=X,y=value,color=Fonction)+geom_line()\n\n\n\n# on peut aussi ne pas créer de tibble intermédiaire\ndonnees |&gt; \n  pivot_longer(cols=-X,\n               names_to = \"Fonction\",\n               values_to = \"value\") |&gt; \n  ggplot()+aes(x=X,y=value,color=Fonction)+geom_line()\n\n\n\n\nTracer les deux fonctions sur deux fenêtres graphiques (utiliser facet_wrap).\n\nggplot(df1)+aes(x=X,y=value)+geom_line()+facet_wrap(~Fonction)\n\n\n\n\nFaire la même chose avec la fonction grid.arrange du package gridExtra.\n\nlibrary(gridExtra)\np1 &lt;- ggplot(donnees1)+aes(x=X,y=cos)+geom_line()\np2 &lt;- ggplot(donnees2)+aes(x=X,y=sin)+geom_line()\ngrid.arrange(p1,p2,nrow=1)\n\n\n\n\n\n\n\nExercice 5.10 (Différents graphes) On considère les données mtcars\n\ndata(mtcars)\nsummary(mtcars)\n##       mpg             cyl             disp             hp       \n##  Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n##  1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n##  Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n##  Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n##  3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n##  Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n##       drat             wt             qsec             vs        \n##  Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n##  1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n##  Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n##  Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n##  3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n##  Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n##        am              gear            carb      \n##  Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n##  1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n##  Median :0.0000   Median :4.000   Median :2.000  \n##  Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n##  3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n##  Max.   :1.0000   Max.   :5.000   Max.   :8.000\n\n\nTracer l’histogramme de mpg (on fera varier le nombre de classes).\n\nggplot(mtcars)+aes(x=mpg)+geom_histogram()\n\n\n\nggplot(mtcars)+aes(x=mpg)+geom_histogram(bins=10)\n\n\n\n\nTracer l’histogramme de la densité.\n\nggplot(mtcars)+aes(x=mpg,y=..density..)+geom_histogram(bins=10)\n\n\n\n\nTracer le diagramme en barres de cyl.\n\nggplot(mtcars)+aes(x=cyl)+geom_bar()\n\n\n\n\nTracer le nuage de points disp vs mpg en utilisant une couleur différente pour chaque valeur de cyl.\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=cyl)+geom_point()\n\n\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=as.factor(cyl))+\n  geom_point()+labs(color=\"cyl\")\n\n\n\n\nAjouter le lisseur linéaire sur le graphe (un lisseur par modalité de cyl).\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=as.factor(cyl))+geom_point()+\n  geom_smooth(method=\"lm\")+labs(color=\"cyl\")\n\n\n\n\n\n\n\nExercice 5.11 (Résidus pour régression simple) On souhaite visualiser les résidus dans un modèle de régression simple.\n\nGénérer un échantillon \\((x_i,y_i),i=1,\\dots,100\\) selon le modèle linéaire \\[y_i=3+x_i+\\varepsilon_i\\] où les \\(x_i\\) sont i.i.d. de loi uniforme sur \\([0,1]\\) et les \\(\\varepsilon_i\\) sont i.i.d. de loi gaussienne \\(N(0,0.2^2)\\) (utiliser runif et rnorm).\n\nn &lt;- 100\nX &lt;- runif(n)\neps &lt;- rnorm(n,sd=0.2)\nY &lt;- 3+X+eps\nD &lt;- data.frame(X,Y)\n\nTracer le nuage de points Y vs X et ajouter le lisseur linéaire.\n\nOn le fait d’abord “à la main” en calculant l’équation de la droite de régression.\n\n\nmodel &lt;- lm(Y~.,data=D)\nco &lt;- coef(model)\nD$fit &lt;- predict(model)\nco &lt;- coef(lm(Y~.,data=D))\nggplot(D)+aes(x=X,y=Y)+geom_point()+\n  geom_abline(slope=co[2],intercept=co[1],color=\"blue\")\n\n\n\n\n\nOn peut avoir le tracé directement avec geom_smooth.\n\n\nggplot(D)+aes(x=X,y=Y)+geom_point()+geom_smooth(method=\"lm\")\n\n\n\n\nReprésenter les résidus : on ajoutera une ligne verticale entre chaque point et la droite de lissage (utiliser geom_segment).\n\nggplot(D)+aes(x=X,y=Y)+geom_point()+geom_smooth(method=\"lm\")+\n  geom_segment(aes(xend=X,yend=fit))\n\n\n\n\n\n\n\nExercice 5.12 (Challenge) On considère les données diamonds.\n\nTracer les graphes suivants.\n\n\n\n\n\n\n\n\n\n\n\n\nOn obtient les graphes demandés avec :\n\n\nggplot(data=diamonds) + geom_boxplot(aes(x=cut,y=carat,fill=cut)) \nggplot(data=diamonds) + geom_boxplot(aes(x=carat,y=cut,fill=cut))\nggplot(data=diamonds) + geom_density(aes(x=carat,y=..density..)) +\n  facet_grid(cut~.)\n\nAjouter sur le troisième graphe les quartiles de la variable carat pour chaque valeur de cut. On utilisera une ligne verticale.\n\nQ1 &lt;- diamonds |&gt; group_by(cut) |&gt; \n  summarize(q1=quantile(carat,c(0.25)),q2=quantile(carat,c(0.5)),\n        q3=quantile(carat,c(0.75)))\nquantildf &lt;- Q1 |&gt; pivot_longer(-cut,names_to=\"alpha\",values_to=\"quantiles\")\nggplot(data=diamonds) + geom_density(aes(x=carat,y=..density..)) +\n  facet_grid(cut~.) +\n  geom_vline(data=quantildf,aes(xintercept=quantiles),col=alpha(\"black\",1/2))\n\n\n\n\n\nOn peut aussi l’obtenir avec stat_boxplot sans calculer explicitement les quartiles :\n\n\nggplot(data=diamonds) + aes(x=carat)+ \n  geom_density() +\n  stat_boxplot(aes(xintercept=c(..xlower..,..xmiddle..,\n                                ..xupper..)),geom=\"vline\") + \n  facet_grid(cut~.) \n\n\n\n\n\nou encore avec stat_summary :\n\n\ndiamonds |&gt; ggplot(aes(x=carat)) +\n  geom_density() +\n  stat_summary(mapping=aes(y=1,xintercept=after_stat(x)),fun=\"quantile\",\n               fun.args = list(prob=c(0.25,0.5,0.75)),\n               geom=\"vline\",orientation=\"y\") + \n  facet_grid(cut~.) \n\n\n\n\nEn déduire le graphe suivant.\n\n\n\n\n\n\nOn l’obtient avec\n\n\nggplot(data=diamonds) +\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density(aes(x=carat,y=..density..)) +  facet_grid(cut~.) +\n  geom_vline(data=quantildf,aes(xintercept=quantiles),col=alpha(\"black\",1/2)) +\n  ylab(\"\")\n\n\nou encore\n\n\nggplot(data=diamonds) + aes(x=carat)+\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density() +\n  stat_boxplot(aes(xintercept=c(..xlower..,..xmiddle..,\n                            ..xupper..)),geom=\"vline\") + \n  facet_grid(cut~.)+ylab(\"\")\n\n\n\n\n\nou encore avec stat_summary :\n\n\ndiamonds |&gt; ggplot(aes(x=carat)) +\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density() +\n  stat_summary(mapping=aes(y=1,xintercept=after_stat(x)),fun=\"quantile\",\n               fun.args = list(prob=c(0.25,0.5,0.75)),\n               geom=\"vline\",orientation=\"y\") + \n  facet_grid(cut~.) + ylab(\"\")"
  },
  {
    "objectID": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "href": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "title": "6  Quelques outils de visualisation dynamique/interactive",
    "section": "6.1 Représentations classiques avec rAmCharts et plotly",
    "text": "6.1 Représentations classiques avec rAmCharts et plotly\nLe package rAmCharts est très utile pour donner un caractère interactif à des représentations graphiques standards (nuages de points, séries temporelles, histogrammes…). Ce package a été fait dans l’esprit d’utiliser les fonctions graphiques de R en utilisant le préfixe am. La syntaxe est très proche de celle des fonctions graphiques standards. On a par exemple :\n\nlibrary(rAmCharts)\namHist(iris$Petal.Length)\n\n\n\n\n\n\namPlot(iris, col = colnames(iris)[1:2], type = c(\"l\", \"st\"), \n       zoom = TRUE, legend = TRUE)\n\n\n\n\n\n\namBoxplot(iris)\n\n\n\n\n\nplotly permet de faire des choses semblables avec avec une syntaxe spécifique. Les commandes plotly se décomposent essentiellement en 3 parties :\n\nle type de représentation graphique (plot_ly}) ;\nles ajouts que l’on souhaite effectuer (add_trace) ;\nla gestion de la fenêtre graphique (axes, titres…) (layout).\n\nOn trouvera un descriptif complet de ces 3 composantes ici. On propose de tracer un nuage de points en dimension 2 et d’y ajouter la droite de régression. On commence par générer le nuage et ajuster le modèle linéaire :\n\nlibrary(plotly)\nn &lt;- 100\nX &lt;- runif(n,-5,5)\nY &lt;- 2+3*X+rnorm(n,0,1)\nD &lt;- data.frame(X,Y)\nmodel &lt;- lm(Y~X,data=D)\n\nOn effectue maintenant le tracé\n\nD |&gt; plot_ly(x=~X,y=~Y) |&gt;\n  add_markers(type=\"scatter\",mode=\"markers\",\n              marker=list(color=\"red\"),name=\"Nuage\") |&gt;\n  add_trace(y=fitted(model),type=\"scatter\",mode='lines',\n            name=\"Régression\",line=list(color=\"blue\")) |&gt; \n  layout(title=\"Régression\",xaxis=list(title=\"abscisse\"),\n         yaxis=list(title=\"ordonnées\"))\n\n\n\n\n\nContrairement à ggplot, plotly permet de faire de la 3D. Par exemple\n\nplot_ly(z = volcano, type = \"surface\")\nplot_ly(z = volcano, type = \"contour\")\n\n\nIl est possible de convertir des graphes ggplot au format plotly avec la fonction ggplotly :\n\np &lt;- ggplot(iris)+aes(x=Species,y=Sepal.Length)+geom_boxplot()+theme_classic()\nggplotly(p)\n\n\n\n\n\n\nExercice 6.1 (Graphes basiques avec rAmCharts et plotly) Pour le jeu de données iris on effectuera les graphes suivants en rAmCharts et plotly.\n\nNuage de points représentant les longueurs et largeurs de Sépales. On utilisera une couleur différente en fonction de l’espèce.\n\namPlot(Sepal.Length~Sepal.Width,data=iris,col=iris$Species) \n\n\n\n\n\n\niris |&gt; plot_ly(x=~Sepal.Width,y=~Sepal.Length,color=~Species) |&gt;\n  add_markers(type=\"scatter\",mode=\"markers\")\n\n\n\n\n\nBoxplot permettant de visualiser la distribution de la variable Petal.Length en fonction de l’espèce.\n\namBoxplot(Petal.Length~Species,data=iris)\n\n\n\n\n\n\niris |&gt; plot_ly(x=~Species,y=~Petal.Length) |&gt; add_boxplot()"
  },
  {
    "objectID": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "href": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "title": "6  Quelques outils de visualisation dynamique/interactive",
    "section": "6.2 Graphes pour visualiser des réseaux avec visNetwork",
    "text": "6.2 Graphes pour visualiser des réseaux avec visNetwork\nDe nombreuses données peuvent être visualisées à l’aide d’un graphe, notamment lorsqu’il s’agit de représenter des connexions entre individus. Un individu est alors représentés par un noeud et les individus connectés sont reliés par des arêtes. Le package igraph propose une visualisation statique d’un réseau. Pour donner un caractère dynamique à ce type de représentation, on pourra utiliser le package visNetwork. Une représentation standard visNetwork s’effectue en spécifiant les nœuds et connexions d’un graphe, par exemple :\n\nnodes &lt;- tibble(id = 1:15, label = paste(\"Id\", 1:15),\n                    group=sample(LETTERS[1:3], 15, replace = TRUE))\nedges &lt;- tibble(from = trunc(runif(15)*(15-1))+1,to = trunc(runif(15)*(15-1))+1)\nlibrary(visNetwork)\nvisNetwork(nodes,edges)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE,\n                                        nodesIdSelection = TRUE)\n\n\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(selectedBy = \"group\")\n\n\n\n\n\n\nExercice 6.2 (Interactions entre media) On considère un graphe qui représente des liens entre différents médias. Les données sont présentées ici et on peut les importer avec\n\nnodes &lt;- read_csv(\"data/Dataset1-Media-Example-NODES.csv\")\nlinks &lt;- read_csv(\"data/Dataset1-Media-Example-EDGES.csv\")\nhead(nodes)\n## # A tibble: 6 × 5\n##   id    media               media.type type.label audience.size\n##   &lt;chr&gt; &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n## 1 s01   NY Times                     1 Newspaper             20\n## 2 s02   Washington Post              1 Newspaper             25\n## 3 s03   Wall Street Journal          1 Newspaper             30\n## 4 s04   USA Today                    1 Newspaper             32\n## 5 s05   LA Times                     1 Newspaper             20\n## 6 s06   New York Post                1 Newspaper             50\nhead(links)\n## # A tibble: 6 × 4\n##   from  to    weight type     \n##   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;    \n## 1 s01   s02       10 hyperlink\n## 2 s01   s02       12 hyperlink\n## 3 s01   s03       22 hyperlink\n## 4 s01   s04       21 hyperlink\n## 5 s04   s11       22 mention  \n## 6 s05   s15       21 mention\n\nL’objet nodes représente les nœuds du graphe et l’objet links les arêtes. On définit l’objet graphe avec\n\nlibrary(igraph)\nmedia &lt;- graph_from_data_frame(d=links, vertices=nodes, directed=T) \nV(media)$name &lt;- nodes$media\n\net on peut le visualiser en faisant un plot de cet objet\n\nplot(media)\n\n\n\n\n\nVisualiser ce graphe avec VisNetwork. On pourra utiliser la fonction toVisNetworkData.\n\nmedia.VN &lt;- toVisNetworkData(media)\nvisNetwork(nodes=media.VN$nodes,edges=media.VN$edges)\n\n\n\n\n\nAjouter une option qui permette de sélectionner le type de media (Newspaper, TV ou Online).\n\nmedia.VN$nodes &lt;- media.VN$nodes |&gt; rename(labels=type.label)\nvisNetwork(nodes=media.VN$nodes,edges=media.VN$edges) |&gt; \n  visOptions(selectedBy = \"labels\")\n\n\n\n\n\n\n\nUtiliser une couleur différente pour chaque type de media.\n\nIl suffit de donner le nom group à la variable type.label.\n\n\nmedia.VN1 &lt;- media.VN\nmedia.VN1$nodes &lt;- media.VN1$nodes |&gt; rename(group=media.type)\nvisNetwork(nodes=media.VN1$nodes,edges=media.VN1$edges) |&gt; \n  visOptions(selectedBy = \"labels\")\n\n\n\n\n\n\n\nFaire des flèches d’épaisseur différente en fonction du poids (weight). On pourra également ajouter l’option visOptions(highlightNearest = TRUE).\n\nIl suffit de donner le nom width ou value à la variable weight.\n\n\nmedia.VN1$edges &lt;- media.VN1$edges |&gt; rename(width=weight)\nvisNetwork(nodes=media.VN1$nodes,edges=media.VN1$edges) |&gt; \n  visOptions(selectedBy = \"labels\",highlightNearest = TRUE)"
  },
  {
    "objectID": "06-interactif.html#dashboard",
    "href": "06-interactif.html#dashboard",
    "title": "6  Quelques outils de visualisation dynamique/interactive",
    "section": "6.3 Dashboard",
    "text": "6.3 Dashboard\nUn tableau de bord permet de visualiser “facilement” et “rapidement” divers graphes et/ou résumés statistiques en lien avec une problématique donnée. Sur R le package flexdashboard permet de construire de tels tableaux de bord. On trouvera un descriptif précis de ce package à cette url : https://rmarkdown.rstudio.com/flexdashboard/. On utilisera cette documentation pour faire l’exercice suivant.\n\nExercice 6.3 (Dashboard pour modèles linéaires) On considère le jeu de données ozone.txt. Le problème est d’expliquer la concentration maximale en ozone quotidienne (variable maxO3) par d’autres variables météorologiques (températures et indicateurs de nébulosité relevés à différents moments de la journée…). On souhaite faire un tableau de bord qui permettra de :\n\nvisualiser les données : la base de données ainsi qu’un ou deux graphes descriptifs sur la variable à expliquer ;\nvisualiser les modèles linéaires simples : on choisit une variable explicative et on visualise le graphe de la régression ainsi que le modèle ;\nvisualiser le modèle linéaire complet : on affiche le résultat de la régression avec toutes les variables et on représente le graphe des résidus ;\nchoisir les variables explicatives.\n\n\nAvant de réaliser le dashboard, on propose d’écrire quelques commandes pour calculer les différentes sorties :\n\nOn considère uniquement les variables quantitatives du jeu de données. Visualiser les corrélations entre ces variables à l’aide de la fonction corrplot du package corrplot.\n\ndf &lt;- read.table(\"data/ozone.txt\")\ncc &lt;- cor(df[,1:11])\nmat.cor &lt;- corrplot::corrplot(cc)\n\n\n\n\nReprésenter l’histogramme de la variable maxO3, on fera le graphe avec ggplot, rAmCharts et plotly (en utilisant ggplotly par exemple).\n\ngg.H &lt;- ggplot(df)+aes(x=maxO3)+geom_histogram(bins = 10)\nam.H &lt;- amHist(df$maxO3)\npl.H &lt;- ggplotly(gg.H)\n\nConstruire le modèle linéaire permettant d’expliquer maxO3 par les autres variables. Calculer les résidus studentisés (rstudent) et visualiser ces résidus en fonction de la variable maxO3. Là encore on pourra ajouter un lisseur sur le graphe.\n\nmod &lt;- lm(maxO3~.,data=df)\nres &lt;- rstudent(mod)\ndf1 &lt;- data.frame(maxO3=df$maxO3,r.student=res)\nGgg &lt;- ggplot(df1)+aes(x=maxO3,y=res)+geom_point()+geom_smooth()\nGggp &lt;- ggplotly(Ggg)\n\n\nOn peut maintenant passer au tableau de bord. On utilise le menu File -&gt; Rmarkdown -&gt; From Template -&gt; Flex Dashboard.\n\nConstruire un premier dashboard permettant de visualiser :\n\nle jeu de données sur une colonne (on pourra utiliser la fonction datatable du package DT)\nl’histogramme de la variable maxO3 ainsi que la matrice des corrélations entre les variables quantitatives.\n\nAjouter un nouvel onglet qui permet de visualiser le summary du modèle linéaire complet. On pourra utiliser la fonction datatable du package DT. Indication : ce nouvel onglet peut se créer avec\n\nName of the tab\n=====================================  \n\nAjouter un nouvel onglet qui permet de visualiser un modèle linéaire simple avec la variable explicative de votre choix. On pourra afficher dans cet onglet le summary du modèle ainsi que le nuage de points et la droite de régression.\nPour aller plus loin : ajouter un dernier onglet qui permette à l’utilisateur de choisir la variable explicative du modèle simple. Indications : on pourra utiliser les commandes Shiny\n\nChoix de la variable\n\nradioButtons(\"variable1\",\n            label=\"Choisir la variable explicative\",\n            choices=names(df)[-1],\n            selected=list(\"T9\"))\n\nMise à jour du résumé\n\nmod1 &lt;- reactive({\n  XX &lt;- paste(input$variable1,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  lm(form,data=df)\n  })\n#Df correspond au jeu de données\nrenderDataTable({\n  mod.sum1 &lt;- summary(mod1())$coefficients |&gt; round(3) |&gt; as.data.frame()\n  DT::datatable(mod.sum1,options = list(dom = 't'))\n})\n\nMise à jour du graph interactif\n\nrenderPlotly({\n  (ggplot(df)+aes(x=!!as.name(input$variable1),y=maxO3)+\n     geom_point()+geom_smooth(method=\"lm\")) |&gt; ggplotly()\n})\n\nEnfin il ne faudra pas oublier d’ajouter\n\nruntime: shiny\n\n\nAjouter un dernier onglet permettant de choisir les variables explicatives dans le modèle linéaire. Là encore on pourra utiliser des commandes Shiny, par exemple\n\ncheckboxGroupInput(\"variable\",\n                   label=\"Choisir la variable\",\n                   choices=names(df)[-1],\n                   selected=list(\"T9\"))\n\nPour les variables choisies, on affichera dans ce nouvel onglet les coefficients du modèle linéaire ainsi que le graphe des résidus studentisés.\n\n\nLe tableau de bord finalisé pourra ressembler à\n\n\n\n\nIl est disponible à l’url https://lrouviere.shinyapps.io/dashboard/"
  },
  {
    "objectID": "07-shiny.html#une-première-application",
    "href": "07-shiny.html#une-première-application",
    "title": "7  Applications web avec Shiny",
    "section": "7.1 Une première application",
    "text": "7.1 Une première application\nCréer un répertoire pour l’application avec RStudio\nFile -&gt; New Project -&gt; New Directory -&gt; Shiny Web Application\nChoisir une application Multiple File.\nSi cette option n’est pas disponible (ça peut dépendre des versions de Rstudio), on pourra utiliser\nFile -&gt; New File -&gt; Shiny Web App -&gt; Multiple File\nDeux fichier sont automatiquement générés : ui.R et server.R. Lancer l’application en cliquant sur le bouton Run App.\n\nChanger le titre de l’application. On pourra l’appeler My first application.\nMettre à jour et vérifier que le titre a bien été changé."
  },
  {
    "objectID": "07-shiny.html#input---output",
    "href": "07-shiny.html#input---output",
    "title": "7  Applications web avec Shiny",
    "section": "7.2 Input - output",
    "text": "7.2 Input - output\nOn garde la même application. On ne s’intéressera pas à la structure dans cette partie, on veut simplement ajouter\n\ndes nouveaux inputs dans le sidebarPanel, après le sliderInput. On n’oubliera pas de séparer les inputs par des virgules ;\ndes nouveaux outputs dans le mainPanel, après le plotOutput. Là encore, on n’oubliera pas de séparer les outputs par des virgules.\n\nPour résumer on souhaite une colonne avec tous les inputs et une autre avec tous les outputs.\n\nAjouter dans ui.R une entrée qui permette de changer la couleur de l’histogramme. On pourra utiliser\n\nselectInput(inputId = \"color\", label = \"Couleur :\",\n            choices = c(\"Rouge\" = \"red\", \"Vert\" = \"green\", \"Bleu\" = \"blue\"))\n\nAjouter une sortie qui permette de visualiser le summary du jeu de données faithful. On pourra utiliser\n\n# ui.R\nverbatimTextOutput(\"...\")\n\n# server.R\noutput$... &lt;- renderPrint({\n  summary(...)\n})\n\n\n\nExercice 7.1 (Ajouter des inputs/outputs) Ajouter des entrées/sorties à votre application pour\n\nproposer à l’utilisateur de choisir un titre pour l’histogramme (utiliser textInput dans l’ui et l’option main dans hist);\nchoisir la variable de faithful à représenter dans l’histogramme avec un radioButtons ayant pour choix colnames(faithful);\nvisualiser le jeu de données entier (renderDataTable & dataTableOutput);\najouter un text sous l’histogramme qui indique le nombre de classes (renderText et paste dans server, textOutput dans ui);\nremplacer le selectInput du choix de la couleur par un colourInput (utiliser la package colourpicker);\nexporter le graphe (downloadButton & jpeg).\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://input-output-rouviere-shiny.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#structurer-lapplication",
    "href": "07-shiny.html#structurer-lapplication",
    "title": "7  Applications web avec Shiny",
    "section": "7.3 Structurer l’application",
    "text": "7.3 Structurer l’application\nOn considère l’application app_structure disponible ici. C’est quasiment la même que précédemment avec un navbarPage qui définit\n\nun onglet Data pour visualiser les données (table + summary)\nun onglet Visualisation : inputs + histogramme.\n\n\nExercice 7.2 (Structurer son application) On conserve l’application précédente.\n\nDans l’onglet Data utiliser navlistPanel pour séparer le summary et la table table en deux onglets :\n\n# rappel de la structure (ui.R)\nnavlistPanel(\"Title of the structure\",\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\"),\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\")\n)\n\nDans l’onglet Visualization changer sidebarLayout - sidebarPanel - mainPanel par un fluidRow à 2 colonnes :\n\n1/4 : pour le sidebarPanel\n3/4 : pour le mainPanel.\n\n\nfluidRow(\n  column(width = 3, ...), # column 1/4 (3/12)\n  column(width = 9, ...)  # column 3/4 (9/12)\n)\n\nIndication : utiliser wellPanel pour la colonne de gauche.\nAjouter un bloxplot dans l’onglet visualisation (même variable et même couleur). On pourra également utiliser tabsetPanel pour avoir deux onglets pour l’histogramme et le boxplot.\n\n# rappel de la structure (ui.R)\ntabsetPanel(\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\"),\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\")\n)\n\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://structure-rouviere-shiny.apps.math.cnrs.fr/.\nPour aller plus loin : faire la même application avec shinydashboard."
  },
  {
    "objectID": "07-shiny.html#ajout-de-graphes-interactifs",
    "href": "07-shiny.html#ajout-de-graphes-interactifs",
    "title": "7  Applications web avec Shiny",
    "section": "7.4 Ajout de graphes interactifs",
    "text": "7.4 Ajout de graphes interactifs\nDans l’application précédente, remplacer l’histogramme et la boxplot par des graphes javascript réalisés avec rAmCharts. On pourra utiliser\n\n# server.R\noutput$distPlot &lt;- renderAmCharts({...})\n\n# ui.R\namChartsOutput(\"...\")\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://interactifs-rouviere-shiny-2.apps.math.cnrs.fr/.\n\nExercice 7.3 (Modèles linéaires pour l’ozone) On considère les données ozone.txt où le problème est d’expliquer la variable continue maxO3 par les autres variables du jeu de données. On propose de construire une application avec 3 onglets en utilisant (dans le ui.R) la structure suivante :\n\nnavbarPage(\n  title=\"Titre de l'appli\",\n  tabPanel(\n    title=\"Titre de l'onglet\",\n    ...\n  )\n)\n\n\nCréer le fichier global.R où on chargera les packages nécessaires et où on lira le jeu de données.\nConstruire le premier onglet où on visualisera :\n\nsur une ligne le jeu de données de façon dynamique : on pourra utiliser la fonction dataTableOutput dans le ui.R et la fonction renderDataTable dans le server.R.\nsur une autre ligne l’histogramme de la variable à expliquer et la matrice des corrélations des variables explicatives quatitatives. On pourra utiliser les commandes suivantes pour la matrice des corrélations :\n\ncorrplot::corrplot(cor(ozone[,2:11]))\n\nD’un point de vue structure on pourra utiliser la fonction fluidrow pour intégrer les deux graphes.\n\nAjouter un second onglet qui permettra de visualiser un modèle à une variable explicative que l’utilisateur choisira. On pourra utiliser radioButtons dans le ui.R pour choisir la variable et les commandes suivantes dans le server.R\n\nrenderDataTable({\n  XX &lt;- paste(input$...,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  mod &lt;- lm(form,data=ozone)\n  mod_sum1 &lt;- summary(mod)$coefficients |&gt; round(3) |&gt; as_tibble()\n  mod_sum1\n})\n\nOn pourra également visualiser le nuage de points et la droite de régression pour le modèle choisi par l’utilisateur.\nAjouter un troisième onglet où l’utilisateur pourra visualiser les estimateurs d’un modèle de régression multiple où il choisira les variables explicatives (avec checkboxGroupInput par exemple). On pourra éventuellement ajouter un graphe pour visualiser les résidus.\nChoisir un thème pour votre application en vous référant à la page suivante : https://rstudio.github.io/shinythemes/.\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici : https://ozone-rouviere-shiny-4.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#reactive-isolation-observe-html",
    "href": "07-shiny.html#reactive-isolation-observe-html",
    "title": "7  Applications web avec Shiny",
    "section": "7.5 Reactive, isolation, observe, html, …",
    "text": "7.5 Reactive, isolation, observe, html, …\nGarder la même application et\n\najouter un actionButton combiné à un isolate pour mettre à jour l’application uniquement lorsque l’utilisateur clique sur le bouton.\nUtiliser observeEvent pour forcer l’apparition de l’histogramme lorsqu’on met à jour l’application. On pourra utiliser\n\n# think to add  \"session\" \nshinyServer(function(input, output, session))\n\n# an id \ntabsetPanel(id = \"viz\",\n            tabPanel(\"Histogram\",...,))\n\n# and finaly\nobserveEvent(input$go, {\n  updateTabsetPanel(session, inputId = \"viz\",\n                    selected = \"Histogram\")})\n\n\nUtiliser reactive pour stocker la variable sélectionnée\n\n# Example of reactive\ndata &lt;- reactive({\n  ...\n})\n\noutput$plot &lt;- renderPlot({\n  x &lt;- data()\n  ...\n})\n\nAjouter un titre en bleu sur le jeu de données. On pourra utiliser h1\n\nh1(\"Dataset\", style = \"color : #0099ff;text-align:center\")\n\nAjouter un troisième onglet pour présenter un résumé de votre Université, avec un logo de l’institution et un lien vers son site web.\nPour aller plus loin : changer le thème de l’application avec un fichier de style .css. On pourra par exemple utiliser bootswatch http://bootswatch.com/3.\n\nL’application finale pourra ressembler à\n\n\n\n\nElle est également disponible ici https://plus-loin-rouviere-shiny-2.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#exercices-complémentaires",
    "href": "07-shiny.html#exercices-complémentaires",
    "title": "7  Applications web avec Shiny",
    "section": "7.6 Exercices complémentaires",
    "text": "7.6 Exercices complémentaires\n\nExercice 7.4 (Une application simple descriptive) On considère le jeu de données SAheart du package bestglm.\n\nA l’aide du package rAmCharts, représenter les histogrammes des variables quantitatives du jeu de données ainsi que les boxplots de ces variables en fonction de la variable chd.\n\nlibrary(bestglm)\nlibrary(rAmCharts)\namHist(SAheart$adiposity,freq=FALSE,xlab=\"adiposity\")\n\n\n\n\n\n\namBoxplot(adiposity~chd,data=SAheart)\n\n\n\n\n\nCréer une application shiny avec shinydashboard qui permette de\n\nchoisir une variable parmi les variables quantitatives du jeu de données. On pourra utiliser radioButtons avec l’argument\n\n\nchoices=names(SAheart)[sapply(SAheart,class)==\"numeric\"]\n\n\nvisualiser l’histogramme, puis le boxplot en fonction de chd de la variable sélectionnée. Ces graphiques devront être faits avec rAmCharts. On pourra utiliser amChartsOutput. L’application demandée pourra ressembler à\n\n\n\n\n\nElle est disponible ici https://lrouviere.shinyapps.io/DESC_APP.\n\n\n\nExercice 7.5 (Stations velib à Rennes) Réaliser une application qui permette de visualiser les stations velib à Rennes. Elle pourra être du même genre que celle-ci :\n\n\n\n\nOn peut avoir une meilleure vision ici : https://lrouviere.shinyapps.io/velib/. On récupérera les données sur le site de Rennes métropole : https://data.rennesmetropole.fr/explore/dataset/etat-des-stations-le-velo-star-en-temps-reel/export/"
  },
  {
    "objectID": "08-estimation.html",
    "href": "08-estimation.html",
    "title": "8  Estimation et intervalles de confiance",
    "section": "",
    "text": "9 Vers des modèles plus complexes\nOn présente un cas d’étude dans cette partie. On se pose le problème d’étudier l’impact de l’activité sportive combiné à un régime sur le cancer. Pour se faire, on étudie l’évolution de tumeurs cancéreuses chez des souris réparties en 4 groupes :\nOn importe les données\n(data1 &lt;- readxl::read_excel(\"data/donnees_tum.xlsx\", sheet = \"Tumeur\",skip=1))\n## # A tibble: 53 × 20\n##    Id        J5    J8   J12   J14   J16   J20   J22    J26    J28    J30    J34\n##    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n##  1 CTL 1  11.3  10.5  11.1  10.4  11.9  19.8  21.8   30.1   33.1   43.3   85.5 \n##  2 CTL 2   0     5.29  5.83  5.22  5.77  4.47  4.79   5.06   5.13   5.00   6.21\n##  3 CTL 3  10.3  16.8  11.4  13.1  13.4  22.9  25.1   24.3   42.1   57.2  104.  \n##  4 CTL 4   6.00 11.4  25.5  32.0  34.3  69.2  85.2  137.   187.   212.   278.  \n##  5 CTL 5  15.9  11.6  14.1  11.0  18.0  19.5  21.0   47.4   82.1   81.7  156.  \n##  6 CTL 6   0     0     3.86  3.65 10.1  14.1  18.8   27.0   46.2   54.2   75.0 \n##  7 CTL 7  10.8  10.9  19.0  16.9  22.2  31.1  33.9   34.4   62.4   79.3  152.  \n##  8 CTL 8   9.00 13.3  16.2  15.4  16.4  22.6  22.0   16.9   15.5   17.8   29.4 \n##  9 CTL 9   3.75 11.2  10.5  11.3  30.3  52.5  59.4   82.1   97.7  126.   218.  \n## 10 CTL 10 14.1  16.3  19.4  23.1  26.7  25.3  38.8   38.2   44.5   54.5   89.5 \n## # ℹ 43 more rows\n## # ℹ 8 more variables: J36 &lt;dbl&gt;, J40 &lt;dbl&gt;, J42 &lt;dbl&gt;, J44 &lt;dbl&gt;, J48 &lt;dbl&gt;,\n## #   J50 &lt;dbl&gt;, J54 &lt;dbl&gt;, J56 &lt;dbl&gt;\ndim(data1)\n## [1] 53 20\net on les met sous un format long :\ndata2 &lt;- data1 |&gt; pivot_longer(-c(Id),names_to=\"Day\",values_to = \"Volume\") |&gt;\n  mutate(day_num=as.numeric(str_remove(Day,'[J]')),\n         groupe=fct(str_remove(Id,'[0-9]+')),\n         Day=fct(Day))\ndata2\n## # A tibble: 1,007 × 5\n##    Id    Day   Volume day_num groupe\n##    &lt;chr&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; \n##  1 CTL 1 J5      11.3       5 \"CTL \"\n##  2 CTL 1 J8      10.5       8 \"CTL \"\n##  3 CTL 1 J12     11.1      12 \"CTL \"\n##  4 CTL 1 J14     10.4      14 \"CTL \"\n##  5 CTL 1 J16     11.9      16 \"CTL \"\n##  6 CTL 1 J20     19.8      20 \"CTL \"\n##  7 CTL 1 J22     21.8      22 \"CTL \"\n##  8 CTL 1 J26     30.1      26 \"CTL \"\n##  9 CTL 1 J28     33.1      28 \"CTL \"\n## 10 CTL 1 J30     43.3      30 \"CTL \"\n## # ℹ 997 more rows"
  },
  {
    "objectID": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "href": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "title": "8  Estimation et intervalles de confiance",
    "section": "8.1 Générer des observations selon des lois de probabilités",
    "text": "8.1 Générer des observations selon des lois de probabilités\nR étant un logiciel de statistique, il est bien entendu possible de\n\nvisualiser\ncalculer des indicateurs (quantiles, probabilités…)\ngénérer des observations\n\npour toutes les lois classiques de probabilités. Chaque loi va être identifiée par une chaîne de caractères :\n\n\n\nLoi\nChaîne\n\n\n\n\nBinomiale\nbinom\n\n\nPoisson\npois\n\n\nUniforme\nunif\n\n\nExponentielle\nexp\n\n\nNormale\nnorm\n\n\n\nUn préfixe permettra de spécifier l’action que l’on souhaite effectuer sur la loi :\n\nd : calculer la densité pour une loi continue ou la fonction de masse pour une loi discrète\nq : calculer les quantiles\nr : générer des observations.\n\nOn pourra par exemple :\n\nCalculer la densité de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\ndnorm(c(-1,0,1),mean=0,sd=1)\n## [1] 0.2419707 0.3989423 0.2419707\n\nCalculer les quantiles d’ordre 0.05, 0.5 et 0.95 de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\nqnorm(c(0.05,0.5,0.95),mean=0,sd=1)\n## [1] -1.644854  0.000000  1.644854\n\nGénérer 10 observations selon une loi \\(\\mathcal N(0,1)\\) avec\n\nrnorm(10,mean=0,sd=1)\n##  [1] -0.30647773  1.22544137 -0.98622333 -0.48768341 -0.68808521  1.23408258\n##  [7]  2.01305561 -0.01116342 -0.03911877  0.15343995\n\n\n\nExercice 8.1 (Loi binomiale) On étudie les fonctions R associées à la loi binomiale.\n\nSoit \\(X\\) un variable de loi binomiale \\(B(20,0.6)\\). Calculer la probabilité que \\(X\\) soit égale à 1,5,10,15.\n\ndbinom(c(1,5,10,15),size=20,prob=0.6)\n## [1] 3.298535e-07 1.294494e-03 1.171416e-01 7.464702e-02\n\nPour la même loi calculer la probabilités : \\[\\mathbf P(X\\leq 13),\\quad\\mathbf P(X&gt;13),\\quad \\mathbf P(X\\geq 13)\\quad\\text{et}\\quad \\mathbf P(X\\in[8,15]).\\]\n\nPour la première il suffit d’utiliser pbinom :\n\npbinom(13,size=20,prob=0.6)\n## [1] 0.7499893\n\nOn remarque ensuite que \\[\\mathbf P(X&gt;13)=1-\\mathbf P(X\\leq 13)\\quad\\text{et}\\quad\\mathbf P(X\\geq 13)=\\mathbf P(X&gt;13)+\\mathbf P(X=13)\\]\ndonc\n\n1-pbinom(13,size=20,prob=0.6)\n## [1] 0.2500107\n1-pbinom(13,size=20,prob=0.6)+dbinom(13,size=20,prob=0.6)\n## [1] 0.4158929\n\nPour la dernière, on utilise \\[\\mathbf P(X\\in[8,15]=\\mathbf P(X\\leq 15)-\\mathbf P(X\\leq 8)+\\mathbf P(X=8)\\]\n\npbinom(15,size=20,prob=0.6)-pbinom(8,size=20,prob=0.6)+dbinom(8,size=20,prob=0.6)\n## [1] 0.9280191\n\nOn aurait aussi pu faire\n\nsum(dbinom(8:15,size=20,prob=0.6))\n## [1] 0.9280191\n\n\nReprésenter le diagramme en barre associé à la loi \\(B(20,0.6)\\). On pourra utiliser l’argument stat=“identity” dans la fonction geom_bar.\n\nprob &lt;- dbinom(0:20,size=20,prob=0.6)\ndf &lt;- data.frame(x=0:20,prob=prob)\nggplot(df)+aes(x=x,y=prob)+geom_bar(stat=\"identity\",width=0.15)+theme_classic()\n\n\n\n\nGénérer un échantillon de taille 5000 selon la loi \\(B(20,0.6)\\). Tracer le diagramme en barres associé à cet échantillon et comparer le à celui de la question précédente.\n\nX &lt;- rbinom(5000,size=20,prob=0.6)\ndf1 &lt;- data.frame(X=X)\nggplot(df1)+aes(x=X,y=..prop..)+geom_bar(width=0.15)+theme_classic()+xlim(c(0,20))\n\n\n\n\n\nOn peut visualiser les digrammes en barres cote à cote avec\n\n\nprop &lt;- table(X)/5000\nprop1 &lt;- data.frame(X=as.numeric(names(prop)),Freq=as.numeric(prop))\ndf2 &lt;- full_join(df,prop1,by=c(\"x\"=\"X\"))\nnames(df2)[2:3] &lt;- c(\"Theo\",\"Emp\")\ndf2[is.na(df2)] &lt;- 0\ndf3 &lt;- df2 |&gt; pivot_longer(-x,names_to=\"type\",values_to=\"valeur\")\nggplot(df3)+aes(x=x,y=valeur,fill=type)+geom_bar(stat=\"identity\",position='dodge',width=0.25)\n\n\n\n\n\n\n\nExercice 8.2 (Loi normale) On considère ici la loi normale \\(\\mathcal N(\\mu,\\sigma^2)\\).\n\nTracer la densité de la loi \\(\\mathcal N(0,1)\\).\n\ndf &lt;- tibble(x=seq(-3,3,by=0.01),y=dnorm(x))\nggplot(df)+aes(x=x,y=y)+geom_line()\n\n\n\n\nSoit \\(X\\) une variable aléatoire de loi \\(\\mathcal N(2,2^2)\\) (variance 4, écart-type 2). Calculer les probabilités suivantes : \\[\\mathbf P(X=2),\\quad \\mathbf P(X\\leq 2),\\quad \\mathbf P(X&lt;2),\\quad \\mathbf P(X&gt;3).\\]\n\nLa première probabilité est nulle. Les deux suivantes sont égales et valent\n\n\npnorm(2,2,2)\n## [1] 0.5\n\n\nOn obtient la dernière avec\n\n\n1-pnorm(3,2,2)\n## [1] 0.3085375\n\nGénérer un échantillon de taille 5000 selon la loi \\(\\mathcal N(0,1)\\). Tracer l’histogramme associé à cet échantillon et comparer le à la densité tracée à la question précédente (on pourra superposer les 2 représentations).\n\ndf1 &lt;- data.frame(X=rnorm(5000))\nggplot(df1)+aes(x=X,y=..density..)+geom_histogram()+theme_classic()+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=1)"
  },
  {
    "objectID": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "href": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "title": "8  Estimation et intervalles de confiance",
    "section": "8.2 Une étude numérique de la moyenne empirique.",
    "text": "8.2 Une étude numérique de la moyenne empirique.\nOn considère un échantillon de \\(x_1,\\dots,x_n\\) i.i.d de loi uniforme sur \\([a,b]\\) avec \\(a\\) et \\(b\\) supposés inconnus. Le problème est d’estimer l’espérance de cette loi uniforme \\[\\mathbf E[X]=\\frac{a+b}{2}.\\]\nUn estimateur naturel est la moyenne empirique \\[\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i\\] Remarquons déjà que la moyenne empirique dépend des observations \\(x_1,\\dots,x_n\\) : la moyenne va donc changer lorsque les observations changent.\n\n8.2.1 Exemple\nPour fixer les idées, on suppose dans cette partie que \\(a=0\\) et \\(b=1\\). L’espérance à estimer vaut donc 0.5 (on peut faire comme si on le la connaissait pas.)\nOn considère deux échantillons de taille 20 générées selon une loi uniforme entre 0 et 1 :\n\nech1 &lt;- runif(20)\nech2 &lt;- runif(20)\ndf &lt;- data.frame(ech1,ech2)\n\nLes moyennes empiriques pour ces deux échantillons sont différentes :\n\ndf |&gt; summarise_all(mean)\n##        ech1      ech2\n## 1 0.4876945 0.4780057\n\nLa moyenne empirique peut-être considérée comme une variable aléatoire : elle va donc posséder une loi de probabilité, une espérance… Si on considère l’exemple précédent, on sent bien que la distribution de la moyenne empirique doit\n\nse répartir autours de 0.5 (qui est la valeur à estimer).\nêtre de plus en plus concentrée autours de 0.5 lorsque le nombre d’observations \\(n\\) augmente.\n\nOn peut visualiser ce fait en considérant un grand nombre d’échantillon et en regardant comment se comporte les valeurs moyennes de chaque échantillon. Pour cela on\n\ngénère un nombre \\(B\\) (grand) d’échantillons de taille \\(n=20\\) selon une loi uniforme entre 0 et 1.\n\nset.seed(1234)\ndf &lt;- matrix(runif(20*5000),nrow=20) |&gt; as.data.frame()\n\ncalcule les moyennes obtenues pour chaque échantillon\n\nmoy &lt;- df |&gt; summarize_all(mean)\nhead(t(moy))\n##         [,1]\n## V1 0.4719301\n## V2 0.4449401\n## V3 0.4833523\n## V4 0.3740339\n## V5 0.4132300\n## V6 0.3734092\n\nvisualise la distribution de la moyenne de chaque échantillon (en traçant l’histogramme de ces valeurs par exemple).\n\nmoy &lt;- data.frame(M=t(moy))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+theme_classic()\n\n\n\n\n\nOn voit que cette distribution semble se comporter comme une distribution gaussienne autours de la vraie valeur (0.5). Le théorème central limite confirme (et surtout prouve) ce constat. En effet, le théorème central limite nous dit que cette moyenne \\(\\bar x_n\\) vérifie \\[\\sqrt{n}\\frac{\\bar x_n-\\mu}{\\sigma}\\to \\mathcal N(0,1)\\] avec \\(\\mu=0.5\\) et \\(\\sigma=1/\\sqrt{12}\\) ici. On a donc \\[\\sqrt{n}\\frac{\\bar X_n-0.5}{1/\\sqrt{12}}\\to \\mathcal N(0,1)\\] Ce qui signifie qu’on peut approcher la loi de \\(\\bar X_n\\) par la loi \\(\\mathcal N(0.5,1/(12n))\\) avec \\(n=20\\). On le retrouve sur notre exemple en supperposant cette distribution gaussienne sur l’histogramme\n\nx &lt;- seq(0.25,0.75,by=0.001)\ndf &lt;- data.frame(x=x,y=dnorm(x,0.5,1/(sqrt(12*20))))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=2)+xlab(\"x\")\n\n\n\n\n\nExercice 8.3 (Théorème central limite) Faire le même travail pour des tailles d’échantillon de 50, 100 et 500. Interpréter.\n\ndf1 &lt;- matrix(runif(20*5000),nrow=20) \ndf2 &lt;- matrix(runif(50*5000),nrow=50) \ndf3 &lt;- matrix(runif(100*5000),nrow=100) \ndf4 &lt;- matrix(runif(500*5000),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n                  n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"))+theme_classic()\n\n\n\n\n\nOn remarque que :\n\ndans tous les cas, la distribution de la moyenne empirique semble être gaussienne et centrée en 0.5 (qui est la valeur à estimer).\nla dispersion augmente lorsque le nombre d’observations \\(n\\) diminue (moins précis).\n\n\n\n\nExercice 8.4 (Théorème central limite (toujours)) Faire le même exercice pour une loi gaussienne \\(\\mathcal N(1,2)\\) et une loi de Bernoulli \\(\\mathcal B(0.6)\\).\n\nPour la loi \\(\\mathcal N(1,2)\\)\n\ndf1 &lt;- matrix(rnorm(20*5000,1,2),nrow=20) \ndf2 &lt;- matrix(rnorm(50*5000,1,2),nrow=50) \ndf3 &lt;- matrix(rnorm(100*5000,1,2),nrow=100) \ndf4 &lt;- matrix(rnorm(500*5000,1,2),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n\n\n\n\nPour la \\(\\mathcal B(0.6)\\)\n\ndf1 &lt;- matrix(rbinom(20*50000,1,0.6),nrow=20) \ndf2 &lt;- matrix(rbinom(50*50000,1,0.6),nrow=50) \ndf3 &lt;- matrix(rbinom(100*50000,1,0.6),nrow=100) \ndf4 &lt;- matrix(rbinom(500*50000,1,0.6),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=30)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n\n\n\n\nDans tous ces cas, on retrouve bien que la moyenne empirique a une distribution gaussienne autours de la valeur à estimer (l’espérance). La dispersion dépend de :\n\nla dispersion des observations (de la loi de \\(x_i\\)) ;\ndu nombre d’observations.\n\nLa moyenne empirique est donc d’autant plus précise que la variance des observations est petite et que le nombre d’observations est grand. Le théorème central limite permet de quantifier tout ça et donc de déduire des intervalles de confiance et de faire des tests…"
  },
  {
    "objectID": "08-estimation.html#intervalles-de-confiance",
    "href": "08-estimation.html#intervalles-de-confiance",
    "title": "8  Estimation et intervalles de confiance",
    "section": "8.3 Intervalles de confiance",
    "text": "8.3 Intervalles de confiance\nOn cherche ici à illustrer numériquement le niveau d’un intervalle de confiance. On rappelle que \\([A,B]\\) est un IC de niveau \\(1-\\alpha\\) pour un paramètre \\(\\theta\\) si \\[P(\\theta\\in[A,B])=1-\\alpha.\\]\n\nExercice 8.5 (IC pour l’espérance d’une gaussienne) On fixe ici le niveau à 0.95 (\\(\\alpha=0.05\\)). On considère \\(n\\) observations \\(x_1,\\dots,x_n\\) i.i.d de loi \\(\\mathcal N(\\mu,1)\\) et on cherche un intervalle de confiance pour \\(\\mu\\).\n\nGénérer \\(n=100\\) observations i.i.d. selon la loi \\(\\mathcal N(\\mu,1)\\) avec \\(\\mu=1\\).\n\nech &lt;- rnorm(100,1,1)\n\nCalculer un intervalle de confiance pour \\(\\mu\\) de niveau 0.95.\n\nt.test(ech)$conf.int\n## [1] 0.8038101 1.2314117\n## attr(,\"conf.level\")\n## [1] 0.95\n\nSelon-vous, peut-on dire que la probabilité que \\(\\mu\\) appartienne à l’intervalle trouvé est de 0.95 ? Si non, comment peut-on interpréter cette formule.\n\nNon. Dans notre cas, \\(\\mu\\) (qui vaut 1) appartient à l’intervalle trouvé. Dans la vraie vie, \\(\\mu\\) est inconnu. Ce que la formule nous dit, c’est que si nos données sont issues d’un loi \\(\\mathcal N(\\mu,\\sigma^2)\\), on a une probabilité de 0.95 que \\(\\mu\\) appartienne à l’intervalle trouvé. Donc si on génère un très grand nombre d’échantillon i.i.d selon la loi \\(\\mathcal N(\\mu,\\sigma^2)\\), alors dans 95% des cas, la vraie valeur de \\(\\mu\\) appartiendra à l’intervalle trouvé. C’est ce qu’on propose de vérifier dans les questions suivantes.\n\nGénérer 5000 échantillons i.i.d. de loi \\(\\mathcal N(1,1)\\) de tailles 100. On pourra mettre le tout dans une matrice de dimension \\(5000\\times 100\\).\n\nmu &lt;- 1\nn &lt;- 100\nB &lt;- 5000\nX &lt;- matrix(rnorm(n*B,mean=mu),nrow=B)\n\nCalculer un intervalle de confiance de niveau 0.95 pour chacun des 5000 échantillons. On pourra utiliser une boucle for ou la fonction apply.\n\nb1 &lt;- apply(X,1, function(x) t.test(x)$conf.int[1:2])\n\nSur les 5000 intervalles obtenus, calculer le nombre de fois où la vraie valeur de \\(\\mu\\) (en l’occcurence ici 1) se trouve à l’intérieur de l’intervalle.\n\nb2 &lt;- as.data.frame(t(b1))\nb2 |&gt; mutate(test=mu&gt;V1 & mu&lt;V2) |&gt; summarize(mean(test))\n##   mean(test)\n## 1     0.9494\n\nRefaire les questions 5-6-7 avec des IC de niveau 0.90.\n\nc1 &lt;- apply(X,1, function(x) t.test(x,conf.level=0.90)$conf.int[1:2])\nc2 &lt;- as.data.frame(t(c1))\nc2 |&gt; mutate(test=mu&gt;V1 & mu&lt;V2) |&gt; summarize(mean(test))\n##   mean(test)\n## 1      0.898\n\n\n\n\nExercice 8.6 (IC pour les iris de Fisher) On considère les données sur les iris de Fisher. Construire un intervalle de confiance de niveau 90% pour les paramètres suivants :\n\nLa longueur de Pétales moyenne\n\nt.test(iris$Petal.Length,conf.level=0.90)$conf.int\n## [1] 3.519434 3.996566\n## attr(,\"conf.level\")\n## [1] 0.9\n\nLa largeur de Sépales moyenne de l’espèce Setosa\n\nsep_set &lt;- iris |&gt; filter(Species==\"setosa\") |&gt; select(Sepal.Width) \nt.test(sep_set,conf.level=0.90)$conf.int\n## [1] 3.338124 3.517876\n## attr(,\"conf.level\")\n## [1] 0.9\n#ou\niris |&gt; filter(Species==\"setosa\") |&gt; \n  select(Sepal.Width) |&gt; t.test(conf.level=0.9)\n## \n##  One Sample t-test\n## \n## data:  select(filter(iris, Species == \"setosa\"), Sepal.Width)\n## t = 63.946, df = 49, p-value &lt; 2.2e-16\n## alternative hypothesis: true mean is not equal to 0\n## 90 percent confidence interval:\n##  3.338124 3.517876\n## sample estimates:\n## mean of x \n##     3.428\n\nLa largeur de Sépales moyenne des espèces Versicolor et Virginica\n\nsep_vervin &lt;- iris |&gt; filter(Species==\"versicolor\" | Species ==\"virginica\") |&gt; select(Sepal.Width) \nt.test(sep_vervin,conf.level=0.90)$conf.int\n## [1] 2.81675 2.92725\n## attr(,\"conf.level\")\n## [1] 0.9\n\n\n\n\nExercice 8.7 (IC pour une proportion) On considère \\(x_1,\\dots,x_n\\) un échantillon i.i.d issu d’une loi de Bernoulli de paramètre \\(p\\in[0,1]\\) inconnu.\n\nProposer un estimateur \\(\\widehat p\\) pour \\(p\\).\n\nOn peut prendre \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\]\n\nA l’aide du TCL, obtenir la loi asymptotique de \\(\\hat p\\).\n\nOn a d’après la TCL\n\\[\\sqrt{n}\\frac{\\widehat{p}-p}{\\sqrt{p(1-p)}}\\stackrel{\\mathcal L}{\\to}\\mathcal N(0,1)\\]\n\nEn déduire un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(p\\).\n\nOn déduit que \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right].\\]\nest un IC de niveau \\(1-\\alpha\\).\n\nQue pouvez-vous reprocher à l’intervalle proposé à la question précédente ?\n\nL’IC proposé dépend de \\(p\\) qui est inconnu ! Il ne sera donc pas calculable en pratique !\n\nProposer une solution.\n\nUn solution classique consiste à remplacer le paramètre \\(p\\) inconnu par son estimateur \\(\\widehat p\\). On obtient ainsi l’IC \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}\\right].\\]\n\n\n\n\nExercice 8.8 (IC pour une proportion (suite)) Afin de tenter de deviner qui va gagner une élection entre deux candidats \\(A\\) et \\(B\\) on effectue un sondage. On demande à 100 personnes pour qui elles vont voter. Les résultats sont reportés dans le vecteur suivant.\n\nset.seed(12345)\nres &lt;- rbinom(100,1,0.52)\n\nOn désigne par \\(p\\) la propotion (inconnue) d’électeurs qui vont voter pour \\(A\\).\n\nProposer et calculer un estimateur de \\(p\\).\n\nOn peut prendre la moyenne empirique \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\] On la calcule avec\n\n\nphat &lt;- mean(res)\nphat\n## [1] 0.54\n\nQue pouvez-vous conclure a priori.\n\nIl semble que \\(A\\) va remporter l’élection.\n\nEn vous basant sur l’exercice précédent, calculer un intervalle de confiance de niveau 95% pour \\(p\\).\n\nOn le calcule avec\n\n\nn &lt;- length(res)\nbinf &lt;- phat-qnorm(0.975)*sqrt(phat*(1-phat)/n)\nbsup &lt;- phat+qnorm(0.975)*sqrt(phat*(1-phat)/n)\nc(binf,bsup)\n## [1] 0.4423159 0.6376841\n\nEst-ce que l’intervalle obtenu conforte votre conclusion de la question 2 ?\n\nNon, en effet 0.5 se trouve dans l’intervalle de confiance !\n\nCalculer un intervalle de confiance pour \\(p\\) à l’aide de la fonction prop.test.\n\nprop.test(sum(res),n)\n## \n##  1-sample proportions test with continuity correction\n## \n## data:  sum(res) out of n, null probability 0.5\n## X-squared = 0.49, df = 1, p-value = 0.4839\n## alternative hypothesis: true p is not equal to 0.5\n## 95 percent confidence interval:\n##  0.4377639 0.6391280\n## sample estimates:\n##    p \n## 0.54\n\n\nOn remarque que l’IC obtenu ne correspond pas exactement à celui que nous avons calculé à la question 3. La fonction prop.test utilise une solution plus pertinente que de remplacer \\(p\\) par son estimateur. La correction utilisée dans prop.test est plus préciser, il est recommandé d’utiliser celle là.\n\n\n\n\nExercice 8.9 (Comparaison de moyennes) Pour le jeu de données decathlon disponible ici\n\nlibrary(FactoMineR)\ndata(decathlon)\n\non souhaite comparer les performances au 100m en fonction de la compétition (Decastar vs JO).\n\nCalculer un intervalle de confiance de niveau 95% pour la vitesse moyenne au 100m au Decastar.\n\nperf.D &lt;- decathlon |&gt; filter(Competition==\"Decastar\") |&gt; select(`100m`)\nt.test(perf.D)\n## \n##  One Sample t-test\n## \n## data:  perf.D\n## t = 163.64, df = 12, p-value &lt; 2.2e-16\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  11.02659 11.32418\n## sample estimates:\n## mean of x \n##  11.17538\n\nMême question pour les jeux olympiques.\n\nperf.JO &lt;- decathlon |&gt; filter(Competition==\"OlympicG\") |&gt; select(`100m`)\nt.test(perf.JO)\n## \n##  One Sample t-test\n## \n## data:  perf.JO\n## t = 250.02, df = 27, p-value &lt; 2.2e-16\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  10.82613 11.00530\n## sample estimates:\n## mean of x \n##  10.91571\n\nPouvez-vous conclure sur la question posée ? Si non, que faire ?\n\nIl n’est pas possible de conclure. La bonne approche consiste à calculer un intervalle de confiance sur la différence moyenne des performances au 100m entre les deux compétitions et de regarder si 0 se situe dans l’intervalle.\nOn obtient l’intervalle avec\n\n\nt.test(perf.D,perf.JO)\n## \n##  Welch Two Sample t-test\n## \n## data:  perf.D and perf.JO\n## t = 3.2037, df = 22.168, p-value = 0.00407\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  0.09164794 0.42769272\n## sample estimates:\n## mean of x mean of y \n##  11.17538  10.91571\n\n\n0 n’étant pas dans l’intervalle, on conclut que les performances sont différentes. On verra par la suite que les tests d’hypothèses permettent de traiter ce genre de questions de façons plus efficace."
  },
  {
    "objectID": "08-estimation.html#étude-descriptive-et-visualisation",
    "href": "08-estimation.html#étude-descriptive-et-visualisation",
    "title": "8  Estimation et intervalles de confiance",
    "section": "9.1 Étude descriptive et visualisation",
    "text": "9.1 Étude descriptive et visualisation\nOn commence par visualiser l’évolution de la tumeur en fonction du groupe à l’aide d’un boxplot :\n\nggplot(data2)+aes(x=as.factor(day_num),y=Volume,color=groupe)+\n  geom_boxplot()+xlab(\"Day\")\n\n\n\n\nIl semble que les évolutions soient différentes, notamment pour le groupe contrôle.\nOn effectue maintenant une Anova pour tester l’effet groupe. Les répétitions portant sur le temps (et non sur les groupes), on fait l’ANOVA à deux facteurs avec (voir https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-m-modmixt7-mesrepet.pdf)\n\ngroupe comme effet inter\nDay comme effet intra\n\n\nlibrary(rstatix)\nres.aov &lt;- anova_test(\n  data = data2, dv = Volume, wid = Id,\n  between = groupe,\n  within = Day\n)\nget_anova_table(res.aov)\n## ANOVA Table (type III tests)\n## \n##       Effect  DFn   DFd      F        p p&lt;.05   ges\n## 1     groupe 3.00 45.00  6.123 1.00e-03     * 0.155\n## 2        Day 1.22 54.76 75.359 4.41e-13     * 0.480\n## 3 groupe:Day 3.65 54.76  7.100 1.72e-04     * 0.207\n\nL’interaction est significative.\nOn peut aller un peu plus loin avec les tests post hoc. Par exemple, pour l’effet groupe à chaque pas de temps :\n\none.way &lt;- data2 |&gt; \n  group_by(day_num) |&gt;\n  anova_test(dv = Volume, wid = Id, between = groupe) |&gt;\n  get_anova_table() |&gt;\n  adjust_pvalue(method = \"bonferroni\")\none.way |&gt; as_tibble() |&gt; \n  arrange(day_num) |&gt; DT::datatable() \n\n\n\n\n\n\nLe groupe devient “de plus en plus significatif” lorsque le temps augmente (y compris avec la correction de Bonferonni).\nOn regarde maintenant les comparaisons par paires :\n\npwc &lt;- data2 |&gt;\n  group_by(Day) |&gt;\n  pairwise_t_test(\n    Volume ~ groupe,\n    p.adjust.method = \"bonferroni\"\n  )\nDT::datatable(pwc)\n\n\n\n\n\npwc |&gt; filter(p.signif!=\"ns\" | p.adj.signif!=\"ns\") |&gt; arrange(p)\n## # A tibble: 34 × 10\n##    Day   .y.    group1 group2     n1    n2       p p.signif   p.adj p.adj.signif\n##    &lt;fct&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n##  1 J56   Volume \"CTL \" \"EPA E…    13    14 1.83e-4 ***      0.0011  **          \n##  2 J56   Volume \"CTL \" \"EPA \"     13    13 2.22e-4 ***      0.00133 **          \n##  3 J56   Volume \"CTL \" \"ET \"      13    13 3.57e-4 ***      0.00214 **          \n##  4 J50   Volume \"CTL \" \"EPA E…    13    14 3.71e-4 ***      0.00222 **          \n##  5 J54   Volume \"CTL \" \"EPA \"     13    13 3.71e-4 ***      0.00223 **          \n##  6 J50   Volume \"CTL \" \"EPA \"     13    13 4   e-4 ***      0.0024  **          \n##  7 J54   Volume \"CTL \" \"EPA E…    13    14 5.2 e-4 ***      0.00312 **          \n##  8 J54   Volume \"CTL \" \"ET \"      13    13 6.59e-4 ***      0.00395 **          \n##  9 J48   Volume \"CTL \" \"EPA E…    13    14 8.99e-4 ***      0.00539 **          \n## 10 J50   Volume \"CTL \" \"ET \"      13    13 1.08e-3 **       0.00651 **          \n## # ℹ 24 more rows\n\nLe groupe CTL se retrouve fréquemment dans les comparaisons significatives."
  },
  {
    "objectID": "08-estimation.html#modèle-mixte",
    "href": "08-estimation.html#modèle-mixte",
    "title": "8  Estimation et intervalles de confiance",
    "section": "9.2 Modèle mixte",
    "text": "9.2 Modèle mixte\nLes données étant répétées dans le temps, on ne peut pas utiliser un modèle linéaire classique. Il faut dans ce cas entraîner un modèle mixte qui va pouvoir prendre en compte les effets individuels :\nAprès plusieurs essais et comparaisons de modèle, on retient le modèle avec\n\ncomme effet fixe : le temps au carré et l’interaction temps au carré vs groupe.\ncomme effet aléatoire : la constante et le temps au carré.\n\n\nlibrary(nlme)\nm1 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          data=data2,na.action=na.omit)\n\nAnova(m1,type=3)\n## Analysis of Deviance Table (Type III tests)\n## \n## Response: Volume\n##                      Chisq Df Pr(&gt;Chisq)    \n## (Intercept)         17.050  1  3.641e-05 ***\n## I(day_num^2)        81.249  1  &lt; 2.2e-16 ***\n## I(day_num^2):groupe 20.854  3  0.0001129 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nOn retrouve bien que l’interaction est significative. Au niveau des paramètres du modèle on a :\n\nsummary(m1)\n## Linear mixed-effects model fit by REML\n##   Data: data2 \n##        AIC      BIC    logLik\n##   10249.63 10288.87 -5116.813\n## \n## Random effects:\n##  Formula: ~1 + I(day_num^2) | Id\n##  Structure: Diagonal\n##         (Intercept) I(day_num^2) Residual\n## StdDev:    27.17808   0.06523892 32.77535\n## \n## Fixed effects:  Volume ~ 1 + I(day_num^2) + I(day_num^2):(groupe) \n##                                 Value Std.Error  DF   t-value p-value\n## (Intercept)                -16.831664  4.076271 946 -4.129182   0e+00\n## I(day_num^2)                 0.164154  0.018211 946  9.013850   0e+00\n## I(day_num^2):groupeEPA      -0.098116  0.025751 946 -3.810174   1e-04\n## I(day_num^2):groupeET       -0.092033  0.025751 946 -3.573908   4e-04\n## I(day_num^2):groupeEPA ET   -0.096512  0.025287 946 -3.816676   1e-04\n##  Correlation: \n##                            (Intr) I(d_^2) I(_^2):EP I(_^2):ET\n## I(day_num^2)               -0.018                            \n## I(day_num^2):groupeEPA      0.000 -0.707                     \n## I(day_num^2):groupeET       0.000 -0.707   0.500             \n## I(day_num^2):groupeEPA ET   0.000 -0.720   0.509     0.509   \n## \n## Standardized Within-Group Residuals:\n##          Min           Q1          Med           Q3          Max \n## -5.702141384 -0.381625266  0.002515069  0.372061286  8.789202686 \n## \n## Number of Observations: 1003\n## Number of Groups: 53\n\nTous les coefficients de l’interaction sont significatifs et négatifs. Cela signifie que, le volume augmente moins vite avec de l’entraînement et du régime. On peut regarder ce qui se passe en changeant le groupe de référence :\n\ngroupe EPA :\n\nm2 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=2)),\n          data=data2,na.action=na.omit)\nsummary(m2)$tTable |&gt; round(4)\n##                               Value Std.Error  DF t-value p-value\n## (Intercept)                -16.8317    4.0763 946 -4.1292  0.0000\n## I(day_num^2)                 0.0660    0.0182 946  3.6261  0.0003\n## I(day_num^2):groupeCTL       0.0981    0.0258 946  3.8102  0.0001\n## I(day_num^2):groupeET        0.0061    0.0258 946  0.2362  0.8133\n## I(day_num^2):groupeEPA ET    0.0016    0.0253 946  0.0634  0.9494\n\ngroupe ET :\n\nm3 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=3)),\n          data=data2,na.action=na.omit)\nsummary(m3)$tTable |&gt; round(4)\n##                               Value Std.Error  DF t-value p-value\n## (Intercept)                -16.8317    4.0763 946 -4.1292  0.0000\n## I(day_num^2)                 0.0721    0.0182 946  3.9600  0.0001\n## I(day_num^2):groupeCTL       0.0920    0.0258 946  3.5739  0.0004\n## I(day_num^2):groupeEPA      -0.0061    0.0258 946 -0.2362  0.8133\n## I(day_num^2):groupeEPA ET   -0.0045    0.0253 946 -0.1771  0.8595\n\ngroupe EPA - ET :\n\nm4 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=4)),\n          data=data2,na.action=na.omit)\nsummary(m4)$tTable |&gt; round(4)\n##                            Value Std.Error  DF t-value p-value\n## (Intercept)             -16.8317    4.0763 946 -4.1292  0.0000\n## I(day_num^2)              0.0676    0.0175 946  3.8543  0.0001\n## I(day_num^2):groupeCTL    0.0965    0.0253 946  3.8167  0.0001\n## I(day_num^2):groupeEPA   -0.0016    0.0253 946 -0.0634  0.9494\n## I(day_num^2):groupeET     0.0045    0.0253 946  0.1771  0.8595\n\n\nÀ chaque fois le groupe CTL se distingue. Il est difficile d’établir des différences significatives entre les autres groupes. On peut enfin visualiser les effets fixes :\n\naa &lt;- predict(m1,data2,level=0:1)\ndata3 &lt;- data2 |&gt; \n  mutate(prev=aa$predict.Id) |&gt; \n  group_by(groupe,day_num) |&gt; \n  summarize(moy=mean(prev))\nggplot(data3)+aes(x=day_num,y=moy,color=groupe)+geom_line()+geom_point()"
  },
  {
    "objectID": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "href": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "title": "9  Régression avec R",
    "section": "9.1 Modèle linéaire : fonctions lm et predict",
    "text": "9.1 Modèle linéaire : fonctions lm et predict\n\nExercice 9.1 (Fonctions standards pour le modèle linéaire) On considère le modèle de régression linéaire \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] où \\(X_1,\\dots,X_p\\) sont les variables explicatives, \\(Y\\) la variable à expliquer et \\(\\varepsilon\\) le terme d’erreur. On fixe \\(p=5\\) et on considère les données suivantes :\n\nn &lt;- 1000\np &lt;- 5\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nConstruire un modèle linéaire permettant d’expliquer \\(Y\\) par \\(X_1,\\dots,X_5\\) (utiliser la fonction lm) et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_5\\) (on pourra utiliser les fonctions coef et summary).\n\nmod1 &lt;- lm(Y~.,data=df)\ncoef(mod1)\n## (Intercept)          X1          X2          X3          X4          X5 \n##   0.0228707   1.0111903   1.0000752   1.0034085   1.0071250   0.9962842\nsummary(mod1)\n## \n## Call:\n## lm(formula = Y ~ ., data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.44876 -0.33840 -0.00769  0.33308  1.76883 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.02287    0.01543   1.482    0.139    \n## X1           1.01119    0.01550  65.258   &lt;2e-16 ***\n## X2           1.00008    0.01575  63.479   &lt;2e-16 ***\n## X3           1.00341    0.01524  65.829   &lt;2e-16 ***\n## X4           1.00712    0.01552  64.908   &lt;2e-16 ***\n## X5           0.99628    0.01589  62.702   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4872 on 994 degrees of freedom\n## Multiple R-squared:  0.9556, Adjusted R-squared:  0.9554 \n## F-statistic:  4279 on 5 and 994 DF,  p-value: &lt; 2.2e-16\n\nOn considère le jeu de données test suivant.\n\nm &lt;- 500\np &lt;- 5\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=5)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nCalculer, pour chaque individu de ce nouveau jeu de données, les prédictions faites par le modèle de la question précédente (utiliser la fonction predict avec l’option newdata).\n\npred &lt;- predict(mod1,newdata=df.test)\nhead(pred)\n##           1           2           3           4           5           6 \n##  0.09630147 -1.25027415 -0.52549286  0.19569041  3.72923032 -5.79419545\n\nCréer un nouveau dataframe qui contiennent les valeurs prédites \\(\\widehat y_i\\) à la question précédente sur une colonne et les valeurs observées \\(y_i\\) du jeu de données df.test sur une autre colonne.\n\npred.df &lt;- data.frame(pred=pred,obs=df.test$Y)\n\nA l’aide du verbe summarize, calculer l’erreur quadratique moyenne (estimée) du modèle linéaire : \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2.\\]\n\npred.df |&gt; summarize(MSE=mean((pred-obs)^2))\n##         MSE\n## 1 0.2326355"
  },
  {
    "objectID": "09-regression.html#sélection-de-variables",
    "href": "09-regression.html#sélection-de-variables",
    "title": "9  Régression avec R",
    "section": "9.2 Sélection de variables",
    "text": "9.2 Sélection de variables\n\nExercice 9.2 (Sélection de variables) On considère les données suivantes\n\nn &lt;- 1000\np &lt;- 105\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nissues du modèle \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] avec \\(p=105\\). On remarquera que seules les variables \\(X_1,\\dots,X_5\\) sont explicatives.\n\nAjuster un modèle linéaire (fonction lm) sur df et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_{105}\\).\n\nmod2 &lt;- lm(Y~.,data=df)\nsummary(mod2)$coefficients |&gt; head()\n##                Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) -0.01307274 0.01660197 -0.787421  4.312441e-01\n## X1           0.98461851 0.01656206 59.450240 7.137528e-313\n## X2           0.99625236 0.01668382 59.713691 3.032293e-314\n## X3           1.01858539 0.01628043 62.565035  0.000000e+00\n## X4           1.00691542 0.01643050 61.283315 2.371515e-322\n## X5           1.00752931 0.01718708 58.621324 1.561036e-308\n\nOn propose d’utiliser une procédure de sélection de variables backward à partir du critère BIC. Effectuer cette procédure à l’aide de la fonction step (on pourra utiliser les options direction=“backward” et k=log(n)). On appellera ce modèle mod.step.\n\nmod.step &lt;- step(mod2,direction=c(\"backward\"),k=log(n),trace=0)\nsummary(mod.step)\n## \n## Call:\n## lm(formula = Y ~ X1 + X2 + X3 + X4 + X5 + X29 + X69 + X74, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.63923 -0.34301  0.00179  0.32041  1.45661 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -0.002413   0.015749  -0.153  0.87828    \n## X1           0.992339   0.015807  62.777  &lt; 2e-16 ***\n## X2           0.991358   0.016097  61.588  &lt; 2e-16 ***\n## X3           1.010115   0.015562  64.907  &lt; 2e-16 ***\n## X4           1.006043   0.015830  63.552  &lt; 2e-16 ***\n## X5           1.008520   0.016242  62.093  &lt; 2e-16 ***\n## X29         -0.043358   0.015158  -2.860  0.00432 ** \n## X69          0.042714   0.015292   2.793  0.00532 ** \n## X74         -0.043792   0.016118  -2.717  0.00670 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4969 on 991 degrees of freedom\n## Multiple R-squared:  0.954,  Adjusted R-squared:  0.9537 \n## F-statistic:  2571 on 8 and 991 DF,  p-value: &lt; 2.2e-16\n\n\nOn a sélectionné un modèle avec 8 variables : les 5 explicatives et 3 variables de bruit.\n\nCalculer les erreurs quadratiques de prévision \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2\\] des deux modèles (le modèle complet et le modèle sélectionné) en utilisant le jeu de données test suivant.\n\nm &lt;- 300\np &lt;- 105\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=p)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nOn calcule les prévisions et on les intègre dans un tibble :\n\n\np.full &lt;- predict(mod2,newdata=df.test)\np.step &lt;- predict(mod.step,newdata=df.test)\npred.df &lt;- tibble(full=p.full,step=p.step,obs=df.test$Y)\n\n\nOn en déduit les erreurs quadratiques moyennes :\n\n\npred.df |&gt; summarize(MSE.full=mean((full-obs)^2),MSE.step=mean((step-obs)^2))\n## # A tibble: 1 × 2\n##   MSE.full MSE.step\n##      &lt;dbl&gt;    &lt;dbl&gt;\n## 1    0.300    0.254\n#ou\npred.df |&gt; summarize_at(1:2,~(mean((.-obs)^2)))\n## # A tibble: 1 × 2\n##    full  step\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1 0.300 0.254"
  },
  {
    "objectID": "09-regression.html#régression-logistique-et-arbre",
    "href": "09-regression.html#régression-logistique-et-arbre",
    "title": "9  Régression avec R",
    "section": "9.3 Régression logistique et arbre",
    "text": "9.3 Régression logistique et arbre\n\nExercice 9.3 On considère le jeu de données spam disponible ici\n\nlibrary(kernlab)\ndata(spam)\n\nLe problème est d’expliquer la variable type (un email est un spam ou non) par les 57 autres variables.\n\nSéparer les données en un échantillon d’apprentissage dapp de taille 3000 et un échantillon test dtest de taille 1601. On pourra utiliser la fonction sample.\n\nset.seed(4321)\nperm &lt;- sample(nrow(spam),3000)\ndapp &lt;- spam[perm,]\ndtest &lt;- spam[-perm,]\n\nConstruire un modèle logistique permettant de répondre au problème en utilisant uniquement les données d’apprentissage. On utilisera la fonction glm avec l’option family=\"binomial\".\n\nm.logit &lt;- glm(type~.,data=dapp,family=\"binomial\")\n\nA l’aide de la fonction step, effectuer une sélection backward (ça peut prendre quelques minutes).\n\nm.step &lt;- step(m.logit,direction=\"backward\",trace=0)\n\nA l’aide de la fonction rpart du package rpart, construire un arbre de régression (toujours sur les données d’apprentissage) pour répondre au problème. On utilisera les paramètres par défaut de la fonction.\n\nlibrary(rpart)\narbre &lt;- rpart(type~.,data=dapp)\n\nVisualiser l’arbre construit à l’aide des fonctions rpart.plot et visTree des packages rpart.plot et visNetwork\n\nlibrary(rpart.plot)\nrpart.plot(arbre)\n\n\n\nlibrary(visNetwork)\nvisTree(arbre)\n\n\n\n\n\nPour les 3 modèles construits (logistique, backward et arbre) calculer les prédictions de la variable type pour les individus de l’échantillon dtest. On pourra regrouper ces prévisions dans un data-frame à 3 colonnes.\n\nprev &lt;- data.frame(\n  logit=predict(m.logit,newdata=dtest,type=\"response\") |&gt; round() |&gt; recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n  step=predict(m.step,newdata=dtest,type=\"response\") |&gt; round() |&gt; recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n  arbre=predict(arbre,newdata=dtest,type=\"class\"))\n\nAjouter au data-frame précédent une colonne où on mettra les valeurs observées de la variable à expliquer.\n\nprev1 &lt;- prev |&gt; mutate(obs=dtest$type)\n\nA l’aide de summarize_at calculer les erreurs de classification des 3 modèles.\n\nprev1 |&gt; summarize_at(1:3,~(mean(obs!=.))) |&gt; round(3)\n##   logit  step arbre\n## 1  0.07 0.074 0.109\n\nReprésenter les courbes ROC et calculer les AUC. On pourra consulter les pages 346 et 347 dans Cornillon et al. (2018) pour le tracé de courbes ROC sur R.\n\nscore &lt;- data.frame(\n  logit=predict(m.logit,newdata=dtest,type=\"response\"),\n  step=predict(m.step,newdata=dtest,type=\"response\"),\n  arbre=predict(arbre,newdata=dtest,type=\"prob\")[,2]) |&gt; \n  mutate(obs=dtest$type) |&gt; \n  pivot_longer(-obs,names_to = \"Methode\",values_to=\"score\")\n\n\nlibrary(plotROC)\nggplot(score)+aes(d=obs,m=score,color=Methode)+geom_roc()+theme_classic()\n\n\n\n\n\nscore |&gt; group_by(Methode) |&gt; \n  summarize(AUC=as.numeric(pROC::auc(obs,score))) |&gt; \n  mutate(AUC=round(AUC,3)) |&gt;\n  arrange(desc(AUC))\n## # A tibble: 3 × 2\n##   Methode   AUC\n##   &lt;chr&gt;   &lt;dbl&gt;\n## 1 logit   0.975\n## 2 step    0.975\n## 3 arbre   0.894\n\n\n\n\n\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Références",
    "section": "",
    "text": "Barnier, J. 2020. Introduction à r Et Au Tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N.\nKlutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, and B.\nThieurmel. 2018. R Pour La Statistique Et La Science Des\nDonnées. PUR. https://r-stat-sc-donnees.github.io.\n\n\nWickham, A., and G. Grolemund. 2017. R for Data Science.\nO’Reilly. https://r4ds.had.co.nz."
  }
]