[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualisation avec R",
    "section": "",
    "text": "Présentation\nCe tutoriel présente une introduction au logiciel R ainsi qu’à quelques outils de visualisation avec R. On pourra trouver :\n\nles supports de cours associés à ce tutoriel ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html ;\nle tutoriel sans les corrections à l’url https://lrouviere.github.io/TUTO_VISU_R/\nle tutoriel avec les corrigés (à certains moments) à l’url https://lrouviere.github.io/TUTO_VISU_R/correction/.\n\nIl est recommandé d’utiliser mozilla firefox pour lire le tutoriel.\nLes thèmes suivants sont abordés :\n\nLogiciel R\n\nPrésentation du logiciel, environnement Rstudio, reporting avec quarto et Rmarkdown\nObjets R\nManipulation des données (essentiellement avec dplyr)\n\nVisualisation\n\nVisualisation statique (représentations standards et avec ggplot2)\nCartographie\n\nstatique avec ggmap et sf\ndynamiques avec leaflet\n\nVisualisation dynamique\n\ngraphes standards avec RamChartset plotly\nréseaux avec visNetwork\ntableaux de bord avec flexdashboard\n\n\nUn peu de statistique avec R\n\nRégression : ajustement de modèles, formules, prévisions…\nIntroduction au problème de l’estimation, lois de probabilités, notions d’estimateurs, performance d’estimateurs, intervalles de confiance.\n\n\nOn pourra trouver des supports de cours ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html. Des compléments sur les outils du tidyverse pourront être consultés dans le très complet document de Barnier (2020) ainsi que les ouvrages de Wickham et Grolemund (2017) et de Cornillon et al. (2018).\n\n\n\n\nBarnier, J. 2020. Introduction à R et au tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io.\n\n\nWickham, A., et G. Grolemund. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz."
  },
  {
    "objectID": "01-intro.html#r-script",
    "href": "01-intro.html#r-script",
    "title": "1  Introduction",
    "section": "1.1 R Script",
    "text": "1.1 R Script\nIl existe différentes façons de travailler sur RStudio. De façon classique, on peut\n\nouvrir un script.\nentrer les commandes dans le script.\nregarder les sorties dans la console (en cliquant sur le bouton run).\nsauver le script."
  },
  {
    "objectID": "01-intro.html#packages",
    "href": "01-intro.html#packages",
    "title": "1  Introduction",
    "section": "1.2 Packages",
    "text": "1.2 Packages\nUn package est une ensemble de programmes et fonctions R qui complètent les fonctions existantes par défaut dans le logiciel. Un package est généralement dédié à une méthode ou un champ d’application spécifique. Il existe plus de 18 000 packages disponibles sur le CRAN https://cran.r-project.org. On installe un package en\n\nutilisant le fonction install.packages dans la console. ou\nou cliquant sur le bouton Packages.\n\nUne fois le package installé sur la machine, on l’installe avec la fonction library :\n\ninstall.packages(package.name)\nlibrary(packages.name)\n\n\nExercice 1.1 (Installation et chargement) \n\n\nExécuter\n\niris |&gt; summarize(mean_Petal=mean(Petal.Length))\n\nQue se passe t-il ?\n\nOn a un message d’erreur. L’opérateur |&gt; n’est pas reconnu.\n\nInstaller et charger le package tidyverse et ré-exécuter le code précédent."
  },
  {
    "objectID": "01-intro.html#quarto",
    "href": "01-intro.html#quarto",
    "title": "1  Introduction",
    "section": "1.3 Quarto",
    "text": "1.3 Quarto\nQuarto est un langage, compatible avec notamment R et Python, qui permet de créer différents types de documents :\n\nrapports au format pdf ou rtf\npages web html\ndiaporama pour des présentations (html, beamer, PowerPoint…)\napplications web interactives\n…\n\nqui comportent du code R.\n\n1.3.1 Syntaxe\nLa syntaxe s’apprend assez facilement (il faut pratiquer), on pourra trouver un descriptif synthétique sur la page https://quarto.org ainsi que dans la cheatsheet dédiée à Rmarkdown puisque quarto est compatible avec markdown. Par exemple :\n\nCaractère en italique ou gras : *italique* et **gras** donne italique et gras\nListes non ordonnées\n- item 1\n- item 2\nproduit\n\nitem 1\nitem 2\n\nliste ordonnée :\n1. item 1\n2. item 2\nproduit\n\nitem 1\nitem 2\n\ntableau :\n|      | Col1 | Col2 | Col3 |\n|:----:|:----:|:----:|:----:|\n| Row1 |  1   |   2  |   3  |\n| Row2 |  1   |   2  |   3  |\nrenvoie\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nRow1\n1\n2\n3\n\n\nRow2\n1\n2\n3\n\n\n\n\néquation latex :\n$$\\int_a^b f(x)dx=1$$\nrenvoie \\[\\int_a^b f(x)dx=1\\]\n\n\n\n1.3.2 Les chunks\nLe code R doit être écrit dans des chunks. On peut insérer des chunks avec :\n\nla raccourci clavier Ctrl + Alt + I (OS X: Cmd + Option + I)\nla bouton Insert -&gt; Code Chunk -&gt; R\nen tapant :\n\n```{r}\ncommandes...\n```\nPlusieurs options peuvent être spécifiés au chunk en fonction de ce que l’on souhaite voir dans le document, par exemple :\n\necho : TRUEor FALSE pour spécifier si on souhaite afficher le code ;\neval : TRUEor FALSE pour spécifier si le code doit être évalusé ou non ;\nresults : hide si on ne veut pas voir la sortie du code.\n\nOn pourra trouver l’ensemble des options disponibles sur cette page : https://yihui.org/knitr/options/\n\nExercice 1.2 (Premier document) \n\n\nOuvrir un document quarto (File -&gt; New File -&gt; Quarto Document).\nCliquer sur le bouton Render et visualiser la sortie html.\nObtenir une sortie pdf.\nModifier le document en créant une section Cosinus dans laquelle on tracera la fonction cosinus, on pourra utiliser le code suivant dans un chunk.\n\nx &lt;- seq(-2*pi,2*pi,by=0.01)\ny &lt;- cos(x)\nplot(x,y,type=\"l\")\n\nAjouter une section Sinus dans laquelle on tracera la fonction sinus.\n\n\n\n\n1.3.3 Notebook\nL’environnement notebook fonctionne exactement comme un document markdown mais permet de visualiser la sortie eu format html sans avoir à recompiler le document en entier. Cet environnement est donc souvent privilégié pendant la réalisation d’un projet en science des données. Pour créer un notebook, on peut passer par RStudio : File -&gt; New File -&gt; R Notebook ou simplement remplacer\noutput: html_document\npar\noutput: html_notebook\ndans l’entête d’un document markdown.\n\nTransformer le document markdown de l’exercice précédent en notebook. On pourra visualier la sortie en cliquant sur Preview.\n\n\n\n1.3.4 Diaporama R\nRstudio propose aussi différents environnements pour construire des diaporamas. On pourra utiliser le menu File -&gt; New File -&gt; Quarto Presentation . On utilisera la même syntaxe que pour les documents markdown. Les slides sont séparés par le symbole ## et les codes R sont toujours insérés dans des chunks.\n\nExercice 1.3 (Premier document)  \n\nCréer 2 diapositives :\n\nTitre : Cosinus où on tracera la fonction cosinus.\nTitre : Sinus où on tracera la fonction sinus.\n\nEn modifiant les options des chunks modifier les diapositives de manière à\n\nne pas voir le code R mais voir les graphiques\nvoir uniquement le code R mais pas les graphiques.\n\n\n\n\n\n1.3.5 Exemples de styles de documents Quarto\nPar défaut l’entête d’un document quarto est de la forme\n---\ntitle: \"Mon document\"\nauthor: \"Laurent\"\nformat: html\neditor: visual\n---\nIl existe un grand nombre d’options qui permettent d’améliorer le document final. On peut par exemple changer la langue et ajouter une table des matières avec\nlang: fr\ntoc: true\nOn peut également utiliser des styles prédéfinis en changeant le thème, par exemple\ntheme: cerulean\n\n\n\n\n\nOn pourra trouver des compléments sur les différents styles et options ici : https://quarto.org/docs/output-formats/html-themes.html#navigation."
  },
  {
    "objectID": "02-objetsR.html#création-dobjets",
    "href": "02-objetsR.html#création-dobjets",
    "title": "2  Les objets R",
    "section": "2.1 Création d’objets",
    "text": "2.1 Création d’objets\n\n2.1.1 Numérique\nOn crée un objet R en assignant une valeur (ou un caractère, vecteur…) avec les opérateurs &lt;-, -&gt;, =\n\nb &lt;- 41.3  # assigne la valeur 41.3 à l'objet b\nx &lt;- b     # b est assigné à x\nx = b      # b est assigné à x\nb -&gt; x     # b est assigné à x\nis.numeric(b)\n## [1] TRUE\nmode(b)\n## [1] \"numeric\"\n\n\n\n2.1.2 Caractère\nLes chaines de caractères sont définies avec des guillemets : \"chaine\", par exemple\n\nx &lt;- \"La mort\"\ny &lt;- \"aux trousses\"\npaste(x,y)\n## [1] \"La mort aux trousses\"\nis.character(x)\n## [1] TRUE\n\n\n\n2.1.3 Facteur\nL’objet facteur est très utile pour travailler avec des variables qualitatives. Cet objet permet d’identifier les modalités prisent par la variable et de travailler dessus, en changeant par exemple le nom d’une modalité :\n\nV1 &lt;- factor(c(\"less20years\",\"more50years\",\"less20years\",\"more50years\",\"less20years\"))\nV1\n## [1] less20years more50years less20years more50years less20years\n## Levels: less20years more50years\nlevels(V1)\n## [1] \"less20years\" \"more50years\"\nlevels(V1) &lt;- c(\"Young\",\"Old\")\nV1\n## [1] Young Old   Young Old   Young\n## Levels: Young Old\n\n\n\n2.1.4 Logique (Booléen)\n\nx &lt;- TRUE\nis.logical(x)\n## [1] TRUE\nmode(x)\n## [1] \"logical\"\na &lt;- 1\na==1\n## [1] TRUE\na!=1\n## [1] FALSE\na&lt;0\n## [1] FALSE\na&gt;0\n## [1] TRUE"
  },
  {
    "objectID": "02-objetsR.html#vecteur",
    "href": "02-objetsR.html#vecteur",
    "title": "2  Les objets R",
    "section": "2.2 Vecteur",
    "text": "2.2 Vecteur\nOn peut définir un vecteur de plusieurs façons :\n\nfonction collect c\n\nx &lt;- c(1.2,5,9,11)\nx\n## [1]  1.2  5.0  9.0 11.0\n\nopérateur séquence :\n\n1:5\n## [1] 1 2 3 4 5\n\nfonction séquence seq\n\nseq(1,10,by=2)\n## [1] 1 3 5 7 9\nseq(0,1,length=10)\n##  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n##  [8] 0.7777778 0.8888889 1.0000000\n\nfonction rep\n\nrep(1,4)\n## [1] 1 1 1 1\nrep(c(1,3),each=3)\n## [1] 1 1 1 3 3 3\n\n\nOn peut aussi créer des vecteurs caractère ou logique\n\nx &lt;- c(\"A\",\"B\",\"C\")\nx &lt;- rep(\"A\",5)\npaste(\"X\",1:5,sep=\"-\")\n## [1] \"X-1\" \"X-2\" \"X-3\" \"X-4\" \"X-5\"\nsubstr(\"statistician\",5,9)\n## [1] \"istic\"\n\n\nc(T,F,T)\n## [1]  TRUE FALSE  TRUE\n\n\n2.2.1 Sélectionner une partie d’un vecteur\nLa sélection s’effectue à l’aide de crochets [ ]\n\nx &lt;- c(-4,-3,1,3,5,8,0)\nx[2]\n## [1] -3\nx[c(2,5)]\n## [1] -3  5\nx&gt;0\n## [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE\nx[x&gt;0]\n## [1] 1 3 5 8\n\n\n\n2.2.2 Opérations sur les vecteurs\nOn peut facilement additionner, multiplier des vecteurs :\n\nx &lt;- seq(-10,10,by=2)\ny &lt;- 1:length(x)\nx+y\n##  [1] -9 -6 -3  0  3  6  9 12 15 18 21\nx*y\n##  [1] -10 -16 -18 -16 -10   0  14  32  54  80 110\nz &lt;- x&gt;0\nx*z\n##  [1]  0  0  0  0  0  0  2  4  6  8 10\n\n\nExercice 2.1 (Manipulation de vecteurs) On s’intéresse à des fonctions classiques permettant de manipuler des vecteurs.\n\nCalculer la moyenne, la somme, la médiane et la variance du vecteur (1,3,8,9,11).\nCréer les vecteurs suivants en utilisant la fonction rep.\nvec1 = 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 \nvec2 = 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\nvec3 = 1 1 2 2 2 3 3 3 3 4 4 4 4 4\nCréer le vecteur suivant à l’aide de la fonction paste, puis avec la fonction str_c.\nvec4 = \"A0)\" \"A1)\" \"A2)\" \"A3)\" \"A4)\" \"A5)\" \"A6)\" \"A7)\" \"A8)\" \"A9)\" \"A10)\"\nletters est un vecteur qui contient les 26 lettres de l’alphabet.\n\nTrouver le numéro de la lettre \\(q\\) (sans compter “avec les doigts” !). On pourra utiliser la fonction which ou str_which.\n\n\n\nCréer le vecteur “a1”,“b2”,\\(\\dots\\) jusqu’à \\(q\\) et son index."
  },
  {
    "objectID": "02-objetsR.html#matrices",
    "href": "02-objetsR.html#matrices",
    "title": "2  Les objets R",
    "section": "2.3 Matrices",
    "text": "2.3 Matrices\nLa fonction matrix permet de définir des matrices.\n\nm &lt;- matrix(1:4,ncol=2)\nm\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nm &lt;- matrix(1:4,nrow=2)\nm\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nm &lt;- matrix(1:4,nrow=2,byrow=TRUE)\ndim(m)\n## [1] 2 2\n\nLa position d’un élément dans une matrice est indiquée par ses numéros de ligne et de colonne. Ainsi, pour sélectionner le terme de la 2ème ligne et la 1ère colonne, on utilisera\n\nm[2,1]\n## [1] 3\n\nOn peut aussi extraire des lignes et des colonnes :\n\nm[1,] #première ligne\n## [1] 1 2\nm[,2] #deuxième colonne\n## [1] 2 4\n\nIl n’est pas difficile de faire les calculs usuels sur les matrices :\n\ndet(m) #déterminant\n## [1] -2\nsolve(m) #inverse\n##      [,1] [,2]\n## [1,] -2.0  1.0\n## [2,]  1.5 -0.5\nt(m) #transposé\n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nn &lt;- matrix(5:8,nrow=2)\nm+n\n##      [,1] [,2]\n## [1,]    6    9\n## [2,]    9   12\nm*n #attention : produit de Hadamart\n##      [,1] [,2]\n## [1,]    5   14\n## [2,]   18   32\nm%*%n #Produit matriciel\n##      [,1] [,2]\n## [1,]   17   23\n## [2,]   39   53\neigen(m) #Décomposition en valeurs propres\n## eigen() decomposition\n## $values\n## [1]  5.3722813 -0.3722813\n## \n## $vectors\n##            [,1]       [,2]\n## [1,] -0.4159736 -0.8245648\n## [2,] -0.9093767  0.5657675"
  },
  {
    "objectID": "02-objetsR.html#listes",
    "href": "02-objetsR.html#listes",
    "title": "2  Les objets R",
    "section": "2.4 Listes",
    "text": "2.4 Listes\nUne liste est un objet hétérogène. Elle permet de stocker des objets de différents modes dans un même objet. Par exemple, on peut céer une liste qui contient un vecteur et une matrice à l’aide de\n\nmylist &lt;- list(vector=rep(1:5),mat=matrix(1:8,nrow=2))\nmylist\n## $vector\n## [1] 1 2 3 4 5\n## \n## $mat\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8\nlength(mylist)\n## [1] 2\n\nL’extraction s’effectue en indiquant la position de l’objet à extraire dans un double crochet [[  ]] :\n\nmylist[[1]]\n## [1] 1 2 3 4 5\n\nOn peut aussi utiliser le nom de l’élément à extraire :\n\nmylist$mat\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8\nmylist[[\"mat\"]]\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    3    5    7\n## [2,]    2    4    6    8"
  },
  {
    "objectID": "02-objetsR.html#dataframe",
    "href": "02-objetsR.html#dataframe",
    "title": "2  Les objets R",
    "section": "2.5 Dataframe",
    "text": "2.5 Dataframe\nLes dataframes sont des listes particulières dont les composantes ont la même longueur, mais potentiellement des modes différents. C’est l’objet généralement utilisé pour les tableaux de données (qui contiennent souvent des variables quantitatives et qualitatives). Par exemple,\n\nname &lt;- c(\"Paul\",\"Mary\",\"Steven\",\"Charlotte\",\"Peter\")\nsex &lt;- factor(c(\"M\",\"F\",\"M\",\"F\",\"M\"))\nsize &lt;- c(180,165,168,170,175)\ndata &lt;- data.frame(name,sex,size)\nsummary(data)\n##      name           sex        size      \n##  Length:5           F:2   Min.   :165.0  \n##  Class :character   M:3   1st Qu.:168.0  \n##  Mode  :character         Median :170.0  \n##                           Mean   :171.6  \n##                           3rd Qu.:175.0  \n##                           Max.   :180.0\n\nOn observe que name est un vecteur de caractères, sex un facteur et size un vecteur numérique.\nL’extraction est similaire aux matrices et aux listes :\n\ndata[2,3]\n## [1] 165\ndata[,2]\n## [1] M F M F M\n## Levels: F M\ndata$sex\n## [1] M F M F M\n## Levels: F M"
  },
  {
    "objectID": "02-objetsR.html#quelques-fonctions-importantes",
    "href": "02-objetsR.html#quelques-fonctions-importantes",
    "title": "2  Les objets R",
    "section": "2.6 Quelques fonctions importantes",
    "text": "2.6 Quelques fonctions importantes\n\nsummary produit un résumé d’un objet\n\nsummary(data)\n##      name           sex        size      \n##  Length:5           F:2   Min.   :165.0  \n##  Class :character   M:3   1st Qu.:168.0  \n##  Mode  :character         Median :170.0  \n##                           Mean   :171.6  \n##                           3rd Qu.:175.0  \n##                           Max.   :180.0\nsummary(1:10)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    3.25    5.50    5.50    7.75   10.00\n\nmean, sum, median, var, min, max… (facile à comprendre)\nsort, order\n\nx &lt;- c(1,8,5,4)\nsort(x)\n## [1] 1 4 5 8\norder(x)\n## [1] 1 4 3 2\n\napply applique une fonction f aux lignes ou colonnes d’une matrice ou dataframe\n\nV1 &lt;- 1:10\nV2 &lt;- seq(-20,25,length=10)\ndf &lt;- data.frame(V1,V2)\napply(df,1,mean)\n##  [1] -9.5 -6.5 -3.5 -0.5  2.5  5.5  8.5 11.5 14.5 17.5\napply(df,2,sum)\n## V1 V2 \n## 55 25"
  },
  {
    "objectID": "02-objetsR.html#exercices-complémentaires",
    "href": "02-objetsR.html#exercices-complémentaires",
    "title": "2  Les objets R",
    "section": "2.7 Exercices complémentaires",
    "text": "2.7 Exercices complémentaires\n\nExercice 2.2 (Manipulation de matrices) Cet exercice propose des questions classiques sur la manipulation de matrices.\n\nCréer la matrice suivante que l’on appellera mat (on pourra utiliser les fonctions rownames et colnames) :\n\n\n\n\n\ncolumn 1\ncolumn 2\ncolumn 3\ncolumn 4\n\n\n\n\nrow-1\n1\n5\n5\n0\n\n\nrow-2\n0\n5\n6\n1\n\n\nrow-3\n3\n0\n3\n3\n\n\nrow-4\n4\n4\n4\n2\n\n\n\n\nCréer un vecteur qui contient la diagonal de mat.\nCréer une matrice qui contient les 2 premières lignes de mat.\nCréer une matrice qui contient les 2 dernières colonnes de mat.\nCalculer le déterminant et l’inverse de mat.\n\n\n\nExercice 2.3 (Manipulations simples sur un jeu de données) On considère le jeu de données iris disponible dans R :\n\ndata(iris)\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\n\nCalculer les moyennes et variances des variables Sepal.Width et Petal.Length.\nCréer un sous jeu de données qui contient uniquement les iris de l’espèce versicolor. On appellera ce tableau iris2.\nOrdonner les individus dans iris2 par valeurs décroissantes de la variable Sepal.Length (on pourra utiliser la fonction order).\nCalculer les valeurs moyennes de Sepal.Length pour chaque espèce.\nAjouter une variable (qu’on appellera sum.Petal) dans le dataframe iris qui contiendra la somme de Petal.Length et Petal.Width.\n\n\n\nExercice 2.4 (Fonction apply) On considère le jeu de données suivant\n\nlibrary(lattice)\ndata(\"ethanol\")\n\n\nCalculer les indicateurs numériques standards (moyenne, min, max, etc.) des 3 variables du jeux de données ethanol (disponible dans le package lattice).\nCalculer les quartiles de chaque variables. On pourra faire un apply avec la fonction quantile.\nFaire de même pour les déciles.\n\n\n\nExercice 2.5 (Données manquantes) On considère le jeu de données presidents\n\ndata(\"presidents\")\ndf &lt;- matrix(presidents,ncol=4,byrow=T)\n\n\nEst-ce que la ligne 20 contient au moins une données manquante ? On pourra utiliser la fonction any.\nQuelles sont les lignes de df qui contiennent au moins une donnée manquante ? On pourra utiliser la fonction which.\nSupprimer les lignes de df qui contiennent au moins une donnée manquante.\n\nOn aurait aussi pu utiliser directement la fonction na.omit :"
  },
  {
    "objectID": "03-dplyr.html#importer-des-données",
    "href": "03-dplyr.html#importer-des-données",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.1 Importer des données",
    "text": "3.1 Importer des données\nLes fonctions read.table et read.csv sont les fonctions standards de R pour importer des données à partir de fichiers .txt ou .csv. Il est important de bien gérer le chemin du répertoire où se trouve le fichier. On peut le spécifier explicitement ou utiliser des fonctions comme file.path :\n\npath &lt;- file.path(\"data/\", \"piscines.csv\") #premier : répertoire, deuxième : fichier\npiscines &lt;- read.csv(path)\nclass(piscines)\n## [1] \"data.frame\"\nsummary(piscines)\n##      Name             Address             Latitude        Longitude    \n##  Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n##  Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n##  Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n##                                        Mean   :-27.49   Mean   :153.0  \n##                                        3rd Qu.:-27.45   3rd Qu.:153.1  \n##                                        Max.   :-27.31   Max.   :153.2\n\nIl existe plusieurs options importantes dans read.csv, notamment\n\nsep : le caractère de séparation (espace, virgule…)\ndec : le caractère pour le séparateur décimal (vigule, point…)\nheader : logique pour indiquer si le nom des variables est spécifié à la première ligne du fichier\nrow.names : vecteurs des identifiants (si besoin)\nna.strings : vecteur de caractères pour repérer les données manquantes.\n…\n\nLe package readr du tidyverse propose d’autres fonctions comme read_csv ou read_delim. Il n’y a pas de différences énormes avec les fonctions standards, les objets créés sont des tibbles et plus des dataframes (même si les tibbles sont des dataframes…). Par exemple\n\nlibrary(readr)\npiscines &lt;- read_csv(\"data/piscines.csv\")\nsummary(piscines)\n##      Name             Address             Latitude        Longitude    \n##  Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n##  Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n##  Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n##                                        Mean   :-27.49   Mean   :153.0  \n##                                        3rd Qu.:-27.45   3rd Qu.:153.1  \n##                                        Max.   :-27.31   Max.   :153.2\nclass(piscines)\n## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\n\nEnfin si on n’est pas très à l’aise avec ces fonctions, on pourra utiliser le bouton Import Dataset qui se trouve dans l’onglet Environment de RStudio. Cette manière de procédé fonctionne pour des jeux de données “propres”. Si les bases contiennent trop de spécificités, on devra utiliser les fonctions présentées précédemment avec les bonnes options.\n\nExercice 3.1 (Premières importations avec readr) On étudie les fonctions classiques permettant d’importer des données.\n\nImporter les données qui se trouvent dans le fichier mydata.csv. On utilisera les fonctions read_csv, read_csv2 et read_delim avec les options par défaut et on comparera les sorties.\n\nread_csv n’utilise pas le bon séparateur par défaut, read_csv2 ne lit pas correctement le symbole pour la décimale, read_delim fonctionne bien pour ce fichier (sinon il aurait fallu ajouter l’option delim).\n\nImporter les données qui se trouvent dans le fichier mydata2.csv.\n\nLes variable height et weight sont interprétées comme des variables qualitatives, cela vient du fait qu’il y a des données manquante mal lues.\n\nCe fichier contient des données manquantes (identifiées par un point). A l’aide de l’option na, refaire l’importation en identifiant correctement les données manquantes.\nChanger les levels de la variable sex en woman et man (on pourra utiliser la fonction levels).\n\n1ère façon :\n2ème façon avec recode_factor du package forcats :\n\n\n\n\nExercice 3.2 (Importer avec read.csv) Refaire l’exercice précédent avec la fonction read.csv.\n\nOn commence avec les paramètres par défaut :\n\n\nLe séparateur n’est pas bien défini ! On corrige :\n\n\nPour le second fichier on fait :\n\n\n\nExercice 3.3 (Jointure de tables) On considère les 3 jeux de données suivants, au format tibble :\n\ndf1 &lt;- tibble(name=c(\"Mary\",\"Peter\",\"John\",\"July\"),age=c(18,25,21,43))\ndf2 &lt;- tibble(name=c(\"Zac\",\"Julian\"),age=c(23,48))\ndf3 &lt;- tibble(size=c(154,178,182,134,142),name1=c(\"Peter\",\"Mary\",\"July\",\"John\",\"stef\"))\ndf1\n## # A tibble: 4 × 2\n##   name    age\n##   &lt;chr&gt; &lt;dbl&gt;\n## 1 Mary     18\n## 2 Peter    25\n## 3 John     21\n## 4 July     43\ndf2\n## # A tibble: 2 × 2\n##   name     age\n##   &lt;chr&gt;  &lt;dbl&gt;\n## 1 Zac       23\n## 2 Julian    48\ndf3\n## # A tibble: 5 × 2\n##    size name1\n##   &lt;dbl&gt; &lt;chr&gt;\n## 1   154 Peter\n## 2   178 Mary \n## 3   182 July \n## 4   134 John \n## 5   142 stef\n\nOn souhaite assembler ces tables en utilisant les fonctions de jointure du tidyverse (left_join, full_join par exemple). On pourra consulter la cheatsheet Data transformation with dplyr (help -&gt; cheatsheets -&gt; …).\n\nAssembler df1 avec df2 en utilisant bind_rows et calculer la moyenne de la variable age. On appellera df cette nouvelle table.\nAssembler df avec df3 en utilisant full_join.\nFaire la même chose avec inner_join.\nExpliquer les différences entre full_join et inner_join.\n\ninner_join retient uniquement les individus pour lesquels age et size ont été observés. full_join garde tous les individus, des NA sont ajoutés lorsque la variable n’est pas observée."
  },
  {
    "objectID": "03-dplyr.html#le-package-dplyr",
    "href": "03-dplyr.html#le-package-dplyr",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.2 Le package dplyr",
    "text": "3.2 Le package dplyr\ndplyr est un package du tidyverse qui permet de faciliter la manipulation des données. Il propose une syntaxe claire (basée sur une grammaire) pour travailler sur les données. On pourra trouver des informations à cet url https://spark.rstudio.com/dplyr.html ou sur la cheatsheet.\nNous avons vu quelques opérations standards pour manipuler les données. Par exemple, on peut obtenir les Longitude et Latitude des piscines ayant une Longitude supérieure à 153 avec\n\npiscines[piscines$Longitude&gt;153,c(\"Longitude\",\"Latitude\")]\n## # A tibble: 16 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.5\n##  3      153.    -27.4\n##  4      153.    -27.5\n##  5      153.    -27.5\n##  6      153.    -27.5\n##  7      153.    -27.6\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.5\n## 11      153.    -27.5\n## 12      153.    -27.4\n## 13      153.    -27.6\n## 14      153.    -27.3\n## 15      153.    -27.5\n## 16      153.    -27.5\n\ndplyr propose de faire la même chose avec une syntaxe plus claire\n\nlibrary(tidyverse) #ou library(dplyr)\npiscines |&gt; select(Longitude,Latitude) |&gt; filter(Longitude&gt;153)\n## # A tibble: 16 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.5\n##  3      153.    -27.4\n##  4      153.    -27.5\n##  5      153.    -27.5\n##  6      153.    -27.5\n##  7      153.    -27.6\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.5\n## 11      153.    -27.5\n## 12      153.    -27.4\n## 13      153.    -27.6\n## 14      153.    -27.3\n## 15      153.    -27.5\n## 16      153.    -27.5\n\nLe code est plus efficace et facile à lire.\ndplyr propose une grammaire dont les principaux verbes sont :\n\nselect() : sélectionner des colonnes (variables)\nfilter() : filtrer des lignes (individus)\narrange() : ordonner des lignes\nmutate() : créer des nouvelles colonnes (nouvelles variables)\nsummarise() : calculer des résumés numériques (ou résumés statistiques)\ngroup_by() : effectuer des opérations pour des groupes d’individus\n\nNous les présentons dans la partie suivante.\n\n3.2.1 Les principaux verbes dplyr\n\nLe verbe select()\nIl permet de sélectionner des variables (colonnes) :\n\nselect(df, VAR1, VAR2, ...)\n\nPar exemple,\n\ncoord &lt;- select(piscines, Latitude, Longitude)\nhead(piscines, n=2)\n## # A tibble: 2 × 4\n##   Name                        Address                         Latitude Longitude\n##   &lt;chr&gt;                       &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;\n## 1 Acacia Ridge Leisure Centre 1391 Beaudesert Road, Acacia R…    -27.6      153.\n## 2 Bellbowrie Pool             Sugarwood Street, Bellbowrie       -27.6      153.\nhead(coord, n=2)\n## # A tibble: 2 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.6      153.\n## 2    -27.6      153.\n\nOn peut utiliser les helper functions (begins_with, end_with, contains, matches) pour des sélections plus précises basées sur le nom des variables.\n\ncoord &lt;- select(piscines, ends_with(\"tude\"))\nhead(coord, n=2)\n## # A tibble: 2 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.6      153.\n## 2    -27.6      153.\n\n\n\nLe verbe mutate()\nIl permet de créer des nouvelles variables\n\nmutate(df, NEW.VAR = expression(VAR1, VAR2, ...))\n\nPar exemple\n\ndf &lt;- mutate(piscines, phrase=paste(\"Swimming pool\", Name, \"is located at the address\", Address))\nselect(df,phrase)\n## # A tibble: 20 × 1\n##    phrase                                                                       \n##    &lt;chr&gt;                                                                        \n##  1 Swimming pool Acacia Ridge Leisure Centre is located at the address 1391 Bea…\n##  2 Swimming pool Bellbowrie Pool is located at the address Sugarwood Street, Be…\n##  3 Swimming pool Carole Park is located at the address Cnr Boundary Road and Wa…\n##  4 Swimming pool Centenary Pool (inner City) is located at the address 400 Greg…\n##  5 Swimming pool Chermside Pool is located at the address 375 Hamilton Road, Ch…\n##  6 Swimming pool Colmslie Pool (Morningside) is located at the address 400 Lytt…\n##  7 Swimming pool Spring Hill Baths (inner City) is located at the address 14 To…\n##  8 Swimming pool Dunlop Park Pool (Corinda) is located at the address 794 Oxley…\n##  9 Swimming pool Fortitude Valley Pool is located at the address 432 Wickham St…\n## 10 Swimming pool Hibiscus Sports Complex (upper MtGravatt) is located at the ad…\n## 11 Swimming pool Ithaca Pool ( Paddington) is located at the address 131 Caxton…\n## 12 Swimming pool Jindalee Pool is located at the address 11 Yallambee Road, Jin…\n## 13 Swimming pool Manly Pool is located at the address 1 Fairlead Crescent, Manly\n## 14 Swimming pool Mt Gravatt East Aquatic Centre is located at the address Cnr w…\n## 15 Swimming pool Musgrave Park Pool (South Brisbane) is located at the address …\n## 16 Swimming pool Newmarket Pool is located at the address 71 Alderson Stret, Ne…\n## 17 Swimming pool Runcorn Pool is located at the address 37 Bonemill Road, Runco…\n## 18 Swimming pool Sandgate Pool is located at the address 231 Flinders Parade, S…\n## 19 Swimming pool Langlands Parks Pool (Stones Corner) is located at the address…\n## 20 Swimming pool Yeronga Park Pool is located at the address 81 School Road, Ye…\n\nOn peut également créer plusieurs variables avec un seul mutate :\n\nmutate(piscines,\n       phrase = paste(\"Swimming pool\", Name, \"is located at the address\", Address),\n       unused = Longitude + Latitude\n)\n## # A tibble: 20 × 6\n##    Name                                 Address Latitude Longitude phrase unused\n##    &lt;chr&gt;                                &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n##  1 Acacia Ridge Leisure Centre          1391 B…    -27.6      153. Swimm…   125.\n##  2 Bellbowrie Pool                      Sugarw…    -27.6      153. Swimm…   125.\n##  3 Carole Park                          Cnr Bo…    -27.6      153. Swimm…   125.\n##  4 Centenary Pool (inner City)          400 Gr…    -27.5      153. Swimm…   126.\n##  5 Chermside Pool                       375 Ha…    -27.4      153. Swimm…   126.\n##  6 Colmslie Pool (Morningside)          400 Ly…    -27.5      153. Swimm…   126.\n##  7 Spring Hill Baths (inner City)       14 Tor…    -27.5      153. Swimm…   126.\n##  8 Dunlop Park Pool (Corinda)           794 Ox…    -27.5      153. Swimm…   125.\n##  9 Fortitude Valley Pool                432 Wi…    -27.5      153. Swimm…   126.\n## 10 Hibiscus Sports Complex (upper MtGr… 90 Klu…    -27.6      153. Swimm…   126.\n## 11 Ithaca Pool ( Paddington)            131 Ca…    -27.5      153. Swimm…   126.\n## 12 Jindalee Pool                        11 Yal…    -27.5      153. Swimm…   125.\n## 13 Manly Pool                           1 Fair…    -27.5      153. Swimm…   126.\n## 14 Mt Gravatt East Aquatic Centre       Cnr we…    -27.5      153. Swimm…   126.\n## 15 Musgrave Park Pool (South Brisbane)  100 Ed…    -27.5      153. Swimm…   126.\n## 16 Newmarket Pool                       71 Ald…    -27.4      153. Swimm…   126.\n## 17 Runcorn Pool                         37 Bon…    -27.6      153. Swimm…   125.\n## 18 Sandgate Pool                        231 Fl…    -27.3      153. Swimm…   126.\n## 19 Langlands Parks Pool (Stones Corner) 5 Pani…    -27.5      153. Swimm…   126.\n## 20 Yeronga Park Pool                    81 Sch…    -27.5      153. Swimm…   125.\n\n\n\nLe verbe filter()\nIl permet de sélectionner (filtrer) des individus (lignes) :\n\nfilter(df, TEST)\n\nPar exemple\n\np1 &lt;- filter(piscines, Longitude&gt;153.02)\nselect(p1,Longitude)\n## # A tibble: 12 × 1\n##    Longitude\n##        &lt;dbl&gt;\n##  1      153.\n##  2      153.\n##  3      153.\n##  4      153.\n##  5      153.\n##  6      153.\n##  7      153.\n##  8      153.\n##  9      153.\n## 10      153.\n## 11      153.\n## 12      153.\n\nou (on sélectionne les piscines dont le nom contient Pool)\n\ndf &lt;- filter(piscines, !grepl(\"Pool\", Name))\nselect(df,Name)\n## # A tibble: 5 × 1\n##   Name                                     \n##   &lt;chr&gt;                                    \n## 1 Acacia Ridge Leisure Centre              \n## 2 Carole Park                              \n## 3 Spring Hill Baths (inner City)           \n## 4 Hibiscus Sports Complex (upper MtGravatt)\n## 5 Mt Gravatt East Aquatic Centre\n\nou (on sélectionne les piscines avec une longitude plus grande que 153.02 ou une latitude plus petite que -27.488)\n\np2 &lt;- filter(piscines, Longitude&gt;153.02 | Latitude &lt; -27.488)\nselect(p2, Longitude, Latitude)\n## # A tibble: 17 × 2\n##    Longitude Latitude\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1      153.    -27.6\n##  2      153.    -27.6\n##  3      153.    -27.6\n##  4      153.    -27.5\n##  5      153.    -27.4\n##  6      153.    -27.5\n##  7      153.    -27.5\n##  8      153.    -27.5\n##  9      153.    -27.5\n## 10      153.    -27.6\n## 11      153.    -27.5\n## 12      153.    -27.5\n## 13      153.    -27.5\n## 14      153.    -27.6\n## 15      153.    -27.3\n## 16      153.    -27.5\n## 17      153.    -27.5\n\nOn peut également utiliser la fonction slice pour choisir des individus à partir de leurs indices :\n\nslice(piscines,5:8)\n## # A tibble: 4 × 4\n##   Name                           Address                      Latitude Longitude\n##   &lt;chr&gt;                          &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt;\n## 1 Chermside Pool                 375 Hamilton Road, Chermside    -27.4      153.\n## 2 Colmslie Pool (Morningside)    400 Lytton Road, Morningside    -27.5      153.\n## 3 Spring Hill Baths (inner City) 14 Torrington Street, Sprin…    -27.5      153.\n## 4 Dunlop Park Pool (Corinda)     794 Oxley Road, Corinda         -27.5      153.\n\n\n\nLe verbe arrange()\nIl permet d’ordonner les individus en fonction d’une variable\n\narrange(df, VAR) #tri croissant\n\nou\n\narrange(df, desc(VAR)) #tri décroissant\n\nPar exemple\n\narrange(piscines, Longitude)\n## # A tibble: 20 × 4\n##    Name                                      Address          Latitude Longitude\n##    &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n##  1 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n##  2 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n##  3 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n##  4 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n##  5 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n##  6 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n##  7 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n##  8 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n##  9 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n## 10 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n## 11 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n## 12 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n## 13 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n## 14 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n## 15 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n## 16 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n## 17 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n## 18 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n## 19 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n## 20 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n\nou\n\narrange(piscines, desc(Longitude))\n## # A tibble: 20 × 4\n##    Name                                      Address          Latitude Longitude\n##    &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n##  1 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n##  2 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n##  3 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n##  4 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n##  5 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n##  6 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n##  7 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n##  8 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n##  9 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n## 10 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n## 11 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n## 12 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n## 13 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n## 14 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n## 15 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n## 16 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n## 17 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n## 18 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n## 19 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n## 20 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n\n\n\n\n3.2.2 Les verbes summarize et groub_by\nLes verbes précédents permettent de manipuler les données en sélectionnant des individus ou variables essentiellement. Ces deux nouveaux verbes vont permettre de calculer des indicateurs statistiques sur un jeu de données.\n\nLe verbe summarize (ou summarise)\nIl permet de créer des nouveaux jeux de données qui contiennent des résumés statistiques du jeu de données initial comme la moyenne, variance, médiane de variables. Par exemple\n\nsummarise(piscines,\n          mean_long = mean(Longitude),\n          med_lat = median(Latitude),\n          min_lat = min(Latitude),\n          sum_long = sum(Longitude)\n)\n## # A tibble: 1 × 4\n##   mean_long med_lat min_lat sum_long\n##       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n## 1      153.   -27.5   -27.6    3061.\n\ndplyr contient également les fonction suivantes (souvent utilisées en statistique) :\n\nn() : nombre de lignes (individus d’un jeu de données).\nn_distinct() : nombre d’éléments distincts dans un vecteur.\nfisrt() et last() : premier et dernier élément d’un vecteur.\n\nPar exemple, on obtient le nombre de piscines dans le jeu de données, et la longitude de la dernière piscine avec\n\nsummarise(piscines,n())\n## # A tibble: 1 × 1\n##   `n()`\n##   &lt;int&gt;\n## 1    20\nsummarise(piscines,last(Longitude))\n## # A tibble: 1 × 1\n##   `last(Longitude)`\n##               &lt;dbl&gt;\n## 1              153.\n\nOn peut aussi utiliser summarise_all, summarise_at qui vont permettre de répéter les mêmes opérations sur plusieurs variables. Par exemple\n\nsummarise_at(piscines,3:4,mean)\n## # A tibble: 1 × 2\n##   Latitude Longitude\n##      &lt;dbl&gt;     &lt;dbl&gt;\n## 1    -27.5      153.\n\n\n\nRegrouper des données avec Group_by\ngroup_by permet d’appliquer une ou des opérations à des groupes de données (ou d’individus). Par exemple, imaginons que l’on souhaite calculer les longitudes moyennes des piscines scindées en 2 groupes : petites et grande latitudes. On créé d’abord une variable lat_dis qui permet d’identifier les latitudes (petite ou grande) :\n\nlat_mean &lt;- piscines |&gt; summarise(mean(Latitude))\npisc1 &lt;- piscines |&gt; mutate(lat_dis=factor(Latitude&gt;as.numeric(lat_mean)))\nlevels(pisc1$lat_dis) &lt;- c(\"Low\",\"High\")\n\nIl reste maintenant à utiliser group_by pour obtenir les longitudes moyennes des 2 groupes :\n\nsummarise(group_by(pisc1,lat_dis),mean_long=mean(Longitude))\n## # A tibble: 2 × 2\n##   lat_dis mean_long\n##   &lt;fct&gt;       &lt;dbl&gt;\n## 1 Low          153.\n## 2 High         153.\n\n\n\n\n3.2.3 Assembler des verbes avec l’opérateur de chainage |&gt;\nUn des principaux intérêts de dplyr est bien entendu d’utiliser plusieurs verbes pour arriver au résultat souhaité. C’est ce qui est fait plus haut et nous observons que la syntaxe n’est pas facile à lire. Le package propose un opérateur de chainage ou pipe opérateur qui permet de rentre cette syntaxe plus lisible. Cet opérateur consiste à décomposer le code étape par étape et à relier ces étapes par le symbole |&gt;. On peut par exemple réécrire l’exemple précédent avec :\n\nLe jeu de données\n\npisc1\n\nÉtape group_by\n\npisc1 |&gt; group_by(lat_dis)\n\nÉtape summarise\n\npisc1 |&gt; group_by(lat_dis) |&gt; summarise(mean_long=mean(Longitude))\n## # A tibble: 2 × 2\n##   lat_dis mean_long\n##   &lt;fct&gt;       &lt;dbl&gt;\n## 1 Low          153.\n## 2 High         153.\n\n\nqui donne le résultat souhaité.\nCet opérateur peut être utilisé pour toutes les fonctions R. Il revient à considérer comme premier argument du terme à droite du pipe le terme à gauche de ce dernier. Par exemple\n\nmean(1:10)\n## [1] 5.5\n1:10 |&gt; mean()\n## [1] 5.5\n\nIl est recommandé d’utiliser cet opérateur lorsque on chaîne les verbes dplyr, la syntaxe est beaucoup plus claire.\n\n\n3.2.4 Quelques exercices\n\nExercice 3.4 (Dplyr sur les iris de Fisher) On considère le jeu de données iris\n\niris &lt;- iris |&gt; as_tibble()\n\nRépondre aux questions suivantes en utilisant les verbes dplyr et l’opérateur |&gt;.\n\nSélectionner les variables Petal.Width et Species.\nConstruire une table qui contient uniquement les iris d’espèce versicolor ou virginica (on pourra utiliser le symbole | pour la condition ou).\nOn peut également conserver tous les iris à l’exception de l’espèce setosa :\n\niris |&gt; filter(Species!=\"setosa\")\n## # A tibble: 100 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n##  1          7           3.2          4.7         1.4 versicolor\n##  2          6.4         3.2          4.5         1.5 versicolor\n##  3          6.9         3.1          4.9         1.5 versicolor\n##  4          5.5         2.3          4           1.3 versicolor\n##  5          6.5         2.8          4.6         1.5 versicolor\n##  6          5.7         2.8          4.5         1.3 versicolor\n##  7          6.3         3.3          4.7         1.6 versicolor\n##  8          4.9         2.4          3.3         1   versicolor\n##  9          6.6         2.9          4.6         1.3 versicolor\n## 10          5.2         2.7          3.9         1.4 versicolor\n## # ℹ 90 more rows\n\nCalculer le nombre d’iris de l’espèce setosa en utilisant summarise.\nCalculer la moyenne de la variable Petal.Width pour les iris de l’espèce versicolor.\nAjouter dans le jeu de données la variable Sum_Petal qui correspond à la somme de Petal.Width et Sepal.Width.\nCalculer la moyenne et la variance de la variable Pepal.Length pour chaque espèce (on pourra utiliser group_by).\n\n\n\nExercice 3.5 (Traffic aérien aux USA) On considère la table hflights qui contient des informations sur les vols au départ des aéroports Houston airports IAH (George Bush Intercontinental) et HOU (Houston Hobby):\n\nlibrary(hflights)\nhflights &lt;- as_tibble(hflights)\n\nLa variable Unique Carrier renseigne sur la compagnie du vol. On recode cette variable afin que la compagnie soit plus explicite :\n\nlut1 &lt;- c(\"AA\" = \"American\", \"AS\" = \"Alaska\", \"B6\" = \"JetBlue\", \"CO\" = \"Continental\",\n         \"DL\" = \"Delta\", \"OO\" = \"SkyWest\", \"UA\" = \"United\", \"US\" = \"US_Airways\", \n         \"WN\" = \"Southwest\", \"EV\" = \"Atlantic_Southeast\", \"F9\" = \"Frontier\", \n         \"FL\" = \"AirTran\", \"MQ\" = \"American_Eagle\", \"XE\" = \"ExpressJet\", \"YV\" = \"Mesa\")\n\nOn fait de même pour la variable CancellationCode :\n\nlut2 &lt;- c(\"A\" = \"carrier\", \"B\" = \"weather\", \"C\" = \"FFA\", \"D\" = \"security\", \"E\" = \"not cancelled\")\n\nOn effectue maintenant les changements dans la table pour obtenir une nouvelle version de hflights :\n\nhflights1 &lt;- hflights\nhflights1$UniqueCarrier &lt;- lut1[hflights1$UniqueCarrier]\nhflights1$CancellationCode[hflights1$CancellationCode==\"\"] &lt;- \"Z\"\nhflights1$CancellationCode &lt;- lut2[hflights1$CancellationCode]\n\nA partir de maintenant, on travaille avec hflights1.\n\nSélectionner les variables qui se situent entre Origin et Cancelled de différentes façons.\nSélectionner les variables DepTime, ArrTime, ActualElapsedTime, AirTime, ArrDelay et DepDelay. On pourra remarquer que toutes ces variables contiennent les chaînes de caractère Time ou Delay et utiliser la helper function contains().\nAjouter une variable ActualGroundTime qui correspond à ActualElapsedTime moins AirTime.\nAjouter la variable AverageSpeed (=Distance/AirTime) et ordonner la table selon les valeurs décroissantes de cette variable.\nSélectionner les vols à destination de JFK.\nCalculer le nombre de vols à destination de JFK.\nCréer un résumé de hflights1 qui contient :\n\nn_flights : le nombre total de vols ;\nn_dest: le nombre total de destinations ;\nn_carrier : le nombre total de compagnies.\n\nCréer un résumé de hflights1 qui contient, pour les vols de la compagnie American,\n\nle nombre total de vols ;\nle nombre total de vols annulés ;\nla valeur moyenne de ArrDelay (attention à la gestion des NA…).\n\nCalculer pour chaque compagnie :\n\nle nombre total de vols ;\nLa valeur moyenne de AirTime.\n\nOrdonner les compagnies en fonction des retards moyens au départ.\n\n\n\nExercice 3.6 (Tournois du grand chelem au tennis) On considère le données sur les résultats de tennis dans les tournois du grand chelem en 2013. Les données, ainsi que le descriptif des variables, se trouvent à l’adresse https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics.\nOn s’intéresse d’abord au tournoi masculin de Roland Garros. On répondra aux questions à l’aide des verbes dplyr.\n\nImporter les données.\nAfficher le nom des adversaires de Roger Federer.\nAfficher le nom des demi-finalistes (ceux qui ont atteint le 6ème tour).\nCombien y a t-il eu de points disputés en moyenne par match ? Il faudra penser à ajouter dans la table une variable correspondant au nombre de points de chaque match (verbe mutate).\nCombien y a t-il eu d’aces par match en moyenne ?\nCombien y a t-il eu d’aces par match en moyenne à chaque tour ?\nCombien y a t-il eu de doubles fautes au total dans le tournoi (attention aux données manquantes, taper help(sum) pour voir comment les gérer) ?\nImporter les données pour le tournoi masculin de Wimbledon 2013.\nConcaténer les tables en ajoutant une variable permettant d’identifier le tournoi. On pourra utiliser bind_rows abev l’option .id.\nAfficher les matchs de Federer pour chaque tournoi.\nou\nComparer les nombres d’aces par matchs à chaque tour pour les tournois de Roland Garros et Wimbledon.\nou pour une présentation plus synthétique\n\n\n\n\n3.2.5 Compléments : Tidy data avec tidyr\nL’utilisation de dplyr et de ggplot (que nous verrons dans la partie suivante) suppose que les données sont présentées sous un format adéquat : une ligne est un individu et une colonne une variable, on parle alors de tidy data. Cette représentation peut dépendre du contexte, et surtout de ce que l’on souhaite faire avec les données. Considérons par exemple le tableau suivant qui présente les taux de chômage des départements français en 2002, 2006, 2011\n\ndf &lt;- read_delim(\"data/tauxchomage.csv\",delim=\";\") |&gt; select(-1)\ndf\n## # A tibble: 96 × 4\n##    NOM_DPT                 TCHOMB1T01 TCHOMB1T06 TCHOMB1T11\n##    &lt;chr&gt;                        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n##  1 Ain                            3.9        5.9        6.6\n##  2 Aisne                         10.6       12         13.2\n##  3 Allier                         9          9.2        9.7\n##  4 Alpes-de-Haute-Provence        9.5        9.7       10.3\n##  5 Hautes-Alpes                   7.1        7.7        8.3\n##  6 Alpes-Maritimes                9.1        8.9        9.2\n##  7 Ardèche                        8.1        9.6        9.7\n##  8 Ardennes                      11.5       12.8       10.9\n##  9 Ariège                         9.2       10.1       10.6\n## 10 Aube                           8.2       10         10  \n## # ℹ 86 more rows\n\nPrésenté ainsi ce tableau comporte 4 variables (en comptant l’identifiant du département). Dans certaines situations, on peut préférer une structure à 3 variables :\n\nle département\nl’année\nle taux de chômage\n\nNous verrons qu’il n’est par exemple pas possible de faire un boxplot permettant de visualiser la distribution du taux de chômage en fonction de l’année à l’aide de ggplot2. Pour passer à ce format il est nécessaire d’assembler les 3 colonnes correspondant aux taux de chômage en une seule colonne et ajouter une colonne qui permette d’identifier l’année. La table obtenue aura plus de lignes, on parle de format long. La fonction pivot_longer du package tidyr permet de faire cette transformation :\n\ndf1 &lt;- df |&gt; pivot_longer(-NOM_DPT,names_to=\"Année\",values_to=\"TCHOM\") |&gt; \n  mutate(Année=fct_recode(Année,\"2001\"=\"TCHOMB1T01\",\"2006\"=\"TCHOMB1T06\",\"2011\"=\"TCHOMB1T11\"))\ndf1\n## # A tibble: 288 × 3\n##    NOM_DPT                 Année TCHOM\n##    &lt;chr&gt;                   &lt;fct&gt; &lt;dbl&gt;\n##  1 Ain                     2001    3.9\n##  2 Ain                     2006    5.9\n##  3 Ain                     2011    6.6\n##  4 Aisne                   2001   10.6\n##  5 Aisne                   2006   12  \n##  6 Aisne                   2011   13.2\n##  7 Allier                  2001    9  \n##  8 Allier                  2006    9.2\n##  9 Allier                  2011    9.7\n## 10 Alpes-de-Haute-Provence 2001    9.5\n## # ℹ 278 more rows\n\nIl sera alors aisé de faire le boxplot souhaité avec\n\nggplot(df1)+aes(x=Année,y=TCHOM)+geom_boxplot()\n\n\n\n\nL’opération inverse peut être effectuée avec pivot_wider :\n\ndf1 |&gt; pivot_wider(names_from=\"Année\",values_from=\"TCHOM\")\n## # A tibble: 96 × 4\n##    NOM_DPT                 `2001` `2006` `2011`\n##    &lt;chr&gt;                    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n##  1 Ain                        3.9    5.9    6.6\n##  2 Aisne                     10.6   12     13.2\n##  3 Allier                     9      9.2    9.7\n##  4 Alpes-de-Haute-Provence    9.5    9.7   10.3\n##  5 Hautes-Alpes               7.1    7.7    8.3\n##  6 Alpes-Maritimes            9.1    8.9    9.2\n##  7 Ardèche                    8.1    9.6    9.7\n##  8 Ardennes                  11.5   12.8   10.9\n##  9 Ariège                     9.2   10.1   10.6\n## 10 Aube                       8.2   10     10  \n## # ℹ 86 more rows\n\nLe package tidyr possède plusieurs autres verbes qui pourront aider l’utilisateur à mettre la table sous le meilleur format pour les analyses. Citons par exemple le verbe separate qui va séparer une colonne en plusieurs :\n\n(df &lt;- tibble(date=as.Date(c(\"01/03/2015\",\"05/18/2017\",\n                             \"09/14/2018\"),\"%m/%d/%Y\"),\n              temp=c(18,21,15)))\n## # A tibble: 3 × 2\n##   date        temp\n##   &lt;date&gt;     &lt;dbl&gt;\n## 1 2015-01-03    18\n## 2 2017-05-18    21\n## 3 2018-09-14    15\n (df1 &lt;- df |&gt; separate_wider_delim(date,delim=\"-\",\n                                       names=c(\"year\",\"month\",\"day\")))\n## # A tibble: 3 × 4\n##   year  month day    temp\n##   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n## 1 2015  01    03       18\n## 2 2017  05    18       21\n## 3 2018  09    14       15\n\nou le verbe unite qui fera l’opération inverse\n\ndf1 |&gt; \n  unite(date,year,month,day,sep=\"/\") |&gt;\n  mutate(date1=lubridate::as_date(date))\n## # A tibble: 3 × 3\n##   date        temp date1     \n##   &lt;chr&gt;      &lt;dbl&gt; &lt;date&gt;    \n## 1 2015/01/03    18 2015-01-03\n## 2 2017/05/18    21 2017-05-18\n## 3 2018/09/14    15 2018-09-14\n\nCitons enfin les verbes :\n\nseparate_longer_delim qui permettra de séparer des informations en plusieurs lignes ;\nseparate_wider_regex pour créer de nouvelles colonnes ;\ncomplete pour ajouter des lignes dans un tableau, par exemple des non réponses à un questionnaire."
  },
  {
    "objectID": "031-programmer.html#structures-de-contrôle",
    "href": "031-programmer.html#structures-de-contrôle",
    "title": "4  Programmer",
    "section": "4.1 Structures de contrôle",
    "text": "4.1 Structures de contrôle\nOn énumère les principales structures :\n\nBoucles for :\n\nfor (i in vecteur){\n  expr1\n  expr2\n  ...\n}\n\nPar exemple\n\nfor (i in 1:3){print(i)}\n## [1] 1\n## [1] 2\n## [1] 3\nfor (i in c(\"lundi\",\"mardi\",\"mercredi\")){print(i)}\n## [1] \"lundi\"\n## [1] \"mardi\"\n## [1] \"mercredi\"\n\nCondition while\n\nwhile (condition) {expression}\n\nPar exemple :\n\ni &lt;- 1\nwhile (i&lt;=3) {\n  print(i)\n  i &lt;- i+1\n}\n## [1] 1\n## [1] 2\n## [1] 3\n\nCondition if else\n\nif (condition){\n  expr1\n  ...\n} else {\n  expre2\n  ...\n}\n\nPar exemple :\n\na &lt;- -2\nif (a&gt;0){\n  a &lt;- a+1\n} else {\n  a &lt;- a-1\n}\nprint(a)\n## [1] -3\n\nswitch\n\nswitch(expression,\n       \"cond1\" = action1,\n       \"cond2\" = action2,\n       ...)\n\nPar exemple :\n\nX &lt;- matrix(0,nrow = 5,ncol = 5)\nswitch(class(X)[1],\n       \"matrix\"=print(\"X est une matrice\"),\n       \"data.frame\"=print(\"X est un data.frame\"),\n       \"numeric\"=print(\"X est de classe numérique\"))\n## [1] \"X est une matrice\""
  },
  {
    "objectID": "031-programmer.html#écrire-une-fonction",
    "href": "031-programmer.html#écrire-une-fonction",
    "title": "4  Programmer",
    "section": "4.2 Écrire une fonction",
    "text": "4.2 Écrire une fonction\nOn peut définir sa propre fonction dans un objet avec function :\n\nmafonct &lt;- function(param1,param2,...){\n  expr1\n  expr2\n  return(...)\n  }\n\nConstruisons par exemple la fonction factorielle qui calcule la factorielle d’un entier n :\n\nfactorielle &lt;- function(n){\n  return(prod(1:n))\n  }\n\nOn peut la tester\n\nfactorielle(5)\n## [1] 120\n\nOn propose d’améliorer cette fonction en spécifiant des messages d’erreur ou d’alerte :\n\nfactorielle &lt;- function(n){\n  if (n&lt;=0) stop(\"l'entier doit être strictement positif\")\n  if (ceiling(n)!=n) warning(paste(\"arrondi de\",n,\"en\",ceiling(n)))\n  return(prod(1:ceiling(n)))\n  }\n\nOn a alors un message d’erreur lorsque le paramètre est négatif\n\nfactorielle(-2)\n## Error in factorielle(-2): l'entier doit être strictement positif\n\nou un avertissement si ce n’est pas un entier\n\nfactorielle(2.8)\n## Warning in factorielle(2.8): arrondi de 2.8 en 3\n## [1] 6"
  },
  {
    "objectID": "031-programmer.html#les-fonctions-map",
    "href": "031-programmer.html#les-fonctions-map",
    "title": "4  Programmer",
    "section": "4.3 Les fonctions map",
    "text": "4.3 Les fonctions map\nCes fonctions appartiennent au package purrr du tidyverse. Elles permettent d’appliquer des fonctions à des listes et donc à des tibbles. On peut les voir comme des versions améliorées des fonctions apply. On peut par exemple retrouver les sorties de\n\napply(iris[,-5],2,mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\navec\n\nmap(iris[,-5],mean)\n## $Sepal.Length\n## [1] 5.843333\n## \n## $Sepal.Width\n## [1] 3.057333\n## \n## $Petal.Length\n## [1] 3.758\n## \n## $Petal.Width\n## [1] 1.199333\n\nou encore\n\nmap_dbl(iris[,-5],mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\nqui renvoie un vecteur de classe numeric plutôt qu’une liste. On peut citer également les fonctions map_lgl, map_chr, map_dbl qui retournent des vecteurs de logiques, de caractères ou d’entiers.\nDans le même style, on dispose des fonctions map2_... pour appliquer des fonctions à des paires d’éléments de listes. On peut par exemple sommer les élément de deux listes avec\n\nl1 &lt;- list(1,2,3)\nl2 &lt;- list(4,5,6)\nmap2(l1,l2,`+`)\n## [[1]]\n## [1] 5\n## \n## [[2]]\n## [1] 7\n## \n## [[3]]\n## [1] 9\n#ou pour obtenir un vecteur\nmap2_dbl(l1,l2,`+`)\n## [1] 5 7 9\n\nIl est également possible de spécifier explicitement sa propre fonction lorsqu’elle n’existe pas\n\nset.seed(123)\ntbl1 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\ntbl2 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\nmap2_dbl(tbl1,tbl2,function(d1,d2) mean(rbind(d1,d2)))\n##       age    taille \n##  38.21492 164.83358\n\nLa syntaxe peut paraître un peu lourde, avec notamment l’utilisation de function. On utilise régulièrement des fonctions anonymes qui peuvent se définir à l’aide d’une formule :\n\nmap2_dbl(tbl1,tbl2,~mean(rbind(.x,.y)))\n##       age    taille \n##  38.21492 164.83358\n\nou en spécifiant explicitement les arguments\n\nmap2_dbl(tbl1,tbl2,\\(d1,d2) mean(rbind(d1,d2)))\n##       age    taille \n##  38.21492 164.83358\n\nNotons enfin que l’utilisation des fonctions anonymes diffèrent lorsqu’on chaîne les opérations avec le pipe de la distribution de R de base |&gt; ou avec celui de dplyr %&gt;% :\n\nset.seed(123)\nX1 &lt;- rnorm(100)\nc(0.25,0.5,0.75) %&gt;% quantile(X1,probs = .)\n##         25%         50%         75% \n## -0.49385424  0.06175631  0.69181917\nc(0.25,0.5,0.75) |&gt; quantile(X1,probs = .)\n## Error in if (na.rm) x &lt;- x[!is.na(x)] else if (anyNA(x)) stop(\"missing values and NaN's not allowed if 'na.rm' is FALSE\"): the condition has length &gt; 1\n\nLe . permet d’indiquer la place de la quantité à gauche du pipe %&gt;%. Lorsqu’on utilise |&gt;, il faut utiliser une fonction anonyme :\n\nc(0.25,0.5,0.75) |&gt; (\\(p) quantile(X1,probs = p))()\n##         25%         50%         75% \n## -0.49385424  0.06175631  0.69181917"
  },
  {
    "objectID": "031-programmer.html#exercices",
    "href": "031-programmer.html#exercices",
    "title": "4  Programmer",
    "section": "4.4 Exercices",
    "text": "4.4 Exercices\n\nExercice 4.1 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui admet en entrée un entier positif n et qui renvoie la somme des entiers qui vont de 1 à n.\nÉcrire une fonction qui remplace les données manquantes d’un jeu de données par la moyenne ou la médiane de la variable. Choisir la moyenne ou la médiane doit être un paramètre de la fonction. On pourra tester la fonction sur le tibble suivant :\n\nset.seed(123)\ntbl &lt;- tibble(X1=as.numeric(sample(10,5)),X2=as.numeric(sample(10,5)))\ntbl[3,1] &lt;- NA;tbl[4,2] &lt;- NA\ntbl\n## # A tibble: 5 × 2\n##      X1    X2\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     3     5\n## 2    10     4\n## 3    NA     6\n## 4     8    NA\n## 5     6     1\n\n\n\n\nExercice 4.2 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui calcule la moyenne et la variance des colonnes d’un jeu de données qui ne contient que des variables continues. On utilisera une boucle for et on testera la fonction sur les 4 premières colonnes des données iris.\nMême question en utilisant la fonction apply.\nMême question en utilisant une fonction map_....\n\nou encore\n\nUtiliser la méthode de votre choix pour un tibble qui peut comporter des variables qualitatives. La fonction renverra un warning qui énumèrent les variables qualitatives."
  },
  {
    "objectID": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "href": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.1 Fonctions graphiques conventionnelles",
    "text": "5.1 Fonctions graphiques conventionnelles\nPour commencer il est intéressant d’examiner quelques exemples de représentations graphiques construits avec R. On peut les obtenir à l’aide de la fonction demo.\n\ndemo(graphics)\n\n\n5.1.1 La fonction plot\nC’est une fonction générique que l’on peut utiliser pour représenter différents types de données. L’utilisation standard consiste à visualiser une variable y en fonction d’une variable x. On peut par exemple obtenir le graphe de la fonction \\(x\\mapsto \\sin(2\\pi x)\\) sur \\([0,1]\\), à l’aide de\n\nx &lt;- seq(-2*pi,2*pi,by=0.05)\ny &lt;- sin(x)\nplot(x,y) #points (par défaut)\n\n\n\nplot(x,y,type=\"l\") #représentation sous forme de ligne\n\n\n\n\nNous proposons des exemples de représentations de variables quantitatives et qualitatives à travers du jeu de données ozone.txt que l’on importe avec\n\nozone &lt;- read.table(\"data/ozone.txt\")\nsummary(ozone)\n##      maxO3              T9             T12             T15       \n##  Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n##  1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n##  Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n##  Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n##  3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n##  Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n##       Ne9             Ne12            Ne15           Vx9         \n##  Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n##  1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n##  Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n##  Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n##  3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n##  Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n##       Vx12             Vx15            maxO3v           vent          \n##  Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n##  1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n##  Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n##  Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n##  3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n##  Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n##     pluie          \n##  Length:112        \n##  Class :character  \n##  Mode  :character  \n##                    \n##                    \n## \n\nOn visualise tout d’abord 2 variables quantitatives à l’aide d’un nuage de points : la concentration en ozone maximale maxO3 en fonction de la température à 12h T12.\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"])\n\n\n\n\nComme les deux variables appartiennent au même jeu de données, on peut obtenir la même représentation à l’aide d’une sytaxe plus claire qui ajoute automatiquement les noms des variables sur les axes :\n\nplot(maxO3~T12,data=ozone)\n\n\n\n\nUne autre façon de faire (moins naturelle) :\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"],xlab=\"T12\",ylab=\"maxO3\")\n\n\n\n\nIl existe des fonctions spécifiques pour chaque type de graphes, par exemple histogram, barplot et boxplot :\n\nhist(ozone$maxO3,main=\"Histogram\")\n\n\n\nbarplot(table(ozone$vent)/nrow(ozone),col=\"blue\")\n\n\n\nboxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n5.1.2 Graphes interactifs avec rAmCharts\nOn peut utiliser ce package pour obtenir des graphes dynamiques. L’utilisation est relativement simple, il suffit d’ajouter le préfixe am devant le nom de la fonction :\n\nlibrary(rAmCharts)\namHist(ozone$maxO3)\n\n\n\n\namPlot(ozone,col=c(\"T9\",\"T12\"))\n\n\n\n\namBoxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n\n5.1.3 Quelques exercices\n\nExercice 5.1 (Premier graphe) On s’intéresse à quelques graphes simples.\n\nTracer la fonction sinus entre \\(0\\) et \\(2\\pi\\).\nA l’aide de la fonction title ajouter le titre Représentation de la fonction sinus.\n\n\n\nExercice 5.2 (Tracé de densités) On souhaite ici visualiser et comparer des densités de probabilité.\n\nTracer la densité de la loi normale centrée réduite entre \\(-4\\) et 4 (utiliser dnorm).\nAjouter une ligne verticale (en tirets) qui passe par \\(x=0\\) (utiliser abline avec l’option lty=2).\nSur le même graphe, ajouter les densités de loi la de Student à 5 et 30 degrés de liberté (utiliser dt). On utilisera la fonction lines et des couleurs différentes pour chaque densité.\nAjouter une légende qui permette d’identifier chaque densité (fonction legend).\n\n\n\nExercice 5.3 (Tâches solaires) On souhaite ici visualiser une série temporelle.\n\nImporter la série taches_solaires.csv qui donne, date par date, un nombre de taches solaires observées.\nA l’aide de la fonction cut_interval du package ggplot2, créer un facteur qui sépare l’intervalle d’années d’observation en 8 intervalles de tailles à peu près égales. On appellera periode ce facteur.\nUtiliser les levels suivants pour le facteur periode.\n\ncouleurs &lt;- c(\"yellow\", \"magenta\", \"orange\", \"cyan\",\n          \"grey\", \"red\", \"green\", \"blue\")\n\nExpliquer la sortie de la fonction\n\nOn crée une séquence avec un pas de 1 de longueur égale à la dimension de taches[,1].\n\nVisualiser la série du nombre de taches en utilisant une couleur différente pour chaque période.\n\n\n\nExercice 5.4 (Layout) On reprend le jeu de données sur l’ozone. A l’aide de la fonction layout séparer la fenêtre graphique en deux lignes avec\n\nun graphe sur la première ligne (nuage de points maxO3 vs T12)\n2 graphes sur la deuxième ligne (histogramme de T12 et boxplot de maxO3)."
  },
  {
    "objectID": "04-ggplot.html#la-grammaire-ggplot2",
    "href": "04-ggplot.html#la-grammaire-ggplot2",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.2 La grammaire ggplot2",
    "text": "5.2 La grammaire ggplot2\nCe package propose de définir des graphes sur R en utilisant une grammaire des graphiques (tout comme dplyr pour manipuler les données). On peut trouver de la documentation sur ce package aux url https://ggplot2.tidyverse.org et https://ggplot2-book.org/index.html\n\n5.2.1 Premiers graphes ggplot2\nNous considérons un sous échantillon du jeu de données diamonds du package ggplot2 (que l’on peut également charger avec le package tidyverse).\n\nlibrary(tidyverse)\nset.seed(1234)\ndiamonds2 &lt;- diamonds[sample(nrow(diamonds),5000),] \nsummary(diamonds2)\n##      carat               cut       color       clarity         depth      \n##  Min.   :0.2000   Fair     : 158   D: 640   SI1    :1189   Min.   :43.00  \n##  1st Qu.:0.4000   Good     : 455   E: 916   VS2    :1157   1st Qu.:61.10  \n##  Median :0.7000   Very Good:1094   F: 900   SI2    : 876   Median :61.80  \n##  Mean   :0.7969   Premium  :1280   G:1018   VS1    : 738   Mean   :61.76  \n##  3rd Qu.:1.0400   Ideal    :2013   H: 775   VVS2   : 470   3rd Qu.:62.50  \n##  Max.   :4.1300                    I: 481   VVS1   : 326   Max.   :71.60  \n##                                    J: 270   (Other): 244                  \n##      table           price             x                y        \n##  Min.   :49.00   Min.   :  365   Min.   : 0.000   Min.   :3.720  \n##  1st Qu.:56.00   1st Qu.:  945   1st Qu.: 4.720   1st Qu.:4.720  \n##  Median :57.00   Median : 2376   Median : 5.690   Median :5.700  \n##  Mean   :57.43   Mean   : 3917   Mean   : 5.728   Mean   :5.731  \n##  3rd Qu.:59.00   3rd Qu.: 5294   3rd Qu.: 6.530   3rd Qu.:6.520  \n##  Max.   :95.00   Max.   :18757   Max.   :10.000   Max.   :9.850  \n##                                                                  \n##        z        \n##  Min.   :0.000  \n##  1st Qu.:2.920  \n##  Median :3.520  \n##  Mean   :3.538  \n##  3rd Qu.:4.030  \n##  Max.   :6.430  \n## \nhelp(diamonds)\n\nUn graphe ggplot est défini à partir de couches que l’on assemblera avec l’opérateur +. Il faut a minima spécifier :\n\nles données\nles variables que l’on souhaite représenter\nle type de représentation (nuage de points, boxplot…).\n\nIl existe un verbe pour définir chacune de ces couches :\n\nggplot pour les données\naes (aesthetics) pour les variables\ngeom_ pour le type de représentation.\n\nOn peut obtenir le nuage de points carat vs price avec la fonction plot :\n\nplot(price~carat,data=diamonds2)\n\n\n\n\nAvec ggplot, on va faire\n\nggplot(diamonds2) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point() #bon\n\n\n\n\n\nExercice 5.5 (Premiers graphes ggplot) \n\n\nTracer l’histogramme de la variable carat (utiliser geom_histogram).\nMême question en utilisant 10 classes pour l’histogramme (help(geom_histogram)).\nTracer le diagramme en barres de la variable cut (utiliser geom_bar).\n\n\nLa syntaxe ggplot est définie à partir d’éléments indépendants qui définissent la grammaire de ggplot. Les principaux verbes sont :\n\nData (ggplot) : les données au format dataframe ou tibble\nAesthetics (aes) : pour sépecifier les variables à représenter dans le graphe.\nGeometrics (geom_...) : le type de graphe (nuage de points, histogramme…).\nStatistics (stat_...) : utile pour spécifier des transformations des données nécessaires pour obtenir le graphe.\nScales (scale_...) : pour controler les paramètres permettant d’affiner le graphe (changement de couleurs, paramètres des axes…).\n\nTous ces éléments sont reliés avec le symbole +.\n\n\n5.2.2 Data et aesthetics\nCes deux verbes sont à utiliser pour tous les graphes ggplot. Le verbe ggplot sert à spécifier le jeu de données que l’on souhaite utiliser. Si le code est bien fait, nous n’aurons plus à utiliser le nom du jeu de données par la suite pour construire le graphe. Le verbe aes est quant à lui utile pour spécifier les variables que l’on souhaite visualiser. Par exemple, pour le nuage de points price vs carat la syntaxe débute avec\n\nggplot(diamonds2)+aes(x=carat,y=price)\n\nLes variables peuvent également être utilisées pour colorier des points ou des barres, définir des tailles… Dans ce cas on pourra renseigner les options color, size, fill dans la fonction aes. Par exemple\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)\n\n\n\n5.2.3 Geometrics\nCe verbe décrira le type de représentation souhaité. Pour un nuage de points, on utilisera par exemple geom_point :\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\n\n\n\n\nOn observe que ggplot ajoute la légende automatiquement. Voici les principaux exemples de geometrics :\n\n\nTable 5.1: Principaux geometrics\n\n\n\n\n\n\n\nGeom\nDescription\nAesthetics\n\n\n\n\ngeom_point()\nnuage de points\nx, y, shape, fill\n\n\ngeom_line()\nLigne (ordonnée selon x)\nx, y, linetype\n\n\ngeom_abline()\nLigne\nslope, intercept\n\n\ngeom_path()\nLigne (ordonnée par l’index)\nx, y, linetype\n\n\ngeom_text()\nTexte\nx, y, label, hjust, vjust\n\n\ngeom_rect()\nRectangle\nxmin, xmax, ymin, ymax, fill, linetype\n\n\ngeom_polygon()\nPolygone\nx, y, fill, linetype\n\n\ngeom_segment()\nSegment\nx, y, xend, yend, fill, linetype\n\n\ngeom_bar()\nDiagramme en barres\nx, fill, linetype, weight\n\n\ngeom_histogram()\nHistogramme\nx, fill, linetype, weight\n\n\ngeom_boxplot()\nBoxplot\nx, fill, weight\n\n\ngeom_density()\nDensité\nx, y, fill, linetype\n\n\ngeom_contour()\nLignes de contour\nx, y, fill, linetype\n\n\ngeom_smooth()\nLisseur (linéaire ou non linéaire)\nx, y, fill, linetype\n\n\nTous\n\ncolor, size, group\n\n\n\n\n\nExercice 5.6 (Diagrammes en barres) On étudie différentes façons de changer la couleur dans un diagramme en barres.\n\nTracer le diagramme en barres de la variable cut avec des barres bleues.\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité de cut ainsi qu’une légende qui permet de repérer la couleur.\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité que vous choisirez (et sans légende).\n\nOn peut ajouter l’option show.legend = FALSE dans geom_bar :\n\n\nou spécifier directement les couleurs (toujours dans geom_bar) :\n\n\n\n\n\n5.2.4 Statistics\nCertains graphes nécessitent des calculs d’indicateurs statistiques pour être tracé. C’est par exemple le cas pour le diagramme en barres et l’histogramme où il faut calculer des hauteurs de rectangles ou barres. On peut spécifier les transformations simples facilement, par exemple\n\nD &lt;- data.frame(X=seq(-2*pi,2*pi,by=0.01))\nggplot(D)+aes(x=X,y=sin(X))+geom_line()\n\n\n\n\nLa transformation est spécifiée dans la fonction aes. Pour des transformations plus complexes, nous devons utiliser le verbe statistics. Une fonction stat_ permet de définir des nouvelles variables à partir du jeu de données initial, il est ensuite possible de représenter ces nouvelles variables. Par exemple, la fonction stat_bin, qui est utilisée par défaut pour construire des histogrammes, calcule les variables suivantes :\n\ncount, le nombre d’observations dans chaque classes.\ndensity, la valeur de la densité des observations dans chaque classe (fréqunce divisée par largeur de la classe).\nx, le centre de la classe.\n\nPar défaut geom_histogram fait appel à cette fonction stat_bin grâce à l’option stat=\"bin\". On visualise ainsi sur l’axe \\(y\\) le nombre d’observations dans chaque classe (la variable count).\n\nggplot(diamonds2)+aes(x=price)+geom_histogram(bins=40)\n\n\n\n\nSi on souhaite une autre variable issue de stat_bin, comme par exemple la densité, il faudra utiliser\n\nggplot(diamonds2)+aes(x=price,y=..density..)+geom_histogram(bins=40)\n\n\n\n\nLes fonctions stat_ peuvent être utilisées à la place des geom_ pour certaines représentations. Chaque fonction stat_ possède par défaut un geom_ et réciproquement. On peut par exemple obtenir le même graphe que précédemment avec\n\nggplot(diamonds2)+aes(x=price,y=..density..)+stat_bin()\n\nVoici quelques exemple de fonctions stat_\n\n\nTable 5.2: Exemple de statistics\n\n\nStat\nDescription\nParamètres\n\n\n\n\nstat_identity()\naucune transformation\n\n\n\nstat_bin()\nCount\nbinwidth, origin\n\n\nstat_density()\nDensity\nadjust, kernel\n\n\nstat_smooth()\nSmoother\nmethod, se\n\n\nstat_boxplot()\nBoxplot\ncoef\n\n\n\n\nstat et geom ne sont pas toujours simples à combiner. Nous recommandons d’utiliser geom lorsqu’on débute avec ggplot, les statisticspar défaut ne doivent en effet être changés que rarement.\n\nExercice 5.7 (Diagramme en barres “très simple”…) On considère une variable qualitative \\(X\\) dont la loi est donnée par \\[P(X=\\text{red})=0.3,\\ P(X=\\text{blue})=0.2,\\ P(X=\\text{green})=0.4,\\ P(X=\\text{black})=0.1\\] Représenter cette distribution de probabilité avec un diagramme en barres.\n\nLa difficulté ici vient du fait que les hauteurs de barre sont données : il ne faut pas les calculer à partir des données. On n’a donc pas à utiliser stat_count de geom_bar, if faut faire appel à stat_identity:\n\n\nOn peut aussi utiliser l’aes weight :\n\n\n\nExercice 5.8 (Lissage) On étudie différentes façons de visualiser un lissage.\n\nReprésenter le lissage non linéaire de la variable price contre la variable carat à l’aide de geom_smooth puis de stat_smooth.\nMême question mais avec une ligne en pointillés à la place d’un trait plein.\n\n\n\n\n5.2.5 Scales\nLes échelles (scales) controlent tout un tas d’options telles que des changements de couleurs, d’échelles ou de limites d’axes, de symboles, etc… L’utilisation n’est pas simple et nécessite de la pratique. On utilise généralement ce verbe à la dernière étape de construction du graphe. La syntaxe est définie comme suit :\n\ndébut : scale_.\najout de l’aesthetics que l’on souhaite modifier (color_, fill_, x_).\nfin : nom de l’échelle (manual, identity…)\n\nPar exemple,\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()+\n  scale_color_manual(values=c(\"Fair\"=\"black\",\"Good\"=\"yellow\",\n                              \"Very Good\"=\"blue\",\"Premium\"=\"red\",\"Ideal\"=\"green\"))\n\n\n\n\nVoici quelques exemples des principales échelles :\n\n\nTable 5.3: Exemples d’échelles\n\n\naes\nDiscret\nContinu\n\n\n\n\nCouleur (color et fill)\nbrewer\ngradient\n\n\n-\ngrey\ngradient2\n\n\n-\nhue\ngradientn\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nPosition (x et y)\ndiscrete\ncontinous\n\n\n-\n\ndate\n\n\nForme\nshape\n\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nTaille\nidentity\nsize\n\n\n-\nmanual\n\n\n\n\n\nNous présentons quelques exemples d’utilisation des échelles :\n\nCouleur dans un diagramme en barres\n\np1 &lt;- ggplot(diamonds2)+aes(x=cut)+geom_bar(aes(fill=cut))\np1\n\n\n\n\nOn change la couleur en utilisant la palette Purples :\n\np1+scale_fill_brewer(palette=\"Purples\")\n\n\n\n\nGradient de couleurs pour un nuage de points :\n\np2 &lt;- ggplot(diamonds2)+aes(x=carat,y=price)+geom_point(aes(color=depth))\np2\n\n\n\n\nOn change le gradient de couleur\n\np2+scale_color_gradient(low=\"red\",high=\"yellow\")\n\n\n\n\nModifications sur les axes\n\np2+scale_x_continuous(breaks=seq(0.5,3,by=0.5))+\n  scale_y_continuous(name=\"prix\")+\n  scale_color_gradient(\"Profondeur\")\n\n\n\n\n\n\n\n5.2.6 Group et facets\nggplot permet de faire des représentations pour des groupes d’individus. On procède généralement de deux façons différentes :\n\nvisualisation de sous groupes sur le même graphe, on utilise l’option group dans le verbe aes ;\nvisualisation de sous groupes sur des graphes différents, on utilise le verbe facet_wrap ou facet_grid.\n\nReprésentons ici (sur le même graphe) le lisseur price vs carat pour chaque modalité de cut\n\nggplot(diamonds2)+aes(x=carat,y=price,group=cut)+\n  geom_smooth(method=\"loess\")\n\n\n\n\nPour obtenir cette représentation sur plusieurs fenêtres, on utilise\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut,nrow=1)\n\n\n\n\nfacet_grid et facet_wrap font des choses proches mais divisent la fenêtre d’une façon différente :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_grid(color~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_wrap(color~cut)"
  },
  {
    "objectID": "04-ggplot.html#compléments",
    "href": "04-ggplot.html#compléments",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.3 Compléments",
    "text": "5.3 Compléments\nLa syntaxe ggplot est définie selon le schéma :\n\nggplot()+aes()+geom_()+scale_()\n\nElle est très flexible, on peut par exemple spécifier les variables de aes dans les verbes ggplot ou geom_ :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()\n\n\n\nggplot(diamonds2,aes(x=carat,y=price))+geom_point()\n\n\n\nggplot(diamonds2)+geom_point(aes(x=carat,y=price))\n\n\n\n\nCeci peut se révéler très utile lorsqu’on utilise des aes différents dans les geom_.\nOn peut aussi construire un graphe à l’aide de différents jeux de données :\n\nX &lt;- seq(-2*pi,2*pi,by=0.001)\nY1 &lt;- cos(X)\nY2 &lt;- sin(X)\ndonnees1 &lt;- data.frame(X,Y1)\ndonnees2 &lt;- data.frame(X,Y2)\nggplot(donnees1)+geom_line(aes(x=X,y=Y1))+\n  geom_line(data=donnees2,aes(x=X,y=Y2),color=\"red\")\n\n\n\n\nIl existe d’autres fonctions ggplot :\n\nggtitle pour ajouter un titre.\nggsave pour sauver un graphe.\ntheme_ pour changer le theme du graphe.\n\n\np &lt;- ggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\np+theme_bw()\n\n\n\np+theme_classic()\n\n\n\np+theme_grey()\n\n\n\np+theme_bw()\n\n\n\n\nD’autres thèmes sont disponibles dans le package ggtheme. On pourra également parler de la fonction set_theme qui permet de modifier le thème par défaut pour un document quarto."
  },
  {
    "objectID": "04-ggplot.html#quelques-exercices-supplémentaires",
    "href": "04-ggplot.html#quelques-exercices-supplémentaires",
    "title": "5  Visualisation avec ggplot2",
    "section": "5.4 Quelques exercices supplémentaires",
    "text": "5.4 Quelques exercices supplémentaires\n\nExercice 5.9 (Fonctions cosinus et sinus) L’objectif est de visualiser les fonctions sinus et cosinus de plusieurs façons.\n\nTracer les fonctions sinus et cosinus. On utilisera tout d’abord les deux jeux de données suivants (un pour le sinus, l’autre pour le cosinus) :\n\ndonnees1 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X))\ndonnees2 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   sin=sin(X))\n\nFaire la même chose avec le jeu de données suivent qui regroupe les informations du cosinus et du sinus (on pourra ajouter une légende) :\n\ndonnees &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X),sin=sin(X))\n\nFaire la même chose avec un jeu de données et un seul appel à geom_line. On pourra utiliser la fonction pivot_longer du tidyverse.\nTracer les deux fonctions sur deux fenêtres graphiques (utiliser facet_wrap).\nFaire la même chose avec la fonction grid.arrange du package gridExtra.\n\n\n\nExercice 5.10 (Différents graphes) On considère les données mtcars\n\ndata(mtcars)\nsummary(mtcars)\n##       mpg             cyl             disp             hp       \n##  Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n##  1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n##  Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n##  Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n##  3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n##  Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n##       drat             wt             qsec             vs        \n##  Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n##  1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n##  Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n##  Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n##  3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n##  Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n##        am              gear            carb      \n##  Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n##  1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n##  Median :0.0000   Median :4.000   Median :2.000  \n##  Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n##  3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n##  Max.   :1.0000   Max.   :5.000   Max.   :8.000\n\n\nTracer l’histogramme de mpg (on fera varier le nombre de classes).\nTracer l’histogramme de la densité.\nTracer le diagramme en barres de cyl.\nTracer le nuage de points disp vs mpg en utilisant une couleur différente pour chaque valeur de cyl.\nAjouter le lisseur linéaire sur le graphe (un lisseur par modalité de cyl).\n\n\n\nExercice 5.11 (Résidus pour régression simple) On souhaite visualiser les résidus dans un modèle de régression simple.\n\nGénérer un échantillon \\((x_i,y_i),i=1,\\dots,100\\) selon le modèle linéaire \\[y_i=3+x_i+\\varepsilon_i\\] où les \\(x_i\\) sont i.i.d. de loi uniforme sur \\([0,1]\\) et les \\(\\varepsilon_i\\) sont i.i.d. de loi gaussienne \\(N(0,0.2^2)\\) (utiliser runif et rnorm).\nTracer le nuage de points Y vs X et ajouter le lisseur linéaire.\n\nOn le fait d’abord “à la main” en calculant l’équation de la droite de régression.\n\n\nOn peut avoir le tracé directement avec geom_smooth.\n\nReprésenter les résidus : on ajoutera une ligne verticale entre chaque point et la droite de lissage (utiliser geom_segment).\n\n\n\nExercice 5.12 (Challenge) On considère les données diamonds.\n\nTracer les graphes suivants.\n\n\n\n\n\n\n\n\n\n\n\n\nOn obtient les graphes demandés avec :\n\nAjouter sur le troisième graphe les quartiles de la variable carat pour chaque valeur de cut. On utilisera une ligne verticale.\n\n\n\n\n\n\nOn peut aussi l’obtenir avec stat_boxplot sans calculer explicitement les quartiles :\n\n\nou encore avec stat_summary :\n\nEn déduire le graphe suivant.\n\n\n\n\n\n\nOn l’obtient avec\n\n\nou encore\n\n\nou encore avec stat_summary :"
  },
  {
    "objectID": "05-carto.html#le-package-ggmap",
    "href": "05-carto.html#le-package-ggmap",
    "title": "6  Faire des cartes avec R",
    "section": "6.1 Le package ggmap",
    "text": "6.1 Le package ggmap\nNous montrons dans cette section comment récupérer des fonds de carte et ajouter quelques informations à l’aide de ggmap. Pour plus de détails sur ce package, on pourra consulter cet article pour plus de détails.\nggmap permet de récupérer facilement des fonds de carte. Par exemple :\n\nlibrary(tidyverse)\nlibrary(ggmap)\nus &lt;- c(left = -125, bottom = 25.75, right = -67, top = 49)\nmap &lt;- get_stamenmap(us, zoom = 5, maptype = \"toner-lite\")\nggmap(map)\n\n\n\n\nPour l’Europe on fait\n\neurope &lt;- c(left = -12, bottom = 35, right = 30, top = 63)\nget_stamenmap(europe, zoom = 5,\"toner-lite\") |&gt; ggmap()\n\n\n\n\nOn peut également changer le fond de carte\n\nget_stamenmap(europe, zoom = 5,\"toner-background\") |&gt; ggmap()\n\n\n\n\nPour la France, on aura\n\nfr &lt;- c(left = -6, bottom = 41, right = 10, top = 52)\nget_stamenmap(fr, zoom = 5,\"toner-lite\") |&gt; ggmap()\n\n\n\n\nLa fonction geocode de tiygecoder permet de récupérer des latitudes et longitudes à partir d’adresses :\n\ntbl &lt;- tibble(address=c(\"the white house\",\"Paris\",\"Rennes\"))\nlibrary(tidygeocoder)\ntbl |&gt; geocode(address)\n## # A tibble: 3 × 3\n##   address           lat   long\n##   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n## 1 the white house  38.9 -77.0 \n## 2 Paris            48.9   2.32\n## 3 Rennes           48.1  -1.68\n\n\nExercice 6.1 (Populations des grandes villes de france) \n\n\nRécupérer les latitudes et longitudes de Paris, Lyon et Marseille et représenter ces 3 villes sur une carte de la France.\nLe fichier villes_fr.csv contient les populations des 30 plus grandes villes de france. Représenter à l’aide d’un point les 30 plus grandes villes de France. On fera varier la taille du point en fonction de la population en 2014.\n\nAttention, la ville de Lille n’est pas bien écrite ! Il faut la renommer :\n\n\nOn calcule les coordonnées avec geocode et on représente les ville. Pour la taille des points, il suffit d’ajouter size=2014 dans l’aes du geom_point."
  },
  {
    "objectID": "05-carto.html#cartes-avec-contours-le-format-shapefile",
    "href": "05-carto.html#cartes-avec-contours-le-format-shapefile",
    "title": "6  Faire des cartes avec R",
    "section": "6.2 Cartes avec contours, le format shapefile",
    "text": "6.2 Cartes avec contours, le format shapefile\nggmap permet de récupérer facilement des fonds de cartes et de placer des points dessus avec la syntaxe ggplot. Cependant, de nombreuses fonctions de ca package nécessitent une API et il est difficile de définir des contours (frontières de pays, départements ou régions) avec ggmap. Nous proposons ici de présenter brièvement le package sf qui va nous permettre de créer des cartes “avancées”, en gérant les contours à l’aide d’objets particuliers mais aussi en prenant en compte différents systèmes de coordonnées. En effet, la terre n’est pas plate… mais une carte est souvent visualisée en 2D, il faut par conséquent réaliser des projections pour représenter des lieux définis par une coordonnée (comme la latitude et la longitude) sur une carte 2D. Ces projections sont généralement gérées par les packages qui permettent de faire de la cartographie comme sf. On pourra trouver de la documentation sur ce package aux url suivantes :\n\nhttps://statnmap.com/fr/2018-07-14-initiation-a-la-cartographie-avec-sf-et-compagnie/\ndans les vignettes sur la page du cran de ce package : https://cran.r-project.org/web/packages/sf/index.html\n\nCe package propose de définir un nouveau format sf adapté à la cartographie. Regardons par exemple l’objet nc\n\nlibrary(sf)\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"), quiet = TRUE)\nclass(nc)\n## [1] \"sf\"         \"data.frame\"\nnc\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\n## First 10 features:\n##     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n## 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n## 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n## 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n## 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n## 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n## 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n## 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n## 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n## 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n## 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n##    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n## 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n## 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n## 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n## 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n## 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n## 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n## 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n## 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n## 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n## 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\nCes données contiennent des informations sur les morts subites de nourissons dans des villes de Caroline du Nord. On remarque que l’objet nc est au format sf et data.frame. On peut donc l’utiliser comme un data.frame classique. Le format sf permet l’ajout d’une colonne particulière (geometry) qui délimitera les villes à l’aide de polygones. Une fois l’objet obtenu au format sf, il est facile de visualiser la carte avec un plot classique\n\nplot(st_geometry(nc))\n\n\n\n\nou en utilisant le verbe geom_sf si on veut faire du ggplot\n\nggplot(nc)+geom_sf()\n\n\n\n\nIl devient dès lors facile de colorier des villes et d’ajouter leurs noms :\n\nggplot(nc[1:3,]) +\n   geom_sf(aes(fill = AREA)) + \n   geom_sf_label(aes(label = NAME))\n\n\n\n\nLa colonne geometry de nc est au format MULTIPOLYGON, elle permettra donc de délimiter les frontières des villes. Si maintenant on souhaite représenter une ville à l’aide d’un point défini par sa latitude et longitude, il va falloir modifier le format de cette colonne geometry. On peut le faire de la manière suivante :\n\nOn récupère les latitudes et longitudes de chaque ville :\n\ncoord.ville.nc &lt;- nc |&gt; tidygeocoder::geocode(NAME)\n\nOn met ces coordonnées au format MULTIPOINT\n\ncoord.ville1.nc &lt;- coord.ville.nc |&gt; select(long,lat) |&gt; \n  filter(long&lt;=-77 & long&gt;=-85 & lat&gt;=33 & lat&lt;=37) |&gt; \n  as.matrix() |&gt; st_multipoint()  |&gt; st_geometry() |&gt; st_cast(to=\"POINT\")\ncoord.ville1.nc\n## Geometry set for 50 features \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -83.83378 ymin: 34.27511 xmax: -77.01151 ymax: 36.503\n## CRS:           NA\n## First 5 geometries:\n## POINT (-81.50766 36.43936)\n## POINT (-81.13408 36.503)\n## POINT (-80.70138 36.41356)\n## POINT (-77.01151 36.35605)\n## POINT (-80.22881 36.4121)\n\nOn indique que ces coordonnées sont des latitudes et longitude et on ajoute la colonne aux données initiales\n\nst_crs(coord.ville1.nc) &lt;- 4326 \n\nOn peut enfin représenter la carte avec les frontières et les points :\n\nggplot(nc)+geom_sf()+geom_sf(data=coord.ville1.nc)\n\n\n\n\n\nLe package sf possède également des fonctions très utiles pour traiter des données cartographiques, on peut citer par exemple :\n\nst_distance qui permet de calculer des distances entre coordonnées ;\nst_centroid pour calculer le centre d’une région ;\n…\n\nOn peut ainsi représenter les centres des villes délimitées par les polygones des données nc avec\n\nnc2 &lt;- nc |&gt; mutate(centre=st_centroid(nc)$geometry)\nggplot(nc2)+geom_sf()+geom_sf(aes(geometry=centre))\n\n\n\n\n\nExercice 6.2 (Première carte avec sf) Nous nous servons de la carte GEOFLAR proposée par l’Institut Géographique National pour récupérer un fond de carte contenant les frontières des départements français. Cette carte est disponible sur le site http: //professionnels.ign.fr/ au format shapefile, elle se trouve dans l’archive dpt.zip. Il faut décompresser pour reproduire la carte. Grâce au package sf, cette carte, contenue dans la série de fichiers département du répertoire dpt, peut être importée dans un objet R :\n\ndpt &lt;- read_sf(\"data/dpt\")\nggplot(dpt) + geom_sf()\n\n\n\n\nRefaire la carte de l’Exercice 6.1 sur ce fond de carte.\n\nOn définit tout d’abord un geometry au format MULTIPOINT. On le transforme ensuite en un “vecteur” de longueur 30 au format POINT que l’on ajoute dans la dataframe qui contient les coordonnées des villes.\n\n\nOn peut maintenant visualiser la carte demandée.\n\n\n\nExercice 6.3 (Visualisation de taux de chômage avec sf) Nous souhaitons visualiser graphiquement les différences de taux de chômage par département entre deux années. Pour cela, nous disposons de chaque taux mesuré aux premiers trimestres des années 2006 et 2011 (variables TCHOMB1T06, TCHOMB1T11) qui se trouvent dans le jeu de données tauxchomage.csv.\n\nImporter le jeu de données.\nFaire la jointure de cette table avec celle des frontières des départements. On pourra utiliser inner_join.\nComparer les taux de chômage en 2006 et 2011 (on le fera avec une carte pour les taux en 2006 et une autre pour les taux en 2011).\n\n\n\n6.2.1 Challenge 1 : carte des températures avec sf\nOn souhaite ici faire une carte permettant de visualiser les température en France à un moment donné. Les données se trouvent sur le site des données publiques de meteo france. On peut notamment récupérer\n\nles températures observées dans certaines stations en France les 15 derniers jours dans le lien téléchargement. On utilisera uniquement les identifiants de la station ainsi que la température observée (colonne t).\nla géolocalisation de ces stations dans le lien documentation\n\n\nImporter les 2 bases nécessaires. On pourra les lire directement sur le site. Convertir les degrés Kelvin en degrés Celsius et faire la jointure de ces bases.\nÉliminer les station d’outre mer (on pourra conserver uniquement les stations qui ont une longitude entre -20 et 25). On appellera ce tableau station1. Visualiser les stations sur la carte contenant les frontières des départements français.\nCréer un dataframe au format sf qui contient les températures des stations ainsi que leurs coordonnées dans la colonne geometry. On pourra commencer avec\n\nstation2 &lt;- station1 |&gt; select(Longitude,Latitude) |&gt; \n  as.matrix() |&gt; st_multipoint() |&gt; st_geometry()\nst_crs(station2) &lt;- 4326\nstation2 &lt;- st_cast(station2, to = \"POINT\")\n\nReprésenter les stations sur une carte de france. On pourra mettre un point de couleur différente en fonction de la température.\nOn obtient les coordonnées des centroïdes des départements à l’aide de\n\ncentro &lt;- st_centroid(dpt$geometry) \ncentro &lt;- st_transform(centro,crs=4326)\n\nOn déduit les distances entre ces centroïdes et les stations avec (df étant la table sf obtenue à la question 3).\n\nDD &lt;- st_distance(df,centro)\n\nPrédire la température de chaque département à l’aide de la règle du 1 plus proche voisin (la température du département \\(i\\) sera celle de la station la plus proche du centroïde de \\(i\\)).\nColorier les départements en fonction de la température prédite dans le département. On pourra faire varier le dégradé de couleur du jaune (pour les faibles températures) au rouge (pour les fortes).\n\nOn peut supprimer les lignes de frontières avec\n\n\n\n\n6.2.2 Trouver des cartes au format shapefile\nLe plus souvent on ne va pas construire les fonds de carte au format shapefile “à la main” et il est bien entendu important de récupérer ces fonds de carte au préalable. La méthode la plus courante consiste à taper les bons mots clefs sur un moteur de recherche… On pourra par exemple utiliser :\n\ndes packages R, par exemple rnaturalearth:\n\nworld &lt;- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\nclass(world)\n## [1] \"sf\"         \"data.frame\"\nggplot(data = world) +\ngeom_sf(aes(fill = pop_est)) +\nscale_fill_viridis_c(option = \"plasma\", trans = \"sqrt\")+theme_void()\n\n\n\n\nOn peut aussi visualiser la térre comme une sphère :\n\nggplot(data = world) +\ngeom_sf() +\ncoord_sf(crs = \"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs \")\n\n\n\n\nVoir https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html pour plus de détails.\nle web, par exemple le site data gouv:\n\nregions &lt;- read_sf(\"data/regions-20180101-shp/\")\n\nAttention, la taille des objets peut être très (trop) grande\n\n\nformat(object.size(regions),units=\"Mb\")\n## [1] \"15.4 Mb\"\n\net la construction de la carte peut dans ce cas prendre beaucoup de temps… On peut réduire la taille avec ce type d’outils\n\n\nlibrary(rmapshaper)\nregions1 &lt;- ms_simplify(regions)\nformat(object.size(regions1),units=\"Mb\")\n## [1] \"0.9 Mb\"\nggplot(regions1)+geom_sf()+\n  coord_sf(xlim = c(-5.5,10),ylim=c(41,51))+theme_void()"
  },
  {
    "objectID": "05-carto.html#cartes-interactives-avec-leaflet",
    "href": "05-carto.html#cartes-interactives-avec-leaflet",
    "title": "6  Faire des cartes avec R",
    "section": "6.3 Cartes interactives avec leaflet",
    "text": "6.3 Cartes interactives avec leaflet\nLeaflet est un package permettant de faire de la cartographie interactive. On pourra consulter un descriptif synthétique ici. Le principe est similaire à ce qui a été présenté précédemment : les cartes sont construites à partir de couches qui se superposent. Un fond de carte s’obtient avec les fonctions leaflet et addTiles\n\nlibrary(leaflet)\nleaflet() |&gt; addTiles()\n\n\n\n\n\nOn dispose de plusieurs styles de fonds de cartes (quelques exemples ici) :\n\nParis &lt;- tibble(V=\"Paris\") |&gt; tidygeocoder::geocode(V)\nm2 &lt;- leaflet() |&gt; setView(lng = as.numeric(Paris[1,3]), \n                           lat = as.numeric(Paris[1,2]), zoom = 12) |&gt; \n  addTiles()\nm2 |&gt; addProviderTiles(\"Stamen.Toner\")\n\n\n\n\n\n\nm2 |&gt; addProviderTiles(\"Esri.NatGeoWorldMap\")\n\n\n\n\n\n\nm2 |&gt;\n  addProviderTiles(\"Stamen.Watercolor\") |&gt;\n  addProviderTiles(\"Stamen.TonerHybrid\")\n\n\n\n\n\nIl est souvent utile de repérer des lieux sur une carte à l’aide de symboles. On pourra effectuer cela à l’aide des fonctions addMarkers et addCircles, par exemple :\n\ndata(quakes)\nleaflet(data = quakes[1:20,]) |&gt; addTiles() |&gt;\n  addMarkers(~long, ~lat, popup = ~as.character(mag))\n\n\n\n\n\nOn remarque que l’on utilise ici un tilde pour spécifier qu’on utilise des variables dans un dataframe.\nLe caractère interactif de la carte permet d’ajouter de l’information lorsqu’on clique sur un marker (grâce à l’option popup). On peut également ajouter des popups qui contiennent plus d’information, voire des liens vers des sites web :\n\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='http://www.samurainoodle.com'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() |&gt; addTiles() |&gt;\n  addPopups(-122.327298, 47.597131, content,\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\nExercice 6.4 (Popup avec leaflet) Placer un popup localisant l’Université Rennes 2 (Campus Villejean). On ajoutera un lien renvoyant sur le site de l’Université.\n\n\n6.3.1 Challenge 2 : Visualisation des stations velib à Paris\nPlusieurs villes dans le monde ont accepté de mettre en ligne les données sur l’occupation des stations velib. Ces données sont facilement accessibles et mises à jour en temps réel. On dispose généralement de la taille et la localisation des stations, la proportion de vélos disponibles… Il est possible de requêter (entre autres) :\n\nsur les données Decaux\nsur Open data Paris\nsur vlstats pour des données mensuelles ou historiques ou encore sur Velib pour obtenir des fichiers qui sont rafraîchis régulièrement.\n\n\nRécupérer les données actuelles de velib disponibles pour la ville de Paris : https://opendata.paris.fr/explore/dataset/velib-disponibilite-en-temps-reel/information/. On pourra utiliser la fonction read_delim avec l’option delim=\";\".\nDécrire les variables du jeu de données.\n\nNous avons de l’information sur la disponibilité, le remplissage… de stations velib parisiennes.\n\nCréer une variable latitude et une variable longitude à partir de la variable Coordonnées géographiques. On pourra utiliser la fonction separate du package tidyr.\nVisualiser les positions des stations sur une carte leaflet. On pourra utiliser l’option clusterOptions = markerClusterOptions() pour que la carte soit plus claire.\n\nLa carte est peu lisible, il y a en effet beaucoup de stations et il est difficile de bien les visualiser. Les choses deviennent plus claires en visualisant es groupes de station :\n\nAjouter un popup qui permet de connaitre le nombre de vélos disponibles (électriques+mécanique) quand on clique sur la station (on pourra utiliser l’option popup dans la fonction addCircleMarkers).\nAjouter la nom de la station dans le popup.\nFaire de même en utilisant des couleurs différentes en fonction de la proportion de vélos disponibles dans la station. On pourra utiliser les palettes de couleur\n\nColorPal1 &lt;- colorNumeric(scales::seq_gradient_pal(low = \"#132B43\", high = \"#56B1F7\",\n                                               space = \"Lab\"), domain = c(0,1.2))\nColorPal2 &lt;- colorNumeric(scales::seq_gradient_pal(low = \"red\", high = \"black\", \n                                               space = \"Lab\"), domain = c(0,1.2))\n\nCréer une fonction local.station qui permette de visualiser quelques stations autours d’une station choisie.\nLa fonction devra par exemple renvoyer\n\nlocal.station(\"Jussieu - Fossés Saint-Bernard\")\n\n\n\n\n\n\nlocal.station(\"Gare Montparnasse - Arrivée\")\n\n\n\n\n\n\n\n\n6.3.2 Carte des températures avec leaflet\n\nExercice 6.5 (Challenge) Refaire la carte des températures du premier challenge (voir Section 6.2.1) en utilisant leaflet. On utilisera la table construite dans le challenge 1 et la fonction addPolygons. On pourra également ajouter un popup qui permet de visualiser le nom du département ainsi que la température prévue lorsqu’on clique dessus.\n\nou avec une autre palette de couleur"
  },
  {
    "objectID": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "href": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "title": "7  Quelques outils de visualisation dynamique/interactive",
    "section": "7.1 Représentations classiques avec rAmCharts et plotly",
    "text": "7.1 Représentations classiques avec rAmCharts et plotly\nLe package rAmCharts est très utile pour donner un caractère interactif à des représentations graphiques standards (nuages de points, séries temporelles, histogrammes…). Ce package a été fait dans l’esprit d’utiliser les fonctions graphiques de R en utilisant le préfixe am. La syntaxe est très proche de celle des fonctions graphiques standards. On a par exemple :\n\nlibrary(rAmCharts)\namHist(iris$Petal.Length)\n\n\n\n\n\n\namPlot(iris, col = colnames(iris)[1:2], type = c(\"l\", \"st\"), \n       zoom = TRUE, legend = TRUE)\n\n\n\n\n\n\namBoxplot(iris)\n\n\n\n\n\nplotly permet de faire des choses semblables avec avec une syntaxe spécifique. Les commandes plotly se décomposent essentiellement en 3 parties :\n\nle type de représentation graphique (plot_ly}) ;\nles ajouts que l’on souhaite effectuer (add_trace) ;\nla gestion de la fenêtre graphique (axes, titres…) (layout).\n\nOn trouvera un descriptif complet de ces 3 composantes ici. On propose de tracer un nuage de points en dimension 2 et d’y ajouter la droite de régression. On commence par générer le nuage et ajuster le modèle linéaire :\n\nlibrary(plotly)\nn &lt;- 100\nX &lt;- runif(n,-5,5)\nY &lt;- 2+3*X+rnorm(n,0,1)\nD &lt;- data.frame(X,Y)\nmodel &lt;- lm(Y~X,data=D)\n\nOn effectue maintenant le tracé\n\nD |&gt; plot_ly(x=~X,y=~Y) |&gt;\n  add_markers(type=\"scatter\",mode=\"markers\",\n              marker=list(color=\"red\"),name=\"Nuage\") |&gt;\n  add_trace(y=fitted(model),type=\"scatter\",mode='lines',\n            name=\"Régression\",line=list(color=\"blue\")) |&gt; \n  layout(title=\"Régression\",xaxis=list(title=\"abscisse\"),\n         yaxis=list(title=\"ordonnées\"))\n\n\n\n\n\nContrairement à ggplot, plotly permet de faire de la 3D. Par exemple\n\nplot_ly(z = volcano, type = \"surface\")\nplot_ly(z = volcano, type = \"contour\")\n\n\nIl est possible de convertir des graphes ggplot au format plotly avec la fonction ggplotly :\n\np &lt;- ggplot(iris)+aes(x=Species,y=Sepal.Length)+geom_boxplot()+theme_classic()\nggplotly(p)\n\n\n\n\n\n\nExercice 7.1 (Graphes basiques avec rAmCharts et plotly) Pour le jeu de données iris on effectuera les graphes suivants en rAmCharts et plotly.\n\nNuage de points représentant les longueurs et largeurs de Sépales. On utilisera une couleur différente en fonction de l’espèce.\nBoxplot permettant de visualiser la distribution de la variable Petal.Length en fonction de l’espèce."
  },
  {
    "objectID": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "href": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "title": "7  Quelques outils de visualisation dynamique/interactive",
    "section": "7.2 Graphes pour visualiser des réseaux avec visNetwork",
    "text": "7.2 Graphes pour visualiser des réseaux avec visNetwork\nDe nombreuses données peuvent être visualisées à l’aide d’un graphe, notamment lorsqu’il s’agit de représenter des connexions entre individus. Un individu est alors représentés par un noeud et les individus connectés sont reliés par des arêtes. Le package igraph propose une visualisation statique d’un réseau. Pour donner un caractère dynamique à ce type de représentation, on pourra utiliser le package visNetwork. Une représentation standard visNetwork s’effectue en spécifiant les nœuds et connexions d’un graphe, par exemple :\n\nnodes &lt;- data.frame(id = 1:15, label = paste(\"Id\", 1:15),\n                    group=sample(LETTERS[1:3], 15, replace = TRUE))\nedges &lt;- data.frame(from = trunc(runif(15)*(15-1))+1,to = trunc(runif(15)*(15-1))+1)\nlibrary(visNetwork)\nvisNetwork(nodes,edges)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE,\n                                        nodesIdSelection = TRUE)\n\n\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(selectedBy = \"group\")\n\n\n\n\n\n\nExercice 7.2 (Interactions entre media) On considère un graphe qui représente des liens entre différents médias. Les données sont présentées ici et on peut les importer avec\n\nnodes &lt;- read.csv(\"data/Dataset1-Media-Example-NODES.csv\", header=T, as.is=T)\nlinks &lt;- read.csv(\"data/Dataset1-Media-Example-EDGES.csv\", header=T, as.is=T)\nhead(nodes)\n##    id               media media.type type.label audience.size\n## 1 s01            NY Times          1  Newspaper            20\n## 2 s02     Washington Post          1  Newspaper            25\n## 3 s03 Wall Street Journal          1  Newspaper            30\n## 4 s04           USA Today          1  Newspaper            32\n## 5 s05            LA Times          1  Newspaper            20\n## 6 s06       New York Post          1  Newspaper            50\nhead(links)\n##   from  to weight      type\n## 1  s01 s02     10 hyperlink\n## 2  s01 s02     12 hyperlink\n## 3  s01 s03     22 hyperlink\n## 4  s01 s04     21 hyperlink\n## 5  s04 s11     22   mention\n## 6  s05 s15     21   mention\n\nL’objet nodes représente les noeuds du graphe et l’objets links les arêtes. On définit l’objet graphe avec\n\nlibrary(igraph)\nmedia &lt;- graph_from_data_frame(d=links, vertices=nodes, directed=T) \nV(media)$name &lt;- nodes$media\n\net on peut le visualiser en faisant un plot de cet objet\n\nplot(media)\n\n\n\n\n\nVisualiser ce graphe avec VisNetwork. On pourra utiliser la fonction toVisNetworkData.\nAjouter une option qui permette de sélectionner le type de media (Newspaper, TV ou Online).\n\n\nUtiliser une couleur différente pour chaque type de media.\n\nIl suffit de donner le nom group à la variable type.label.\n\n\n\nFaire des flèches d’épaisseur différente en fonction du poids (weight). On pourra également ajouter l’option visOptions(highlightNearest = TRUE).\n\nIl suffit de donner le nom value à la variable weight."
  },
  {
    "objectID": "06-interactif.html#dashboard",
    "href": "06-interactif.html#dashboard",
    "title": "7  Quelques outils de visualisation dynamique/interactive",
    "section": "7.3 Dashboard",
    "text": "7.3 Dashboard\nUn tableau de bord permet de visualiser “facilement” et “rapidement” divers graphes et/ou résumés statistiques en lien avec une problématique donnée. Sur R le package flexdashboard permet de construire de tels tableaux de bord. On trouvera un descriptif précis de ce package à cette url : https://rmarkdown.rstudio.com/flexdashboard/. On utilisera cette documentation pour faire l’exercice suivant.\n\nExercice 7.3 (Dashboard pour modèles linéaires) On considère le jeu de données ozone.txt. Le problème est d’expliquer la concentration maximale en ozone quotidienne (variable maxO3) par d’autres variables météorologiques (températures et indicateurs de nébulosité relevés à différents moments de la journée…). On souhaite faire un tableau de bord qui permettra de :\n\nvisualiser les données : la base de données ainsi qu’un ou deux graphes descriptifs sur la variable à expliquer ;\nvisualiser les modèles linéaires simples : on choisit une variable explicative et on visualise le graphe de la régression ainsi que le modèle ;\nvisualiser le modèle linéaire complet : on affiche le résultat de la régression avec toutes les variables et on représente le graphe des résidus ;\nchoisir les variables explicatives.\n\n\nAvant de réaliser le dashboard, on propose d’écrire quelques commandes pour calculer les différentes sorties :\n\nOn considère uniquement les variables quantitatives du jeu de données. Visualiser les corrélations entre ces variables à l’aide de la fonction corrplot du package corrplot.\nReprésenter l’histogramme de la variable maxO3, on fera le graphe avec ggplot, rAmCharts et plotly (en utilisant ggplotly par exemple).\nConstruire le modèle linéaire permettant d’expliquer maxO3 par les autres variables. Calculer les résidus studentisés (rstudent) et visualiser ces résidus en fonction de la variable maxO3. Là encore on pourra ajouter un lisseur sur le graphe.\n\nOn peut maintenant passer au tableau de bord. On utilise le menu File -&gt; Rmarkdown -&gt; From Template -&gt; Flex Dashboard.\n\nConstruire un premier dashboard permettant de visualiser :\n\nle jeu de données sur une colonne (on pourra utiliser la fonction datatable du package DT)\nl’histogramme de la variable maxO3 ainsi que la matrice des corrélations entre les variables quantitatives.\n\nAjouter un nouvel onglet qui permet de visualiser le summary du modèle linéaire complet. On pourra utiliser la fonction datatable du package DT. Indication : ce nouvel onglet peut se créer avec\nAjouter un nouvel onglet qui permet de visualiser un modèle linéaire simple avec la variable explicative de votre choix. On pourra afficher dans cet onglet le summary du modèle ainsi que le nuage de points et la droite de régression.\nPour aller plus loin : ajouter un dernier onglet qui permette à l’utilisateur de choisir la variable explicative du modèle simple. Indications : on pourra utiliser les commandes Shiny\n\nChoix de la variable\n\nradioButtons(\"variable1\",\n            label=\"Choisir la variable explicative\",\n            choices=names(df)[-1],\n            selected=list(\"T9\"))\n\nMise à jour du résumé\n\nmod1 &lt;- reactive({\n  XX &lt;- paste(input$variable1,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  lm(form,data=df)\n  })\n#Df correspond au jeu de données\nrenderDataTable({\n  mod.sum1 &lt;- summary(mod1())$coefficients |&gt; round(3) |&gt; as.data.frame()\n  DT::datatable(mod.sum1,options = list(dom = 't'))\n})\n\nMise à jour du graph interactif\n\nrenderPlotly({\n  (ggplot(df)+aes(x=!!as.name(input$variable1),y=maxO3)+\n     geom_point()+geom_smooth(method=\"lm\")) |&gt; ggplotly()\n})\n\nEnfin il ne faudra pas oublier d’ajouter\n\nruntime: shiny\n\n\nAjouter un dernier onglet permettant de choisir les variables explicatives dans le modèle linéaire. Là encore on pourra utiliser des commandes Shiny, par exemple\n\ncheckboxGroupInput(\"variable\",\n                   label=\"Choisir la variable\",\n                   choices=names(df)[-1],\n                   selected=list(\"T9\"))\n\nPour les variables choisies, on affichera dans ce nouvel onglet les coefficients du modèle linéaire ainsi que le graphe des résidus studentisés.\n\n\nLe tableau de bord finalisé pourra ressembler à\n\n\n\n\nIl est disponible à l’url https://lrouviere.shinyapps.io/dashboard/"
  },
  {
    "objectID": "07-shiny.html#une-première-application",
    "href": "07-shiny.html#une-première-application",
    "title": "8  Applications web avec Shiny",
    "section": "8.1 Une première application",
    "text": "8.1 Une première application\nCréer un répertoire pour l’application avec RStudio\nFile -&gt; New Project -&gt; New Directory -&gt; Shiny Web Application\nChoisir une application Multiple File.\nSi cette option n’est pas disponible (ça peut dépendre des versions de Rstudio), on pourra utiliser\nFile -&gt; New File -&gt; Shiny Web App -&gt; Multiple File\nDeux fichier sont automatiquement générés : ui.R et server.R. Lancer l’application en cliquant sur le bouton Run App.\n\nChanger le titre de l’application. On pourra l’appeler My first application.\nMettre à jour et vérifier que le titre a bien été changé."
  },
  {
    "objectID": "07-shiny.html#input---output",
    "href": "07-shiny.html#input---output",
    "title": "8  Applications web avec Shiny",
    "section": "8.2 Input - output",
    "text": "8.2 Input - output\nOn garde la même application. On ne s’intéressera pas à la structure dans cette partie, on veut simplement ajouter\n\ndes nouveaux inputs dans le sidebarPanel, après le sliderInput. On n’oubliera pas de séparer les inputs par des virgules ;\ndes nouveaux outputs dans le mainPanel, après le plotOutput. Là encore, on n’oubliera pas de séparer les outputs par des virgules.\n\nPour résumer on souhaite une colonne avec tous les inputs et une autre avec tous les outputs.\n\nAjouter dans ui.R une entrée qui permette de changer la couleur de l’histogramme. On pourra utiliser\n\nselectInput(inputId = \"color\", label = \"Couleur :\",\n            choices = c(\"Rouge\" = \"red\", \"Vert\" = \"green\", \"Bleu\" = \"blue\"))\n\nAjouter une sortie qui permette de visualiser le summary du jeu de données faithful. On pourra utiliser\n\n# ui.R\nverbatimTextOutput(\"...\")\n\n# server.R\noutput$... &lt;- renderPrint({\n  summary(...)\n})\n\n\n\nExercice 8.1 (Ajouter des inputs/outputs) Ajouter des entrées/sorties à votre application pour\n\nproposer à l’utilisateur de choisir un titre pour l’histogramme (utiliser textInput dans l’ui et l’option main dans hist);\nchoisir la variable de faithful à représenter dans l’histogramme avec un radioButtons ayant pour choix colnames(faithful);\nvisualiser le jeu de données entier (renderDataTable & dataTableOutput);\najouter un text sous l’histogramme qui indique le nombre de classes (renderText et paste dans server, textOutput dans ui);\nremplacer le selectInput du choix de la couleur par un colourInput (utiliser la package colourpicker);\nexporter le graphe (downloadButton & jpeg).\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://input-output-rouviere-shiny.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#structurer-lapplication",
    "href": "07-shiny.html#structurer-lapplication",
    "title": "8  Applications web avec Shiny",
    "section": "8.3 Structurer l’application",
    "text": "8.3 Structurer l’application\nOn considère l’application app_structure disponible ici. C’est quasiment la même que précédemment avec un navbarPage qui définit\n\nun onglet Data pour visualiser les données (table + summary)\nun onglet Visualisation : inputs + histogramme.\n\n\nExercice 8.2 (Structurer son application) On conserve l’application précédente.\n\nDans l’onglet Data utiliser navlistPanel pour séparer le summary et la table table en deux onglets :\n\n# rappel de la structure (ui.R)\nnavlistPanel(\"Title of the structure\",\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\"),\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\")\n)\n\nDans l’onglet Visualization changer sidebarLayout - sidebarPanel - mainPanel par un fluidRow à 2 colonnes :\n\n1/4 : pour le sidebarPanel\n3/4 : pour le mainPanel.\n\n\nfluidRow(\n  column(width = 3, ...), # column 1/4 (3/12)\n  column(width = 9, ...)  # column 3/4 (9/12)\n)\n\nIndication : utiliser wellPanel pour la colonne de gauche.\nAjouter un bloxplot dans l’onglet visualisation (même variable et même couleur). On pourra également utiliser tabsetPanel pour avoir deux onglets pour l’histogramme et le boxplot.\n\n# rappel de la structure (ui.R)\ntabsetPanel(\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\"),\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\")\n)\n\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://structure-rouviere-shiny.apps.math.cnrs.fr/.\nPour aller plus loin : faire la même application avec shinydashboard."
  },
  {
    "objectID": "07-shiny.html#ajout-de-graphes-interactifs",
    "href": "07-shiny.html#ajout-de-graphes-interactifs",
    "title": "8  Applications web avec Shiny",
    "section": "8.4 Ajout de graphes interactifs",
    "text": "8.4 Ajout de graphes interactifs\nDans l’application précédente, remplacer l’histogramme et la boxplot par des graphes javascript réalisés avec rAmCharts. On pourra utiliser\n\n# server.R\noutput$distPlot &lt;- renderAmCharts({...})\n\n# ui.R\namChartsOutput(\"...\")\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://interactifs-rouviere-shiny-2.apps.math.cnrs.fr/.\n\nExercice 8.3 (Modèles linéaires pour l’ozone) On considère les données ozone.txt où le problème est d’expliquer la variable continue maxO3 par les autres variables du jeu de données. On propose de construire une application avec 3 onglets en utilisant (dans le ui.R) la structure suivante :\n\nnavbarPage(\n  title=\"Titre de l'appli\",\n  tabPanel(\n    title=\"Titre de l'onglet\",\n    ...\n  )\n)\n\n\nCréer le fichier global.R où on chargera les packages nécessaires et où on lira le jeu de données.\nConstruire le premier onglet où on visualisera :\n\nsur une ligne le jeu de données de façon dynamique : on pourra utiliser la fonction dataTableOutput dans le ui.R et la fonction renderDataTable dans le server.R.\nsur une autre ligne l’histogramme de la variable à expliquer et la matrice des corrélations des variables explicatives quatitatives. On pourra utiliser les commandes suivantes pour la matrice des corrélations :\n\ncorrplot::corrplot(cor(ozone[,2:11]))\n\nD’un point de vue structure on pourra utiliser la fonction fluidrow pour intégrer les deux graphes.\n\nAjouter un second onglet qui permettra de visualiser un modèle à une variable explicative que l’utilisateur choisira. On pourra utiliser radioButtons dans le ui.R pour choisir la variable et les commandes suivantes dans le server.R\n\nrenderDataTable({\n  XX &lt;- paste(input$...,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  mod &lt;- lm(form,data=ozone)\n  mod_sum1 &lt;- summary(mod)$coefficients |&gt; round(3) |&gt; as_tibble()\n  mod_sum1\n})\n\nOn pourra également visualiser le nuage de points et la droite de régression pour le modèle choisi par l’utilisateur.\nAjouter un troisième onglet où l’utilisateur pourra visualiser les estimateurs d’un modèle de régression multiple où il choisira les variables explicatives (avec checkboxGroupInput par exemple). On pourra éventuellement ajouter un graphe pour visualiser les résidus.\nChoisir un thème pour votre application en vous référant à la page suivante : https://rstudio.github.io/shinythemes/.\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici : https://ozone-rouviere-shiny-4.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#reactive-isolation-observe-html",
    "href": "07-shiny.html#reactive-isolation-observe-html",
    "title": "8  Applications web avec Shiny",
    "section": "8.5 Reactive, isolation, observe, html, …",
    "text": "8.5 Reactive, isolation, observe, html, …\nGarder la même application et\n\najouter un actionButton combiné à un isolate pour mettre à jour l’application uniquement lorsque l’utilisateur clique sur le bouton.\nUtiliser observeEvent pour forcer l’apparition de l’histogramme lorsqu’on met à jour l’application. On pourra utiliser\n\n# think to add  \"session\" \nshinyServer(function(input, output, session))\n\n# an id \ntabsetPanel(id = \"viz\",\n            tabPanel(\"Histogram\",...,))\n\n# and finaly\nobserveEvent(input$go, {\n  updateTabsetPanel(session, inputId = \"viz\",\n                    selected = \"Histogram\")})\n\n\nUtiliser reactive pour stocker la variable sélectionnée\n\n# Example of reactive\ndata &lt;- reactive({\n  ...\n})\n\noutput$plot &lt;- renderPlot({\n  x &lt;- data()\n  ...\n})\n\nAjouter un titre en bleu sur le jeu de données. On pourra utiliser h1\n\nh1(\"Dataset\", style = \"color : #0099ff;text-align:center\")\n\nAjouter un troisième onglet pour présenter un résumé de votre Université, avec un logo de l’institution et un lien vers son site web.\nPour aller plus loin : changer le thème de l’application avec un fichier de style .css. On pourra par exemple utiliser bootswatch http://bootswatch.com/3.\n\nL’application finale pourra ressembler à\n\n\n\n\nElle est également disponible ici https://plus-loin-rouviere-shiny-2.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#exercices-complémentaires",
    "href": "07-shiny.html#exercices-complémentaires",
    "title": "8  Applications web avec Shiny",
    "section": "8.6 Exercices complémentaires",
    "text": "8.6 Exercices complémentaires\n\nExercice 8.4 (Une application simple descriptive) On considère le jeu de données SAheart du package bestglm.\n\nA l’aide du package rAmCharts, représenter les histogrammes des variables quantitatives du jeu de données ainsi que les boxplots de ces variables en fonction de la variable chd.\nCréer une application shiny avec shinydashboard qui permette de\n\nchoisir une variable parmi les variables quantitatives du jeu de données. On pourra utiliser radioButtons avec l’argument\n\n\nchoices=names(SAheart)[sapply(SAheart,class)==\"numeric\"]\n\n\nvisualiser l’histogramme, puis le boxplot en fonction de chd de la variable sélectionnée. Ces graphiques devront être faits avec rAmCharts. On pourra utiliser amChartsOutput. L’application demandée pourra ressembler à\n\n\n\n\n\nElle est disponible ici https://lrouviere.shinyapps.io/DESC_APP.\n\n\n\nExercice 8.5 (Stations velib à Rennes) Réaliser une application qui permette de visualiser les stations velib à Rennes. Elle pourra être du même genre que celle-ci :\n\n\n\n\nOn peut avoir une meilleure vision ici : https://lrouviere.shinyapps.io/velib/. On récupérera les données sur le site de Rennes métropole : https://data.rennesmetropole.fr/explore/dataset/etat-des-stations-le-velo-star-en-temps-reel/export/"
  },
  {
    "objectID": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "href": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "title": "9  Estimation et intervalles de confiance",
    "section": "9.1 Générer des observations selon des lois de probabilités",
    "text": "9.1 Générer des observations selon des lois de probabilités\nR étant un logiciel de statistique, il est bien entendu possible de\n\nvisualiser\ncalculer des indicateurs (quantiles, probabilités…)\ngénérer des observations\n\npour toutes les lois classiques de probabilités. Chaque loi va être identifiée par une chaîne de caractères :\n\n\n\nLoi\nChaîne\n\n\n\n\nBinomiale\nbinom\n\n\nPoisson\npois\n\n\nUniforme\nunif\n\n\nExponentielle\nexp\n\n\nNormale\nnorm\n\n\n\nUn préfixe permettra de spécifier l’action que l’on souhaite effectuer sur la loi :\n\nd : calculer la densité pour une loi continue ou la fonction de masse pour une loi discrète\nq : calculer les quantiles\nr : générer des observations.\n\nOn pourra par exemple :\n\nCalculer la densité de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\ndnorm(c(-1,0,1),mean=0,sd=1)\n## [1] 0.2419707 0.3989423 0.2419707\n\nCalculer les quantiles d’ordre 0.05, 0.5 et 0.95 de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\nqnorm(c(0.05,0.5,0.95),mean=0,sd=1)\n## [1] -1.644854  0.000000  1.644854\n\nGénérer 10 observations selon une loi \\(\\mathcal N(0,1)\\) avec\n\nrnorm(10,mean=0,sd=1)\n##  [1] -0.29951433  0.78218262 -1.35751031 -0.23104990  0.83009903  0.06394242\n##  [7]  0.79726443 -1.32921071  1.08853438  1.73191221\n\n\n\nExercice 9.1 (Loi binomiale) On étudie les fonctions R associées à la loi binomiale.\n\nSoit \\(X\\) un variable de loi binomiale \\(B(20,0.6)\\). Calculer la probabilité que \\(X\\) soit égale à 1,5,10,15.\nPour la même loi calculer la probabilités : \\[\\mathbf P(X\\leq 13),\\quad\\mathbf P(X&gt;13),\\quad \\mathbf P(X\\geq 13)\\quad\\text{et}\\quad \\mathbf P(X\\in[8,15]).\\]\n\nPour la première il suffit d’utiliser pbinorm :\nOn remarque ensuite que \\[\\mathbf P(X&gt;13)=1-\\mathbf P(X\\leq 13)\\quad\\text{et}\\quad\\mathbf P(X\\geq 13)=\\mathbf P(X&gt;13)+\\mathbf P(X=13)\\]\ndonc\nPour la dernière, on utilise \\[\\mathbf P(X\\in[8,15]=\\mathbf P(X\\leq 15)-\\mathbf P(X\\leq 8)+\\mathbf P(X=8)\\]\nOn aurait aussi pu faire\n\nReprésenter le diagramme en barre associé à la loi \\(B(20,0.6)\\). On pourra utiliser l’argument stat=“identity” dans la fonction geom_bar.\nGénérer un échantillon de taille 5000 selon la loi \\(B(20,0.6)\\). Tracer le diagramme en barres associé à cet échantillon et comparer le à celui de la question précédente.\n\nOn peut visualiser les digrammes en barres cote à cote avec\n\n\n\n\nExercice 9.2 (Loi normale) On considère ici la loi normale \\(\\mathcal N(\\mu,\\sigma^2)\\).\n\nTracer la densité de la loi \\(\\mathcal N(0,1)\\).\nSoit \\(X\\) une variable aléatoire de loi \\(\\mathcal N(2,2^2)\\) (variance 4, écart-type 2). Calculer les probabilités suivantes : \\[\\mathbf P(X=2),\\quad \\mathbf P(X\\leq 2),\\quad \\mathbf P(X&lt;2),\\quad \\mathbf P(X&gt;3).\\]\n\nLa première probabilité est nulle. Les deux suivantes sont égales et valent\n\n\nOn obtient la dernière avec\n\nGénérer un échantillon de taille 5000 selon la loi \\(\\mathcal N(0,1)\\). Tracer l’histogramme associé à cet échantillon et comparer le à la densité tracée à la question précédente (on pourra supperposer les 2 représentations)."
  },
  {
    "objectID": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "href": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "title": "9  Estimation et intervalles de confiance",
    "section": "9.2 Une étude numérique de la moyenne empirique.",
    "text": "9.2 Une étude numérique de la moyenne empirique.\nOn considère un échantillon de \\(x_1,\\dots,x_n\\) i.i.d de loi uniforme sur \\([a,b]\\) avec \\(a\\) et \\(b\\) supposés inconnus. Le problème est d’estimer l’espérance de cette loi uniforme \\[\\mathbf E[X]=\\frac{a+b}{2}.\\]\nUn estimateur naturel est la moyenne empirique \\[\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i\\] Remarquons déjà que la moyenne empirique dépend des observations \\(x_1,\\dots,x_n\\) : la moyenne va donc changer lorsque les observations changent.\n\n9.2.1 Exemple\nPour fixer les idées, on suppose dans cette partie que \\(a=0\\) et \\(b=1\\). L’espérance à estimer vaut donc 0.5 (on peut faire comme si on le la connaissait pas.)\nOn considère deux échantillons de taille 20 générées selon une loi uniforme entre 0 et 1 :\n\nech1 &lt;- runif(20)\nech2 &lt;- runif(20)\ndf &lt;- data.frame(ech1,ech2)\n\nLes moyennes empiriques pour ces deux échantillons sont différentes :\n\ndf |&gt; summarise_all(mean)\n##        ech1     ech2\n## 1 0.3327998 0.527143\n\nLa moyenne empirique peut-être considérée comme une variable aléatoire : elle va donc posséder une loi de probabilité, une espérance… Si on considère l’exemple précédent, on sent bien que la distribution de la moyenne empirique doit\n\nse répartir autours de 0.5 (qui est la valeur à estimer).\nêtre de plus en plus concentrée autours de 0.5 lorsque le nombre d’observations \\(n\\) augmente.\n\nOn peut visualiser ce fait en considérant un grand nombre d’échantillon et en regardant comment se comporte les valeurs moyennes de chaque échantillon. Pour cela on\n\ngénère un nombre \\(B\\) (grand) d’échantillons de taille \\(n=20\\) selon une loi uniforme entre 0 et 1.\n\nset.seed(1234)\ndf &lt;- matrix(runif(20*5000),nrow=20) |&gt; as.data.frame()\n\ncalcule les moyennes obtenues pour chaque échantillon\n\nmoy &lt;- df |&gt; summarize_all(mean)\nhead(t(moy))\n##         [,1]\n## V1 0.4719301\n## V2 0.4449401\n## V3 0.4833523\n## V4 0.3740339\n## V5 0.4132300\n## V6 0.3734092\n\nvisualise la distribution de la moyenne de chaque échantillon (en traçant l’histogramme de ces valeurs par exemple).\n\nmoy &lt;- data.frame(M=t(moy))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+theme_classic()\n\n\n\n\n\nOn voit que cette distribution semble se comporter comme une distribution gaussienne autours de la vraie valeur (0.5). Le théorème central limite confirme (et surtout prouve) ce constat. En effet, le théorème central limite nous dit que cette moyenne \\(\\bar x_n\\) vérifie \\[\\sqrt{n}\\frac{\\bar x_n-\\mu}{\\sigma}\\to \\mathcal N(0,1)\\] avec \\(\\mu=0.5\\) et \\(\\sigma=1/\\sqrt{12}\\) ici. On a donc \\[\\sqrt{n}\\frac{\\bar X_n-0.5}{1/\\sqrt{12}}\\to \\mathcal N(0,1)\\] Ce qui signifie qu’on peut approcher la loi de \\(\\bar X_n\\) par la loi \\(\\mathcal N(0.5,1/(12n))\\) avec \\(n=20\\). On le retrouve sur notre exemple en supperposant cette distribution gaussienne sur l’histogramme\n\nx &lt;- seq(0.25,0.75,by=0.001)\ndf &lt;- data.frame(x=x,y=dnorm(x,0.5,1/(sqrt(12*20))))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=2)+xlab(\"x\")\n\n\n\n\n\nExercice 9.3 (Théorème central limite) Faire le même travail pour des tailles d’échantillon de 50, 100 et 500. Interpréter.\n\nOn remarque que :\n\ndans tous les cas, la distribution de la moyenne empirique semble être gaussienne et centrée en 0.5 (qui est la valeur à estimer).\nla dispersion augmente lorsque le nombre d’observations \\(n\\) diminue (moins précis).\n\n\n\n\nExercice 9.4 (Théorème central limite (toujours)) Faire le même exercice pour une loi gaussienne \\(\\mathcal N(1,2)\\) et une loi de Bernoulli \\(\\mathcal B(0.6)\\).\n\nPour la loi \\(\\mathcal N(1,2)\\)\nPour la \\(\\mathcal B(0.6)\\)\nDans tous ces cas, on retrouve bien que la moyenne empirique a une distribution gaussienne autours de la valeur à estimer (l’espérance). La dispersion dépend de :\n\nla dispersion des observations (de la loi de \\(x_i\\)) ;\ndu nombre d’observations.\n\nLa moyenne empirique est donc d’autant plus précise que la variance des observations est petite et que le nombre d’observations est grand. Le théorème central limite permet de quantifier tout ça et donc de déduire des intervalles de confiance et de faire des tests…"
  },
  {
    "objectID": "08-estimation.html#intervalles-de-confiance",
    "href": "08-estimation.html#intervalles-de-confiance",
    "title": "9  Estimation et intervalles de confiance",
    "section": "9.3 Intervalles de confiance",
    "text": "9.3 Intervalles de confiance\nOn cherche ici à illustrer numériquement le niveau d’un intervalle de confiance. On rappelle que \\([A,B]\\) est un IC de niveau \\(1-\\alpha\\) pour un paramètre \\(\\theta\\) si \\[P(\\theta\\in[A,B])=1-\\alpha.\\]\n\nExercice 9.5 (IC pour l’espérance d’une gaussienne) On fixe ici le niveau à 0.95 (\\(\\alpha=0.05\\)). On considère \\(n\\) observations \\(x_1,\\dots,x_n\\) i.i.d de loi \\(\\mathcal N(\\mu,1)\\) et on cherche un intervalle de confiance pour \\(\\mu\\).\n\nGénérer \\(n=100\\) observations i.i.d. selon la loi \\(\\mathcal N(\\mu,1)\\) avec \\(\\mu=1\\).\nCalculer un intervalle de confiance pour \\(\\mu\\) de niveau 0.95.\nSelon-vous, peut-on dire que la probabilité que \\(\\mu\\) appartienne à l’intervalle trouvé est de 0.95 ? Si non, comment peut-on interpréter cette formule.\n\nNon. Dans notre cas, \\(\\mu\\) (qui vaut 1) appartient à l’intervalle trouvé. Dans la vraie vie, \\(\\mu\\) est inconnu. Ce que la formule nous dit, c’est que si nos données sont issues d’un loi \\(\\mathcal N(\\mu,\\sigma^2)\\), on a une probabilité de 0.95 que \\(\\mu\\) appartienne à l’intervalle trouvé. Donc si on génère un très grand nombre d’échantillon i.i.d selon la loi \\(\\mathcal N(\\mu,\\sigma^2)\\), alors dans 95% des cas, la vraie valeur de \\(\\mu\\) appartiendra à l’intervalle trouvé. C’est ce qu’on propose de vérifier dans les questions suivantes.\n\nGénérer 5000 échantillons i.i.d. de loi \\(\\mathcal N(1,1)\\) de tailles 100. On pourra mettre le tout dans une matrice de dimension \\(5000\\times 100\\).\nCalculer un intervalle de confiance de niveau 0.95 pour chacun des 5000 échantillons. On pourra utiliser une boucle for ou la fonction apply.\nSur les 5000 intervalles obtenus, calculer le nombre de fois où la vraie valeur de \\(\\mu\\) (en l’occcurence ici 1) se trouve à l’intérieur de l’intervalle.\nRefaire les questions 5-6-7 avec des IC de niveau 0.90.\n\n\n\nExercice 9.6 (IC pour les iris de Fisher) On considère les données sur les iris de Fisher. Construire un intervalle de confiance de niveau 90% pour les paramètres suivants :\n\nLa longueur de Pétales moyenne\nLa largeur de Sépales moyenne de l’espèce Setosa\nLa largeur de Sépales moyenne des espèces Versicolor et Virginica\n\n\n\nExercice 9.7 (IC pour une proportion) On considère \\(x_1,\\dots,x_n\\) un échantillon i.i.d issu d’une loi de Bernoulli de paramètre \\(p\\in[0,1]\\) inconnu.\n\nProposer un estimateur \\(\\widehat p\\) pour \\(p\\).\n\nOn peut prendre \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\]\n\nA l’aide du TCL, obtenir la loi asymptotique de \\(\\hat p\\).\n\nOn a d’après la TCL\n\\[\\sqrt{n}\\frac{\\widehat{p}-p}{\\sqrt{p(1-p)}}\\stackrel{\\mathcal L}{\\to}\\mathcal N(0,1)\\]\n\nEn déduire un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(p\\).\n\nOn déduit que \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right].\\]\nest un IC de niveau \\(1-\\alpha\\).\n\nQue pouvez-vous reprocher à l’intervalle proposé à la question précédente ?\n\nL’IC proposé dépend de \\(p\\) qui est inconnu ! Il ne sera donc pas calculable en pratique !\n\nProposer une solution.\n\nUn solution classique consiste à remplacer le paramètre \\(p\\) inconnu par son estimateur \\(\\widehat p\\). On obtient ainsi l’IC \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}\\right].\\]\n\n\n\n\nExercice 9.8 (IC pour une proportion (suite)) Afin de tenter de deviner qui va gagner une élection entre deux candidats \\(A\\) et \\(B\\) on effectue un sondage. On demande à 100 personnes pour qui elles vont voter. Les résultats sont reportés dans le vecteur suivant.\n\nset.seed(12345)\nres &lt;- rbinom(100,1,0.52)\n\nOn désigne par \\(p\\) la propotion (inconnue) d’électeurs qui vont voter pour \\(A\\).\n\nProposer et calculer un estimateur de \\(p\\).\n\nOn peut prendre la moyenne empirique \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\] On la calcule avec\n\nQue pouvez-vous conclure a priori.\n\nIl semble que \\(A\\) va remporter l’élection.\n\nEn vous basant sur l’exercice précédent, calculer un intervalle de confiance de niveau 95% pour \\(p\\).\n\nOn le calcule avec\n\nEst-ce que l’intervalle obtenu conforte votre conclusion de la question 2 ?\n\nNon, en effet 0.5 se trouve dans l’intervalle de confiance !\n\nCalculer un intervalle de confiance pour \\(p\\) à l’aide de la fonction prop.test.\n\nOn remarque que l’IC obtenu ne correspond pas exactement à celui que nous avons calculé à la question 3. La fonction prop.test utilise une solution plus pertinente que de remplacer \\(p\\) par son estimateur. La correction utilisée dans prop.test est plus préciser, il est recommandé d’utiliser celle là.\n\n\n\n\nExercice 9.9 (Comparaison de moyennes) Pour le jeu de données decathlon disponible ici\n\nlibrary(FactoMineR)\ndata(decathlon)\n\non souhaite comparer les performances au 100m en fonction de la compétition (Decastar vs JO).\n\nCalculer un intervalle de confiance de niveau 95% pour la vitesse moyenne au 100m au Decastar.\nMême question pour les jeux olympiques.\nPouvez-vous conclure sur la question posée ? Si non, que faire ?\n\nIl n’est pas possible de conclure. La bonne approche consiste à calculer un intervalle de confiance sur la différence moyenne des performances au 100m entre les deux compétitions et de regarder si 0 se situe dans l’intervalle.\nOn obtient l’intervalle avec\n\n\n0 n’étant pas dans l’intervalle, on conclut que les performances sont différentes. On verra par la suite que les tests d’hypothèses permettent de traiter ce genre de questions de façons plus efficace."
  },
  {
    "objectID": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "href": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "title": "10  Régression avec R",
    "section": "10.1 Modèle linéaire : fonctions lm et predict",
    "text": "10.1 Modèle linéaire : fonctions lm et predict\n\nExercice 10.1 (Fonctions standards pour le modèle linéaire) On considère le modèle de régression linéaire \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] où \\(X_1,\\dots,X_p\\) sont les variables explicatives, \\(Y\\) la variable à expliquer et \\(\\varepsilon\\) le terme d’erreur. On fixe \\(p=5\\) et on considère les données suivantes :\n\nn &lt;- 1000\np &lt;- 5\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nConstruire un modèle linéaire permettant d’expliquer \\(Y\\) par \\(X_1,\\dots,X_5\\) (utiliser la fonction lm) et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_5\\) (on pourra utiliser les fonctions coef et summary).\nOn considère le jeu de données test suivant.\n\nm &lt;- 500\np &lt;- 5\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=5)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nCalculer, pour chaque individu de ce nouveau jeu de données, les prédictions faites par le modèle de la question précédente (utiliser la fonction predict avec l’option newdata).\nCréer un nouveau dataframe qui contiennent les valeurs prédites \\(\\widehat y_i\\) à la question précédente sur une colonne et les valeurs observées \\(y_i\\) du jeu de données df.test sur une autre colonne.\nA l’aide du verbe summarize, calculer l’erreur quadratique moyenne (estimée) du modèle linéaire : \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2.\\]"
  },
  {
    "objectID": "09-regression.html#sélection-de-variables",
    "href": "09-regression.html#sélection-de-variables",
    "title": "10  Régression avec R",
    "section": "10.2 Sélection de variables",
    "text": "10.2 Sélection de variables\n\nExercice 10.2 (Sélection de variables) On considère les données suivantes\n\nn &lt;- 1000\np &lt;- 105\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nissues du modèle \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] avec \\(p=105\\). On remarquera que seules les variables \\(X_1,\\dots,X_5\\) sont explicatives.\n\nAjuster un modèle linéaire (fonction lm) sur df et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_{105}\\).\nOn propose d’utiliser une procédure de sélection de variables backward à partir du critère BIC. Effectuer cette procédure à l’aide de la fonction step (on pourra utiliser les options direction=“backward” et k=log(n)). On appellera ce modèle mod.step.\n\nOn a sélectionné un modèle avec 8 variables : les 5 explicatives et 3 variables de bruit.\n\nCalculer les erreurs quadratiques de prévision \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2\\] des deux modèles (le modèle complet et le modèle sélectionné) en utilisant le jeu de données test suivant.\n\nm &lt;- 300\np &lt;- 105\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=p)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nOn calcule les prévisions et on les intègre dans un tibble :\n\n\nOn en déduit les erreurs quadratiques moyennes :"
  },
  {
    "objectID": "09-regression.html#régression-logistique-et-arbre",
    "href": "09-regression.html#régression-logistique-et-arbre",
    "title": "10  Régression avec R",
    "section": "10.3 Régression logistique et arbre",
    "text": "10.3 Régression logistique et arbre\n\nExercice 10.3 On considère le jeu de données spam disponible ici\n\nlibrary(kernlab)\ndata(spam)\n\nLe problème est d’expliquer la variable type (un email est un spam ou non) par les 57 autres variables.\n\nSéparer les données en un échantillon d’apprentissage dapp de taille 3000 et un échantillon test dtest de taille 1601. On pourra utiliser la fonction sample.\nConstruire un modèle logistique permettant de répondre au problème en utilisant uniquement les données d’apprentissage. On utilisera la fonction glm avec l’option family=\"binomial\".\nA l’aide de la fonction step, effectuer une sélection backward (ça peut prendre quelques minutes).\nA l’aide de la fonction rpart du package rpart, construire un arbre de régression (toujours sur les données d’apprentissage) pour répondre au problème. On utilisera les paramètres par défaut de la fonction.\nVisualiser l’arbre construit à l’aide des fonctions rpart.plot et visTree des packages rpart.plot et visNetwork\nPour les 3 modèles construits (logistique, backward et arbre) calculer les prédictions de la variable type pour les individus de l’échantillon dtest. On pourra regrouper ces prévisions dans un data-frame à 3 colonnes.\nAjouter au data-frame précédent une colonne où on mettra les valeurs observées de la variable à expliquer.\nA l’aide de summarize_at calculer les erreurs de classification des 3 modèles.\nReprésenter les courbes ROC et calculer les AUC. On pourra consulter les pages 346 et 347 dans Cornillon et al. (2018) pour le tracé de courbes ROC sur R.\n\n\n\n\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Références",
    "section": "",
    "text": "Barnier, J. 2020. Introduction à r Et Au Tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N.\nKlutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, and B.\nThieurmel. 2018. R Pour La Statistique Et La Science Des\nDonnées. PUR. https://r-stat-sc-donnees.github.io.\n\n\nWickham, A., and G. Grolemund. 2017. R for Data Science.\nO’Reilly. https://r4ds.had.co.nz."
  }
]