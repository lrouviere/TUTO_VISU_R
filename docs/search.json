[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visualisation avec R",
    "section": "",
    "text": "Présentation\nCe tutoriel présente une introduction au logiciel R ainsi qu’à quelques outils de visualisation avec R. On pourra trouver :\n\nles supports de cours associés à ce tutoriel ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html ;\nle tutoriel sans les corrections à l’url https://lrouviere.github.io/TUTO_VISU_R/\nle tutoriel avec les corrigés (à certains moments) à l’url https://lrouviere.github.io/TUTO_VISU_R/correction/.\n\nIl est recommandé d’utiliser mozilla firefox pour lire le tutoriel.\nLes thèmes suivants sont abordés :\n\nLogiciel R\n\nPrésentation du logiciel, environnement Rstudio, reporting avec quarto et Rmarkdown\nObjets R\nManipulation des données (essentiellement avec dplyr)\n\nVisualisation\n\nVisualisation statique (représentations standards et avec ggplot2)\nCartographie\n\nstatique avec ggmap et sf\ndynamiques avec leaflet\n\nVisualisation dynamique\n\ngraphes standards avec RamChartset plotly\nréseaux avec visNetwork\ntableaux de bord avec flexdashboard\n\n\nUn peu de statistique avec R\n\nRégression : ajustement de modèles, formules, prévisions…\nIntroduction au problème de l’estimation, lois de probabilités, notions d’estimateurs, performance d’estimateurs, intervalles de confiance.\n\n\nOn pourra trouver des supports de cours ainsi que les données utilisées à l’adresse suivante https://lrouviere.github.io/page_perso/visualisationR.html. Des compléments sur les outils du tidyverse pourront être consultés dans le très complet document de Barnier (2020) ainsi que les ouvrages de Wickham et Grolemund (2017) et de Cornillon et al. (2018).\n\n\n\n\nBarnier, J. 2020. Introduction à R et au tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io.\n\n\nWickham, A., et G. Grolemund. 2017. R for Data Science. O’Reilly. https://r4ds.had.co.nz."
  },
  {
    "objectID": "01-intro.html#r-script",
    "href": "01-intro.html#r-script",
    "title": "1  Introduction",
    "section": "1.1 R Script",
    "text": "1.1 R Script\nIl existe différentes façons de travailler sur RStudio. De façon classique, on peut\n\nouvrir un script.\nentrer les commandes dans le script.\nregarder les sorties dans la console (en cliquant sur le bouton run).\nsauver le script."
  },
  {
    "objectID": "01-intro.html#packages",
    "href": "01-intro.html#packages",
    "title": "1  Introduction",
    "section": "1.2 Packages",
    "text": "1.2 Packages\nUn package est une ensemble de programmes et fonctions R qui complètent les fonctions existantes par défaut dans le logiciel. Un package est généralement dédié à une méthode ou un champ d’application spécifique. Il existe plus de 18 000 packages disponibles sur le CRAN https://cran.r-project.org. On installe un package en\n\nutilisant le fonction install.packages dans la console. ou\nou cliquant sur le bouton Packages.\n\nUne fois le package installé sur la machine, on l’installe avec la fonction library :\n\ninstall.packages(package.name)\nlibrary(packages.name)\n\n\nExercice 1.1 (Installation et chargement) \n\n\nExécuter\n\niris |&gt; summarize(mean_Petal=mean(Petal.Length))\n\nQue se passe t-il ?\n\nOn a un message d’erreur. L’opérateur |&gt; n’est pas reconnu.\n\nInstaller et charger le package tidyverse et ré-exécuter le code précédent.\n\ninstall.packages(\"tidyverse\")\n\n\nlibrary(tidyverse)\niris |&gt; summarize(mean_Petal=mean(Petal.Length))\n\n  mean_Petal\n1      3.758"
  },
  {
    "objectID": "01-intro.html#quarto",
    "href": "01-intro.html#quarto",
    "title": "1  Introduction",
    "section": "1.3 Quarto",
    "text": "1.3 Quarto\nQuarto est un langage, compatible avec notamment R et Python, qui permet de créer différents types de documents :\n\nrapports au format pdf ou rtf\npages web html\ndiaporama pour des présentations (html, beamer, PowerPoint…)\napplications web interactives\n…\n\nqui comportent du code R.\n\n1.3.1 Syntaxe\nLa syntaxe s’apprend assez facilement (il faut pratiquer), on pourra trouver un descriptif synthétique sur la page https://quarto.org ainsi que dans la cheatsheet dédiée à Rmarkdown puisque quarto est compatible avec markdown. Par exemple :\n\nCaractère en italique ou gras : *italique* et **gras** donne italique et gras\nListes non ordonnées\n- item 1\n- item 2\nproduit\n\nitem 1\nitem 2\n\nliste ordonnée :\n1. item 1\n2. item 2\nproduit\n\nitem 1\nitem 2\n\ntableau :\n|      | Col1 | Col2 | Col3 |\n|:----:|:----:|:----:|:----:|\n| Row1 |  1   |   2  |   3  |\n| Row2 |  1   |   2  |   3  |\nrenvoie\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nRow1\n1\n2\n3\n\n\nRow2\n1\n2\n3\n\n\n\n\néquation latex :\n$$\\int_a^b f(x)dx=1$$\nrenvoie \\[\\int_a^b f(x)dx=1\\]\n\n\n\n1.3.2 Les chunks\nLe code R doit être écrit dans des chunks. On peut insérer des chunks avec :\n\nla raccourci clavier Ctrl + Alt + I (OS X: Cmd + Option + I)\nla bouton Insert -&gt; Code Chunk -&gt; R\nen tapant :\n\n```{r}\ncommandes...\n```\nPlusieurs options peuvent être spécifiés au chunk en fonction de ce que l’on souhaite voir dans le document, par exemple :\n\necho : TRUEor FALSE pour spécifier si on souhaite afficher le code ;\neval : TRUEor FALSE pour spécifier si le code doit être évalusé ou non ;\nresults : hide si on ne veut pas voir la sortie du code.\n\nOn pourra trouver l’ensemble des options disponibles sur cette page : https://yihui.org/knitr/options/\n\nExercice 1.2 (Premier document) \n\n\nOuvrir un document quarto (File -&gt; New File -&gt; Quarto Document).\nCliquer sur le bouton Render et visualiser la sortie html.\nObtenir une sortie pdf.\nModifier le document en créant une section Cosinus dans laquelle on tracera la fonction cosinus, on pourra utiliser le code suivant dans un chunk.\n\nx &lt;- seq(-2*pi,2*pi,by=0.01)\ny &lt;- cos(x)\nplot(x,y,type=\"l\")\n\nAjouter une section Sinus dans laquelle on tracera la fonction sinus.\n\n\n\n\n1.3.3 Notebook\nL’environnement notebook fonctionne exactement comme un document markdown mais permet de visualiser la sortie eu format html sans avoir à recompiler le document en entier. Cet environnement est donc souvent privilégié pendant la réalisation d’un projet en science des données. Pour créer un notebook, on peut passer par RStudio : File -&gt; New File -&gt; R Notebook ou simplement remplacer\noutput: html_document\npar\noutput: html_notebook\ndans l’entête d’un document markdown.\n\nTransformer le document markdown de l’exercice précédent en notebook. On pourra visualier la sortie en cliquant sur Preview.\n\n\n\n1.3.4 Diaporama R\nRstudio propose aussi différents environnements pour construire des diaporamas. On pourra utiliser le menu File -&gt; New File -&gt; Quarto Presentation . On utilisera la même syntaxe que pour les documents markdown. Les slides sont séparés par le symbole ## et les codes R sont toujours insérés dans des chunks.\n\nExercice 1.3 (Premier document)  \n\nCréer 2 diapositives :\n\nTitre : Cosinus où on tracera la fonction cosinus.\nTitre : Sinus où on tracera la fonction sinus.\n\nEn modifiant les options des chunks modifier les diapositives de manière à\n\nne pas voir le code R mais voir les graphiques\nvoir uniquement le code R mais pas les graphiques.\n\n\n\n\n\n1.3.5 Exemples de styles de documents Quarto\nPar défaut l’entête d’un document quarto est de la forme\n---\ntitle: \"Mon document\"\nauthor: \"Laurent\"\nformat: html\neditor: visual\n---\nIl existe un grand nombre d’options qui permettent d’améliorer le document final. On peut par exemple changer la langue et ajouter une table des matières avec\nlang: fr\ntoc: true\nOn peut également utiliser des styles prédéfinis en changeant le thème, par exemple\ntheme: cerulean\n\n\n\n\n\nOn pourra trouver des compléments sur les différents styles et options ici : https://quarto.org/docs/output-formats/html-themes.html#navigation."
  },
  {
    "objectID": "01-intro.html#lenvironnement-projet-de-rstudio",
    "href": "01-intro.html#lenvironnement-projet-de-rstudio",
    "title": "1  Introduction",
    "section": "1.4 L’environnement projet de Rstudio",
    "text": "1.4 L’environnement projet de Rstudio\nIl permet de créer un répertoire dans l’arborescence et facilite la gestion des chemins. R travaille par défaut dans un répertoire que l’on peut identifier à l’aide de la commande\n\ngetwd()\n\nCe répertoire peut être modifié avec la fonction\n\nsetwd()\n\nou avec les boutons\nSession -&gt; Set Working Directory -&gt; Choose Directory\nTravailler en mode projet permet, entre autres, d’utiliser le répertoire du projet comme répertoire de travail ppar défaut.\n\n\nOuvrir Rstudio et executer la fonction getwd(). Expliquer la sortie.\n\nCette fonction renvoie le répertoire à partir duquel R travaille.\n\nCréer un projet avec\nFile -&gt; New Project -&gt; New Directory -&gt; New Project\nOn choisit un répertoire dans l’arborescence qui contiendra le répertoire de cet enseignement.\nExécuter à nouveau la commande getwd().\n\nLe répertoire de travail est maintenant le répertoire du projet.\n\nFermer le projet en cliquant sur Close Project en haut à droite de la fenêtre Rstudio.\nRé-ouvrir le projet, toujours en cliquant en haut à droite de la fenêtre Rstudio."
  },
  {
    "objectID": "02-objetsR.html#création-dobjets",
    "href": "02-objetsR.html#création-dobjets",
    "title": "2  Les objets R",
    "section": "2.1 Création d’objets",
    "text": "2.1 Création d’objets\n\n2.1.1 Numérique\nOn crée un objet R en assignant une valeur (ou un caractère, vecteur…) avec les opérateurs &lt;-, -&gt;, =\n\nb &lt;- 41.3  # assigne la valeur 41.3 à l'objet b\nx &lt;- b     # b est assigné à x\nx = b      # b est assigné à x\nb -&gt; x     # b est assigné à x\nis.numeric(b)\n\n[1] TRUE\n\nmode(b)\n\n[1] \"numeric\"\n\n\n\n\n2.1.2 Caractère\nLes chaines de caractères sont définies avec des guillemets : \"chaine\", par exemple\n\nx &lt;- \"La mort\"\ny &lt;- \"aux trousses\"\npaste(x,y)\n\n[1] \"La mort aux trousses\"\n\nis.character(x)\n\n[1] TRUE\n\n\n\n\n2.1.3 Facteur\nL’objet facteur est très utile pour travailler avec des variables qualitatives. Cet objet permet d’identifier les modalités prisent par la variable et de travailler dessus, en changeant par exemple le nom d’une modalité :\n\nV1 &lt;- factor(c(\"less20years\",\"more50years\",\"less20years\",\"more50years\",\"less20years\"))\nV1\n\n[1] less20years more50years less20years more50years less20years\nLevels: less20years more50years\n\nlevels(V1)\n\n[1] \"less20years\" \"more50years\"\n\nlevels(V1) &lt;- c(\"Young\",\"Old\")\nV1\n\n[1] Young Old   Young Old   Young\nLevels: Young Old\n\n\n\n\n2.1.4 Logique (Booléen)\n\nx &lt;- TRUE\nis.logical(x)\n\n[1] TRUE\n\nmode(x)\n\n[1] \"logical\"\n\na &lt;- 1\na==1\n\n[1] TRUE\n\na!=1\n\n[1] FALSE\n\na&lt;0\n\n[1] FALSE\n\na&gt;0\n\n[1] TRUE"
  },
  {
    "objectID": "02-objetsR.html#vecteur",
    "href": "02-objetsR.html#vecteur",
    "title": "2  Les objets R",
    "section": "2.2 Vecteur",
    "text": "2.2 Vecteur\nOn peut définir un vecteur de plusieurs façons :\n\nfonction collect c\n\nx &lt;- c(1.2,5,9,11)\nx\n\n[1]  1.2  5.0  9.0 11.0\n\n\nopérateur séquence :\n\n1:5\n\n[1] 1 2 3 4 5\n\n\nfonction séquence seq\n\nseq(1,10,by=2)\n\n[1] 1 3 5 7 9\n\nseq(0,1,length=10)\n\n [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n [8] 0.7777778 0.8888889 1.0000000\n\n\nfonction rep\n\nrep(1,4)\n\n[1] 1 1 1 1\n\nrep(c(1,3),each=3)\n\n[1] 1 1 1 3 3 3\n\n\n\nOn peut aussi créer des vecteurs caractère ou logique\n\nx &lt;- c(\"A\",\"B\",\"C\")\nx &lt;- rep(\"A\",5)\npaste(\"X\",1:5,sep=\"-\")\n\n[1] \"X-1\" \"X-2\" \"X-3\" \"X-4\" \"X-5\"\n\nsubstr(\"statistician\",5,9)\n\n[1] \"istic\"\n\n\n\nc(T,F,T)\n\n[1]  TRUE FALSE  TRUE\n\n\n\n2.2.1 Sélectionner une partie d’un vecteur\nLa sélection s’effectue à l’aide de crochets [ ]\n\nx &lt;- c(-4,-3,1,3,5,8,0)\nx[2]\n\n[1] -3\n\nx[c(2,5)]\n\n[1] -3  5\n\nx&gt;0\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE\n\nx[x&gt;0]\n\n[1] 1 3 5 8\n\n\n\n\n2.2.2 Opérations sur les vecteurs\nOn peut facilement additionner, multiplier des vecteurs :\n\nx &lt;- seq(-10,10,by=2)\ny &lt;- 1:length(x)\nx+y\n\n [1] -9 -6 -3  0  3  6  9 12 15 18 21\n\nx*y\n\n [1] -10 -16 -18 -16 -10   0  14  32  54  80 110\n\nz &lt;- x&gt;0\nx*z\n\n [1]  0  0  0  0  0  0  2  4  6  8 10\n\n\n\nExercice 2.1 (Manipulation de vecteurs) On s’intéresse à des fonctions classiques permettant de manipuler des vecteurs.\n\nCalculer la moyenne, la somme, la médiane et la variance du vecteur (1,3,8,9,11).\n\nx &lt;- c(1,3,8,9,11)\nmean(x)\n\n[1] 6.4\n\nsum(x)\n\n[1] 32\n\nmedian(x)\n\n[1] 8\n\nvar(x)\n\n[1] 17.8\n\n\nCréer les vecteurs suivants en utilisant la fonction rep.\nvec1 = 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 \nvec2 = 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\nvec3 = 1 1 2 2 2 3 3 3 3 4 4 4 4 4\n\nrep(1:5,3)\n\n [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\nrep(1:5,each=3)\n\n [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\nrep(1:4,2:5)\n\n [1] 1 1 2 2 2 3 3 3 3 4 4 4 4 4\n\n\nCréer le vecteur suivant à l’aide de la fonction paste, puis avec la fonction str_c.\nvec4 = \"A0)\" \"A1)\" \"A2)\" \"A3)\" \"A4)\" \"A5)\" \"A6)\" \"A7)\" \"A8)\" \"A9)\" \"A10)\"\n\npaste(\"A\",0:10,\")\",sep=\"\")\n\n [1] \"A0)\"  \"A1)\"  \"A2)\"  \"A3)\"  \"A4)\"  \"A5)\"  \"A6)\"  \"A7)\"  \"A8)\"  \"A9)\" \n[11] \"A10)\"\n\n#ou\nstr_c(\"A\",1:10,\")\")\n\n [1] \"A1)\"  \"A2)\"  \"A3)\"  \"A4)\"  \"A5)\"  \"A6)\"  \"A7)\"  \"A8)\"  \"A9)\"  \"A10)\"\n\n\nletters est un vecteur qui contient les 26 lettres de l’alphabet.\n\nTrouver le numéro de la lettre \\(q\\) (sans compter “avec les doigts” !). On pourra utiliser la fonction which ou str_which.\n\nindex_q &lt;- which(letters==\"q\")\n#ou\nindex_q &lt;- str_which(letters,\"q\")\n\n\n\n\nCréer le vecteur “a1”,“b2”,\\(\\dots\\) jusqu’à \\(q\\) et son index.\n\npaste(letters[1:index_q],1:index_q,sep=\"\")\n\n [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n[13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\"\n\n#ou\nstr_c(letters[1:index_q],1:index_q)\n\n [1] \"a1\"  \"b2\"  \"c3\"  \"d4\"  \"e5\"  \"f6\"  \"g7\"  \"h8\"  \"i9\"  \"j10\" \"k11\" \"l12\"\n[13] \"m13\" \"n14\" \"o15\" \"p16\" \"q17\""
  },
  {
    "objectID": "02-objetsR.html#matrices",
    "href": "02-objetsR.html#matrices",
    "title": "2  Les objets R",
    "section": "2.3 Matrices",
    "text": "2.3 Matrices\nLa fonction matrix permet de définir des matrices.\n\nm &lt;- matrix(1:4,ncol=2)\nm\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nm &lt;- matrix(1:4,nrow=2)\nm\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nm &lt;- matrix(1:4,nrow=2,byrow=TRUE)\ndim(m)\n\n[1] 2 2\n\n\nLa position d’un élément dans une matrice est indiquée par ses numéros de ligne et de colonne. Ainsi, pour sélectionner le terme de la 2ème ligne et la 1ère colonne, on utilisera\n\nm[2,1]\n\n[1] 3\n\n\nOn peut aussi extraire des lignes et des colonnes :\n\nm[1,] #première ligne\n\n[1] 1 2\n\nm[,2] #deuxième colonne\n\n[1] 2 4\n\n\nIl n’est pas difficile de faire les calculs usuels sur les matrices :\n\ndet(m) #déterminant\n\n[1] -2\n\nsolve(m) #inverse\n\n     [,1] [,2]\n[1,] -2.0  1.0\n[2,]  1.5 -0.5\n\nt(m) #transposé\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nn &lt;- matrix(5:8,nrow=2)\nm+n\n\n     [,1] [,2]\n[1,]    6    9\n[2,]    9   12\n\nm*n #attention : produit de Hadamart\n\n     [,1] [,2]\n[1,]    5   14\n[2,]   18   32\n\nm%*%n #Produit matriciel\n\n     [,1] [,2]\n[1,]   17   23\n[2,]   39   53\n\neigen(m) #Décomposition en valeurs propres\n\neigen() decomposition\n$values\n[1]  5.3722813 -0.3722813\n\n$vectors\n           [,1]       [,2]\n[1,] -0.4159736 -0.8245648\n[2,] -0.9093767  0.5657675"
  },
  {
    "objectID": "02-objetsR.html#listes",
    "href": "02-objetsR.html#listes",
    "title": "2  Les objets R",
    "section": "2.4 Listes",
    "text": "2.4 Listes\nUne liste est un objet hétérogène. Elle permet de stocker des objets de différents modes dans un même objet. Par exemple, on peut céer une liste qui contient un vecteur et une matrice à l’aide de\n\nmylist &lt;- list(vector=rep(1:5),mat=matrix(1:8,nrow=2))\nmylist\n\n$vector\n[1] 1 2 3 4 5\n\n$mat\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\nlength(mylist)\n\n[1] 2\n\n\nL’extraction s’effectue en indiquant la position de l’objet à extraire dans un double crochet [[  ]] :\n\nmylist[[1]]\n\n[1] 1 2 3 4 5\n\n\nOn peut aussi utiliser le nom de l’élément à extraire :\n\nmylist$mat\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\nmylist[[\"mat\"]]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8"
  },
  {
    "objectID": "02-objetsR.html#dataframe",
    "href": "02-objetsR.html#dataframe",
    "title": "2  Les objets R",
    "section": "2.5 Dataframe",
    "text": "2.5 Dataframe\nLes dataframes sont des listes particulières dont les composantes ont la même longueur, mais potentiellement des modes différents. C’est l’objet généralement utilisé pour les tableaux de données (qui contiennent souvent des variables quantitatives et qualitatives). Par exemple,\n\nname &lt;- c(\"Paul\",\"Mary\",\"Steven\",\"Charlotte\",\"Peter\")\nsex &lt;- factor(c(\"M\",\"F\",\"M\",\"F\",\"M\"))\nsize &lt;- c(180,165,168,170,175)\ndata &lt;- data.frame(name,sex,size)\nsummary(data)\n\n     name           sex        size      \n Length:5           F:2   Min.   :165.0  \n Class :character   M:3   1st Qu.:168.0  \n Mode  :character         Median :170.0  \n                          Mean   :171.6  \n                          3rd Qu.:175.0  \n                          Max.   :180.0  \n\n\nOn observe que name est un vecteur de caractères, sex un facteur et size un vecteur numérique.\nL’extraction est similaire aux matrices et aux listes :\n\ndata[2,3]\n\n[1] 165\n\ndata[,2]\n\n[1] M F M F M\nLevels: F M\n\ndata$sex\n\n[1] M F M F M\nLevels: F M"
  },
  {
    "objectID": "02-objetsR.html#quelques-fonctions-importantes",
    "href": "02-objetsR.html#quelques-fonctions-importantes",
    "title": "2  Les objets R",
    "section": "2.6 Quelques fonctions importantes",
    "text": "2.6 Quelques fonctions importantes\n\nsummary produit un résumé d’un objet\n\nsummary(data)\n\n     name           sex        size      \n Length:5           F:2   Min.   :165.0  \n Class :character   M:3   1st Qu.:168.0  \n Mode  :character         Median :170.0  \n                          Mean   :171.6  \n                          3rd Qu.:175.0  \n                          Max.   :180.0  \n\nsummary(1:10)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    3.25    5.50    5.50    7.75   10.00 \n\n\nmean, sum, median, var, min, max… (facile à comprendre)\nsort, order\n\nx &lt;- c(1,8,5,4)\nsort(x)\n\n[1] 1 4 5 8\n\norder(x)\n\n[1] 1 4 3 2\n\n\napply applique une fonction f aux lignes ou colonnes d’une matrice ou dataframe\n\nV1 &lt;- 1:10\nV2 &lt;- seq(-20,25,length=10)\ndf &lt;- data.frame(V1,V2)\napply(df,1,mean)\n\n [1] -9.5 -6.5 -3.5 -0.5  2.5  5.5  8.5 11.5 14.5 17.5\n\napply(df,2,sum)\n\nV1 V2 \n55 25"
  },
  {
    "objectID": "02-objetsR.html#exercices-complémentaires",
    "href": "02-objetsR.html#exercices-complémentaires",
    "title": "2  Les objets R",
    "section": "2.7 Exercices complémentaires",
    "text": "2.7 Exercices complémentaires\n\nExercice 2.2 (Manipulation de matrices) Cet exercice propose des questions classiques sur la manipulation de matrices.\n\nCréer la matrice suivante que l’on appellera mat (on pourra utiliser les fonctions rownames et colnames) :\n\n\n\n\n\ncolumn 1\ncolumn 2\ncolumn 3\ncolumn 4\n\n\n\n\nrow-1\n1\n5\n5\n0\n\n\nrow-2\n0\n5\n6\n1\n\n\nrow-3\n3\n0\n3\n3\n\n\nrow-4\n4\n4\n4\n2\n\n\n\n\n\nmat &lt;- matrix(c(1,0,3,4,5,5,0,4,5,6,3,4,0,1,3,2),ncol=4)\nrownames(mat) &lt;- paste(\"row-\",1:4,sep=\"\")\ncolnames(mat) &lt;- paste(\"column \",1:4)\nmat\n\n      column  1 column  2 column  3 column  4\nrow-1         1         5         5         0\nrow-2         0         5         6         1\nrow-3         3         0         3         3\nrow-4         4         4         4         2\n\n\nCréer un vecteur qui contient la diagonal de mat.\n\ndiag(mat)\n\n[1] 1 5 3 2\n\n\nCréer une matrice qui contient les 2 premières lignes de mat.\n\nmat[1:2,]\n\n      column  1 column  2 column  3 column  4\nrow-1         1         5         5         0\nrow-2         0         5         6         1\n\n\nCréer une matrice qui contient les 2 dernières colonnes de mat.\n\nmat[,3:4]\n\n      column  3 column  4\nrow-1         5         0\nrow-2         6         1\nrow-3         3         3\nrow-4         4         2\n\n\nCalculer le déterminant et l’inverse de mat.\n\ndet(mat)\n\n[1] 60\n\nsolve(mat)\n\n          row-1 row-2      row-3         row-4\ncolumn  1   0.5  -0.5  0.1666667 -1.665335e-16\ncolumn  2  -0.6   0.4 -0.4666667  5.000000e-01\ncolumn  3   0.7  -0.3  0.4333333 -5.000000e-01\ncolumn  4  -1.2   0.8 -0.2666667  5.000000e-01\n\n\n\n\n\nExercice 2.3 (Manipulations simples sur un jeu de données) On considère le jeu de données iris disponible dans R :\n\ndata(iris)\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nCalculer les moyennes et variances des variables Sepal.Width et Petal.Length.\n\nmean(iris$Sepal.Width)\n\n[1] 3.057333\n\nmean(iris$Petal.Length)\n\n[1] 3.758\n\nvar(iris$Sepal.Width)\n\n[1] 0.1899794\n\nvar(iris$Petal.Length)\n\n[1] 3.116278\n\n\nCréer un sous jeu de données qui contient uniquement les iris de l’espèce versicolor. On appellera ce tableau iris2.\n\ntest &lt;- iris$Species==\"versicolor\"\niris2 &lt;- iris[test,]\nsummary(iris2)\n\n  Sepal.Length    Sepal.Width     Petal.Length   Petal.Width          Species  \n Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000   setosa    : 0  \n 1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200   versicolor:50  \n Median :5.900   Median :2.800   Median :4.35   Median :1.300   virginica : 0  \n Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326                  \n 3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500                  \n Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800                  \n\n\nOrdonner les individus dans iris2 par valeurs décroissantes de la variable Sepal.Length (on pourra utiliser la fonction order).\n\nord &lt;- order(iris2$Sepal.Length,decreasing=TRUE)\niris3 &lt;- iris2[ord,]\nhead(iris3)\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n51          7.0         3.2          4.7         1.4 versicolor\n53          6.9         3.1          4.9         1.5 versicolor\n77          6.8         2.8          4.8         1.4 versicolor\n66          6.7         3.1          4.4         1.4 versicolor\n78          6.7         3.0          5.0         1.7 versicolor\n87          6.7         3.1          4.7         1.5 versicolor\n\n\nCalculer les valeurs moyennes de Sepal.Length pour chaque espèce.\n\nmean(iris[iris$Species==\"versicolor\",\"Sepal.Length\"])\n\n[1] 5.936\n\nmean(iris[iris$Species==\"virginica\",\"Sepal.Length\"])\n\n[1] 6.588\n\nmean(iris[iris$Species==\"setosa\",\"Sepal.Length\"])\n\n[1] 5.006\n\n\nAjouter une variable (qu’on appellera sum.Petal) dans le dataframe iris qui contiendra la somme de Petal.Length et Petal.Width.\n\niris$sum.petal &lt;- iris$Petal.Length+iris$Petal.Width\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species sum.petal\n1          5.1         3.5          1.4         0.2  setosa       1.6\n2          4.9         3.0          1.4         0.2  setosa       1.6\n3          4.7         3.2          1.3         0.2  setosa       1.5\n4          4.6         3.1          1.5         0.2  setosa       1.7\n5          5.0         3.6          1.4         0.2  setosa       1.6\n6          5.4         3.9          1.7         0.4  setosa       2.1\n\n\n\n\n\nExercice 2.4 (Fonction apply) On considère le jeu de données suivant\n\nlibrary(lattice)\ndata(\"ethanol\")\n\n\nCalculer les indicateurs numériques standards (moyenne, min, max, etc.) des 3 variables du jeux de données ethanol (disponible dans le package lattice).\n\nsummary(ethanol)\n\n      NOx              C                E         \n Min.   :0.370   Min.   : 7.500   Min.   :0.5350  \n 1st Qu.:0.953   1st Qu.: 8.625   1st Qu.:0.7618  \n Median :1.754   Median :12.000   Median :0.9320  \n Mean   :1.957   Mean   :12.034   Mean   :0.9265  \n 3rd Qu.:3.003   3rd Qu.:15.000   3rd Qu.:1.1098  \n Max.   :4.028   Max.   :18.000   Max.   :1.2320  \n\napply(ethanol,2,mean)\n\n       NOx          C          E \n 1.9573750 12.0340909  0.9264773 \n\n\nCalculer les quartiles de chaque variables. On pourra faire un apply avec la fonction quantile.\n\nquantile(ethanol$NOx,probs=c(0.25,0.5,0.75))\n\n   25%    50%    75% \n0.9530 1.7545 3.0030 \n\nquantile(ethanol$C,probs=c(0.25,0.5,0.75))\n\n   25%    50%    75% \n 8.625 12.000 15.000 \n\nquantile(ethanol$E,probs=c(0.25,0.5,0.75))\n\n    25%     50%     75% \n0.76175 0.93200 1.10975 \n\n#ou mieux\napply(ethanol,2,quantile,probs=c(0.25,0.5,0.75))\n\n       NOx      C       E\n25% 0.9530  8.625 0.76175\n50% 1.7545 12.000 0.93200\n75% 3.0030 15.000 1.10975\n\n\nFaire de même pour les déciles.\n\napply(ethanol,2,quantile,probs=seq(0.1,0.9,by=0.1))\n\n       NOx    C      E\n10% 0.6000  7.5 0.6496\n20% 0.8030  7.5 0.7206\n30% 1.0138  9.0 0.7977\n40% 1.4146  9.0 0.8636\n50% 1.7545 12.0 0.9320\n60% 2.0994 12.6 1.0104\n70% 2.7232 15.0 1.0709\n80% 3.3326 15.0 1.1404\n90% 3.6329 18.0 1.1920\n\n\n\n\n\nExercice 2.5 (Données manquantes) On considère le jeu de données presidents\n\ndata(\"presidents\")\ndf &lt;- matrix(presidents,ncol=4,byrow=T)\n\n\nEst-ce que la ligne 20 contient au moins une données manquante ? On pourra utiliser la fonction any.\n\nany(is.na(df[20,]))\n\n[1] FALSE\n\n\nQuelles sont les lignes de df qui contiennent au moins une donnée manquante ? On pourra utiliser la fonction which.\n\nwhich(apply(is.na(df),1,any))\n\n[1]  1  4  8 28\n\n\nSupprimer les lignes de df qui contiennent au moins une donnée manquante.\n\nind_sup &lt;- which(apply(is.na(df),1,any))\ndf1 &lt;- df[-ind_sup,]\nsummary(df1)\n\n       V1              V2              V3              V4       \n Min.   :28.00   Min.   :24.00   Min.   :24.00   Min.   :23.00  \n 1st Qu.:52.50   1st Qu.:49.00   1st Qu.:46.50   1st Qu.:44.50  \n Median :64.50   Median :60.50   Median :61.00   Median :55.50  \n Mean   :60.96   Mean   :56.69   Mean   :56.27   Mean   :53.04  \n 3rd Qu.:71.00   3rd Qu.:64.75   3rd Qu.:66.50   3rd Qu.:61.50  \n Max.   :80.00   Max.   :83.00   Max.   :79.00   Max.   :78.00  \n\n\n\nOn aurait aussi pu utiliser directement la fonction na.omit :\n\n\ndf2 &lt;- na.omit(df)\nall(df1==df2)\n\n[1] TRUE"
  },
  {
    "objectID": "03-dplyr.html#importer-des-données",
    "href": "03-dplyr.html#importer-des-données",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.1 Importer des données",
    "text": "3.1 Importer des données\nLes fonctions read.table et read.csv sont les fonctions standards de R pour importer des données à partir de fichiers .txt ou .csv. Il est important de bien gérer le chemin du répertoire où se trouve le fichier. On peut le spécifier explicitement ou utiliser des fonctions comme file.path :\n\npath &lt;- file.path(\"data/\", \"piscines.csv\") #premier : répertoire, deuxième : fichier\npiscines &lt;- read.csv(path)\nclass(piscines)\n\n[1] \"data.frame\"\n\nsummary(piscines)\n\n     Name             Address             Latitude        Longitude    \n Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n                                       Mean   :-27.49   Mean   :153.0  \n                                       3rd Qu.:-27.45   3rd Qu.:153.1  \n                                       Max.   :-27.31   Max.   :153.2  \n\n\nIl existe plusieurs options importantes dans read.csv, notamment\n\nsep : le caractère de séparation (espace, virgule…)\ndec : le caractère pour le séparateur décimal (vigule, point…)\nheader : logique pour indiquer si le nom des variables est spécifié à la première ligne du fichier\nrow.names : vecteurs des identifiants (si besoin)\nna.strings : vecteur de caractères pour repérer les données manquantes.\n…\n\nLe package readr du tidyverse propose d’autres fonctions comme read_csv ou read_delim. Il n’y a pas de différences énormes avec les fonctions standards, les objets créés sont des tibbles et plus des dataframes (même si les tibbles sont des dataframes…). Par exemple\n\nlibrary(readr)\npiscines &lt;- read_csv(\"data/piscines.csv\")\nsummary(piscines)\n\n     Name             Address             Latitude        Longitude    \n Length:20          Length:20          Min.   :-27.61   Min.   :152.9  \n Class :character   Class :character   1st Qu.:-27.55   1st Qu.:153.0  \n Mode  :character   Mode  :character   Median :-27.49   Median :153.0  \n                                       Mean   :-27.49   Mean   :153.0  \n                                       3rd Qu.:-27.45   3rd Qu.:153.1  \n                                       Max.   :-27.31   Max.   :153.2  \n\nclass(piscines)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nEnfin si on n’est pas très à l’aise avec ces fonctions, on pourra utiliser le bouton Import Dataset qui se trouve dans l’onglet Environment de RStudio. Cette manière de procédé fonctionne pour des jeux de données “propres”. Si les bases contiennent trop de spécificités, on devra utiliser les fonctions présentées précédemment avec les bonnes options.\n\nExercice 3.1 (Premières importations avec readr) On étudie les fonctions classiques permettant d’importer des données.\n\nImporter les données qui se trouvent dans le fichier mydata.csv. On utilisera les fonctions read_csv, read_csv2 et read_delim avec les options par défaut et on comparera les sorties.\n\nread_csv(\"data/mydata.csv\")\n\n# A tibble: 3 × 1\n  `surname;height;weight;feet_size;sex`\n  &lt;chr&gt;                                \n1 tony;184;80;9.5;M                    \n2 james;175.5;78;8.5;M                 \n3 john;158;72;8;M                      \n\nread_csv2(\"data/mydata.csv\")\n\n# A tibble: 3 × 5\n  surname height weight feet_size sex  \n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;\n1 tony       184     80        95 M    \n2 james     1755     78        85 M    \n3 john       158     72         8 M    \n\nread_delim(\"data/mydata.csv\")\n\n# A tibble: 3 × 5\n  surname height weight feet_size sex  \n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;\n1 tony      184      80       9.5 M    \n2 james     176.     78       8.5 M    \n3 john      158      72       8   M    \n\n\n\nread_csv n’utilise pas le bon séparateur par défaut, read_csv2 ne lit pas correctement le symbole pour la décimale, read_delim fonctionne bien pour ce fichier (sinon il aurait fallu ajouter l’option delim).\n\nImporter les données qui se trouvent dans le fichier mydata2.csv.\n\ndata2 &lt;- read_delim(\"data/mydata2.csv\",delim=\" \")\ndata2\n\n# A tibble: 4 × 4\n  height weight  size sex  \n  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;\n1 184    80       9.5 M    \n2 175.5  78       8.5 M    \n3 .      72       8   M    \n4 178    .        7   F    \n\nsummary(data2)\n\n    height             weight               size          sex           \n Length:4           Length:4           Min.   :7.00   Length:4          \n Class :character   Class :character   1st Qu.:7.75   Class :character  \n Mode  :character   Mode  :character   Median :8.25   Mode  :character  \n                                       Mean   :8.25                     \n                                       3rd Qu.:8.75                     \n                                       Max.   :9.50                     \n\n\n\nLes variable height et weight sont interprétées comme des variables qualitatives, cela vient du fait qu’il y a des données manquante mal lues.\n\nCe fichier contient des données manquantes (identifiées par un point). A l’aide de l’option na, refaire l’importation en identifiant correctement les données manquantes.\n\ndata2 &lt;- read_delim(\"data/mydata2.csv\",delim=\" \",na=\".\")\ndata2\n\n# A tibble: 4 × 4\n  height weight  size sex  \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n1   184      80   9.5 M    \n2   176.     78   8.5 M    \n3    NA      72   8   M    \n4   178      NA   7   F    \n\nsummary(data2)\n\n     height          weight           size          sex           \n Min.   :175.5   Min.   :72.00   Min.   :7.00   Length:4          \n 1st Qu.:176.8   1st Qu.:75.00   1st Qu.:7.75   Class :character  \n Median :178.0   Median :78.00   Median :8.25   Mode  :character  \n Mean   :179.2   Mean   :76.67   Mean   :8.25                     \n 3rd Qu.:181.0   3rd Qu.:79.00   3rd Qu.:8.75                     \n Max.   :184.0   Max.   :80.00   Max.   :9.50                     \n NA's   :1       NA's   :1                                        \n\n\nChanger les levels de la variable sex en woman et man (on pourra utiliser la fonction levels).\n\ndata22 &lt;- data2\n\n\n1ère façon :\n\ndata2$sex &lt;- as.factor(data2$sex)\nlevels(data2$sex) &lt;- c(\"woman\",\"man\")\ndata2\n\n# A tibble: 4 × 4\n  height weight  size sex  \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n1   184      80   9.5 man  \n2   176.     78   8.5 man  \n3    NA      72   8   man  \n4   178      NA   7   woman\n\n\n2ème façon avec recode_factor du package forcats :\n\ndata22$sex &lt;- recode_factor(data2$sex,\"F\"=\"woman\",\"M\"=\"man\")\ndata22\n\n# A tibble: 4 × 4\n  height weight  size sex  \n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n1   184      80   9.5 man  \n2   176.     78   8.5 man  \n3    NA      72   8   man  \n4   178      NA   7   woman\n\n\n\n\n\n\nExercice 3.2 (Importer avec read.csv) Refaire l’exercice précédent avec la fonction read.csv.\n\nOn commence avec les paramètres par défaut :\n\n\ndata1 &lt;- read.csv(\"data/mydata.csv\")\nsummary(data1)\n\n surname.height.weight.feet_size.sex\n Length:3                           \n Class :character                   \n Mode  :character                   \n\n\n\nLe séparateur n’est pas bien défini ! On corrige :\n\n\ndata1 &lt;- read.csv(\"data/mydata.csv\",sep=\";\",\n                  dec=\".\",row.names = 1)\nsummary(data1)\n\n     height          weight        feet_size         sex           \n Min.   :158.0   Min.   :72.00   Min.   :8.000   Length:3          \n 1st Qu.:166.8   1st Qu.:75.00   1st Qu.:8.250   Class :character  \n Median :175.5   Median :78.00   Median :8.500   Mode  :character  \n Mean   :172.5   Mean   :76.67   Mean   :8.667                     \n 3rd Qu.:179.8   3rd Qu.:79.00   3rd Qu.:9.000                     \n Max.   :184.0   Max.   :80.00   Max.   :9.500                     \n\n\n\nPour le second fichier on fait :\n\n\ndata2 &lt;- read.csv(\"data/mydata2.csv\",sep=\"\",na.strings = \".\")\ndata2$sex &lt;- recode_factor(data2$sex,\"F\"=\"woman\",\"M\"=\"man\")\ndata2\n\n  height weight size   sex\n1  184.0     80  9.5   man\n2  175.5     78  8.5   man\n3     NA     72  8.0   man\n4  178.0     NA  7.0 woman\n\nsummary(data2)\n\n     height          weight           size         sex   \n Min.   :175.5   Min.   :72.00   Min.   :7.00   woman:1  \n 1st Qu.:176.8   1st Qu.:75.00   1st Qu.:7.75   man  :3  \n Median :178.0   Median :78.00   Median :8.25            \n Mean   :179.2   Mean   :76.67   Mean   :8.25            \n 3rd Qu.:181.0   3rd Qu.:79.00   3rd Qu.:8.75            \n Max.   :184.0   Max.   :80.00   Max.   :9.50            \n NA's   :1       NA's   :1                               \n\n\n\n\nExercice 3.3 (Jointure de tables) On considère les 3 jeux de données suivants, au format tibble :\n\ndf1 &lt;- tibble(name=c(\"Mary\",\"Peter\",\"John\",\"July\"),age=c(18,25,21,43))\ndf2 &lt;- tibble(name=c(\"Zac\",\"Julian\"),age=c(23,48))\ndf3 &lt;- tibble(size=c(154,178,182,134,142),name1=c(\"Peter\",\"Mary\",\"July\",\"John\",\"stef\"))\ndf1\n\n# A tibble: 4 × 2\n  name    age\n  &lt;chr&gt; &lt;dbl&gt;\n1 Mary     18\n2 Peter    25\n3 John     21\n4 July     43\n\ndf2\n\n# A tibble: 2 × 2\n  name     age\n  &lt;chr&gt;  &lt;dbl&gt;\n1 Zac       23\n2 Julian    48\n\ndf3\n\n# A tibble: 5 × 2\n   size name1\n  &lt;dbl&gt; &lt;chr&gt;\n1   154 Peter\n2   178 Mary \n3   182 July \n4   134 John \n5   142 stef \n\n\nOn souhaite assembler ces tables en utilisant les fonctions de jointure du tidyverse (left_join, full_join par exemple). On pourra consulter la cheatsheet Data transformation with dplyr (help -&gt; cheatsheets -&gt; …).\n\nAssembler df1 avec df2 en utilisant bind_rows et calculer la moyenne de la variable age. On appellera df cette nouvelle table.\n\ndf &lt;- bind_rows(df1,df2)\nmean(df$age)\n\n[1] 29.66667\n\n\nAssembler df avec df3 en utilisant full_join.\n\na1 &lt;- full_join(df,df3,by=c(\"name\"=\"name1\"))\na1\n\n# A tibble: 7 × 3\n  name     age  size\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Mary      18   178\n2 Peter     25   154\n3 John      21   134\n4 July      43   182\n5 Zac       23    NA\n6 Julian    48    NA\n7 stef      NA   142\n\n\nFaire la même chose avec inner_join.\n\na2 &lt;- inner_join(df,df3,by=c(\"name\"=\"name1\"))\na2\n\n# A tibble: 4 × 3\n  name    age  size\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mary     18   178\n2 Peter    25   154\n3 John     21   134\n4 July     43   182\n\n\nExpliquer les différences entre full_join et inner_join.\n\ninner_join retient uniquement les individus pour lesquels age et size ont été observés. full_join garde tous les individus, des NA sont ajoutés lorsque la variable n’est pas observée."
  },
  {
    "objectID": "03-dplyr.html#le-package-dplyr",
    "href": "03-dplyr.html#le-package-dplyr",
    "title": "3  Manipuler les données avec dplyr",
    "section": "3.2 Le package dplyr",
    "text": "3.2 Le package dplyr\ndplyr est un package du tidyverse qui permet de faciliter la manipulation des données. Il propose une syntaxe claire (basée sur une grammaire) pour travailler sur les données. On pourra trouver des informations à cet url https://spark.rstudio.com/dplyr.html ou sur la cheatsheet.\nNous avons vu quelques opérations standards pour manipuler les données. Par exemple, on peut obtenir les Longitude et Latitude des piscines ayant une Longitude supérieure à 153 avec\n\npiscines[piscines$Longitude&gt;153,c(\"Longitude\",\"Latitude\")]\n\n# A tibble: 16 × 2\n   Longitude Latitude\n       &lt;dbl&gt;    &lt;dbl&gt;\n 1      153.    -27.6\n 2      153.    -27.5\n 3      153.    -27.4\n 4      153.    -27.5\n 5      153.    -27.5\n 6      153.    -27.5\n 7      153.    -27.6\n 8      153.    -27.5\n 9      153.    -27.5\n10      153.    -27.5\n11      153.    -27.5\n12      153.    -27.4\n13      153.    -27.6\n14      153.    -27.3\n15      153.    -27.5\n16      153.    -27.5\n\n\ndplyr propose de faire la même chose avec une syntaxe plus claire\n\nlibrary(tidyverse) #ou library(dplyr)\npiscines |&gt; select(Longitude,Latitude) |&gt; filter(Longitude&gt;153)\n\n# A tibble: 16 × 2\n   Longitude Latitude\n       &lt;dbl&gt;    &lt;dbl&gt;\n 1      153.    -27.6\n 2      153.    -27.5\n 3      153.    -27.4\n 4      153.    -27.5\n 5      153.    -27.5\n 6      153.    -27.5\n 7      153.    -27.6\n 8      153.    -27.5\n 9      153.    -27.5\n10      153.    -27.5\n11      153.    -27.5\n12      153.    -27.4\n13      153.    -27.6\n14      153.    -27.3\n15      153.    -27.5\n16      153.    -27.5\n\n\nLe code est plus efficace et facile à lire.\ndplyr propose une grammaire dont les principaux verbes sont :\n\nselect() : sélectionner des colonnes (variables)\nfilter() : filtrer des lignes (individus)\narrange() : ordonner des lignes\nmutate() : créer des nouvelles colonnes (nouvelles variables)\nsummarise() : calculer des résumés numériques (ou résumés statistiques)\ngroup_by() : effectuer des opérations pour des groupes d’individus\n\nNous les présentons dans la partie suivante.\n\n3.2.1 Les principaux verbes dplyr\n\nLe verbe select()\nIl permet de sélectionner des variables (colonnes) :\n\nselect(df, VAR1, VAR2, ...)\n\nPar exemple,\n\ncoord &lt;- select(piscines, Latitude, Longitude)\nhead(piscines, n=2)\n\n# A tibble: 2 × 4\n  Name                        Address                         Latitude Longitude\n  &lt;chr&gt;                       &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;\n1 Acacia Ridge Leisure Centre 1391 Beaudesert Road, Acacia R…    -27.6      153.\n2 Bellbowrie Pool             Sugarwood Street, Bellbowrie       -27.6      153.\n\nhead(coord, n=2)\n\n# A tibble: 2 × 2\n  Latitude Longitude\n     &lt;dbl&gt;     &lt;dbl&gt;\n1    -27.6      153.\n2    -27.6      153.\n\n\nOn peut utiliser les helper functions (begins_with, end_with, contains, matches) pour des sélections plus précises basées sur le nom des variables.\n\ncoord &lt;- select(piscines, ends_with(\"tude\"))\nhead(coord, n=2)\n\n# A tibble: 2 × 2\n  Latitude Longitude\n     &lt;dbl&gt;     &lt;dbl&gt;\n1    -27.6      153.\n2    -27.6      153.\n\n\n\n\nLe verbe mutate()\nIl permet de créer des nouvelles variables\n\nmutate(df, NEW.VAR = expression(VAR1, VAR2, ...))\n\nPar exemple\n\ndf &lt;- mutate(piscines, phrase=paste(\"Swimming pool\", Name, \"is located at the address\", Address))\nselect(df,phrase)\n\n# A tibble: 20 × 1\n   phrase                                                                       \n   &lt;chr&gt;                                                                        \n 1 Swimming pool Acacia Ridge Leisure Centre is located at the address 1391 Bea…\n 2 Swimming pool Bellbowrie Pool is located at the address Sugarwood Street, Be…\n 3 Swimming pool Carole Park is located at the address Cnr Boundary Road and Wa…\n 4 Swimming pool Centenary Pool (inner City) is located at the address 400 Greg…\n 5 Swimming pool Chermside Pool is located at the address 375 Hamilton Road, Ch…\n 6 Swimming pool Colmslie Pool (Morningside) is located at the address 400 Lytt…\n 7 Swimming pool Spring Hill Baths (inner City) is located at the address 14 To…\n 8 Swimming pool Dunlop Park Pool (Corinda) is located at the address 794 Oxley…\n 9 Swimming pool Fortitude Valley Pool is located at the address 432 Wickham St…\n10 Swimming pool Hibiscus Sports Complex (upper MtGravatt) is located at the ad…\n11 Swimming pool Ithaca Pool ( Paddington) is located at the address 131 Caxton…\n12 Swimming pool Jindalee Pool is located at the address 11 Yallambee Road, Jin…\n13 Swimming pool Manly Pool is located at the address 1 Fairlead Crescent, Manly\n14 Swimming pool Mt Gravatt East Aquatic Centre is located at the address Cnr w…\n15 Swimming pool Musgrave Park Pool (South Brisbane) is located at the address …\n16 Swimming pool Newmarket Pool is located at the address 71 Alderson Stret, Ne…\n17 Swimming pool Runcorn Pool is located at the address 37 Bonemill Road, Runco…\n18 Swimming pool Sandgate Pool is located at the address 231 Flinders Parade, S…\n19 Swimming pool Langlands Parks Pool (Stones Corner) is located at the address…\n20 Swimming pool Yeronga Park Pool is located at the address 81 School Road, Ye…\n\n\nOn peut également créer plusieurs variables avec un seul mutate :\n\nmutate(piscines,\n       phrase = paste(\"Swimming pool\", Name, \"is located at the address\", Address),\n       unused = Longitude + Latitude\n)\n\n# A tibble: 20 × 6\n   Name                                 Address Latitude Longitude phrase unused\n   &lt;chr&gt;                                &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 Acacia Ridge Leisure Centre          1391 B…    -27.6      153. Swimm…   125.\n 2 Bellbowrie Pool                      Sugarw…    -27.6      153. Swimm…   125.\n 3 Carole Park                          Cnr Bo…    -27.6      153. Swimm…   125.\n 4 Centenary Pool (inner City)          400 Gr…    -27.5      153. Swimm…   126.\n 5 Chermside Pool                       375 Ha…    -27.4      153. Swimm…   126.\n 6 Colmslie Pool (Morningside)          400 Ly…    -27.5      153. Swimm…   126.\n 7 Spring Hill Baths (inner City)       14 Tor…    -27.5      153. Swimm…   126.\n 8 Dunlop Park Pool (Corinda)           794 Ox…    -27.5      153. Swimm…   125.\n 9 Fortitude Valley Pool                432 Wi…    -27.5      153. Swimm…   126.\n10 Hibiscus Sports Complex (upper MtGr… 90 Klu…    -27.6      153. Swimm…   126.\n11 Ithaca Pool ( Paddington)            131 Ca…    -27.5      153. Swimm…   126.\n12 Jindalee Pool                        11 Yal…    -27.5      153. Swimm…   125.\n13 Manly Pool                           1 Fair…    -27.5      153. Swimm…   126.\n14 Mt Gravatt East Aquatic Centre       Cnr we…    -27.5      153. Swimm…   126.\n15 Musgrave Park Pool (South Brisbane)  100 Ed…    -27.5      153. Swimm…   126.\n16 Newmarket Pool                       71 Ald…    -27.4      153. Swimm…   126.\n17 Runcorn Pool                         37 Bon…    -27.6      153. Swimm…   125.\n18 Sandgate Pool                        231 Fl…    -27.3      153. Swimm…   126.\n19 Langlands Parks Pool (Stones Corner) 5 Pani…    -27.5      153. Swimm…   126.\n20 Yeronga Park Pool                    81 Sch…    -27.5      153. Swimm…   125.\n\n\n\n\nLe verbe filter()\nIl permet de sélectionner (filtrer) des individus (lignes) :\n\nfilter(df, TEST)\n\nPar exemple\n\np1 &lt;- filter(piscines, Longitude&gt;153.02)\nselect(p1,Longitude)\n\n# A tibble: 12 × 1\n   Longitude\n       &lt;dbl&gt;\n 1      153.\n 2      153.\n 3      153.\n 4      153.\n 5      153.\n 6      153.\n 7      153.\n 8      153.\n 9      153.\n10      153.\n11      153.\n12      153.\n\n\nou (on sélectionne les piscines dont le nom contient Pool)\n\ndf &lt;- filter(piscines, !grepl(\"Pool\", Name))\nselect(df,Name)\n\n# A tibble: 5 × 1\n  Name                                     \n  &lt;chr&gt;                                    \n1 Acacia Ridge Leisure Centre              \n2 Carole Park                              \n3 Spring Hill Baths (inner City)           \n4 Hibiscus Sports Complex (upper MtGravatt)\n5 Mt Gravatt East Aquatic Centre           \n\n\nou (on sélectionne les piscines avec une longitude plus grande que 153.02 ou une latitude plus petite que -27.488)\n\np2 &lt;- filter(piscines, Longitude&gt;153.02 | Latitude &lt; -27.488)\nselect(p2, Longitude, Latitude)\n\n# A tibble: 17 × 2\n   Longitude Latitude\n       &lt;dbl&gt;    &lt;dbl&gt;\n 1      153.    -27.6\n 2      153.    -27.6\n 3      153.    -27.6\n 4      153.    -27.5\n 5      153.    -27.4\n 6      153.    -27.5\n 7      153.    -27.5\n 8      153.    -27.5\n 9      153.    -27.5\n10      153.    -27.6\n11      153.    -27.5\n12      153.    -27.5\n13      153.    -27.5\n14      153.    -27.6\n15      153.    -27.3\n16      153.    -27.5\n17      153.    -27.5\n\n\nOn peut également utiliser la fonction slice pour choisir des individus à partir de leurs indices :\n\nslice(piscines,5:8)\n\n# A tibble: 4 × 4\n  Name                           Address                      Latitude Longitude\n  &lt;chr&gt;                          &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt;\n1 Chermside Pool                 375 Hamilton Road, Chermside    -27.4      153.\n2 Colmslie Pool (Morningside)    400 Lytton Road, Morningside    -27.5      153.\n3 Spring Hill Baths (inner City) 14 Torrington Street, Sprin…    -27.5      153.\n4 Dunlop Park Pool (Corinda)     794 Oxley Road, Corinda         -27.5      153.\n\n\n\n\nLe verbe arrange()\nIl permet d’ordonner les individus en fonction d’une variable\n\narrange(df, VAR) #tri croissant\n\nou\n\narrange(df, desc(VAR)) #tri décroissant\n\nPar exemple\n\narrange(piscines, Longitude)\n\n# A tibble: 20 × 4\n   Name                                      Address          Latitude Longitude\n   &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n 1 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n 2 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n 3 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n 4 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n 5 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n 6 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n 7 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n 8 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n 9 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n10 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n11 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n12 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n13 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n14 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n15 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n16 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n17 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n18 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n19 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n20 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n\n\nou\n\narrange(piscines, desc(Longitude))\n\n# A tibble: 20 × 4\n   Name                                      Address          Latitude Longitude\n   &lt;chr&gt;                                     &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n 1 Manly Pool                                1 Fairlead Cres…    -27.5      153.\n 2 Mt Gravatt East Aquatic Centre            Cnr wecker Road…    -27.5      153.\n 3 Colmslie Pool (Morningside)               400 Lytton Road…    -27.5      153.\n 4 Runcorn Pool                              37 Bonemill Roa…    -27.6      153.\n 5 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road,…    -27.6      153.\n 6 Sandgate Pool                             231 Flinders Pa…    -27.3      153.\n 7 Langlands Parks Pool (Stones Corner)      5 Panitya Stree…    -27.5      153.\n 8 Fortitude Valley Pool                     432 Wickham Str…    -27.5      153.\n 9 Chermside Pool                            375 Hamilton Ro…    -27.4      153.\n10 Acacia Ridge Leisure Centre               1391 Beaudesert…    -27.6      153.\n11 Centenary Pool (inner City)               400 Gregory Ter…    -27.5      153.\n12 Spring Hill Baths (inner City)            14 Torrington S…    -27.5      153.\n13 Yeronga Park Pool                         81 School Road,…    -27.5      153.\n14 Musgrave Park Pool (South Brisbane)       100 Edmonstone …    -27.5      153.\n15 Ithaca Pool ( Paddington)                 131 Caxton Stre…    -27.5      153.\n16 Newmarket Pool                            71 Alderson Str…    -27.4      153.\n17 Dunlop Park Pool (Corinda)                794 Oxley Road,…    -27.5      153.\n18 Jindalee Pool                             11 Yallambee Ro…    -27.5      153.\n19 Carole Park                               Cnr Boundary Ro…    -27.6      153.\n20 Bellbowrie Pool                           Sugarwood Stree…    -27.6      153.\n\n\n\n\n\n3.2.2 Les verbes summarize et groub_by\nLes verbes précédents permettent de manipuler les données en sélectionnant des individus ou variables essentiellement. Ces deux nouveaux verbes vont permettre de calculer des indicateurs statistiques sur un jeu de données.\n\nLe verbe summarize (ou summarise)\nIl permet de créer des nouveaux jeux de données qui contiennent des résumés statistiques du jeu de données initial comme la moyenne, variance, médiane de variables. Par exemple\n\nsummarise(piscines,\n          mean_long = mean(Longitude),\n          med_lat = median(Latitude),\n          min_lat = min(Latitude),\n          sum_long = sum(Longitude)\n)\n\n# A tibble: 1 × 4\n  mean_long med_lat min_lat sum_long\n      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1      153.   -27.5   -27.6    3061.\n\n\ndplyr contient également les fonction suivantes (souvent utilisées en statistique) :\n\nn() : nombre de lignes (individus d’un jeu de données).\nn_distinct() : nombre d’éléments distincts dans un vecteur.\nfisrt() et last() : premier et dernier élément d’un vecteur.\n\nPar exemple, on obtient le nombre de piscines dans le jeu de données, et la longitude de la dernière piscine avec\n\nsummarise(piscines,n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1    20\n\nsummarise(piscines,last(Longitude))\n\n# A tibble: 1 × 1\n  `last(Longitude)`\n              &lt;dbl&gt;\n1              153.\n\n\nOn peut aussi utiliser summarise_all, summarise_at qui vont permettre de répéter les mêmes opérations sur plusieurs variables. Par exemple\n\nsummarise_at(piscines,3:4,mean)\n\n# A tibble: 1 × 2\n  Latitude Longitude\n     &lt;dbl&gt;     &lt;dbl&gt;\n1    -27.5      153.\n\n\n\n\nRegrouper des données avec Group_by\ngroup_by permet d’appliquer une ou des opérations à des groupes de données (ou d’individus). Par exemple, imaginons que l’on souhaite calculer les longitudes moyennes des piscines scindées en 2 groupes : petites et grande latitudes. On créé d’abord une variable lat_dis qui permet d’identifier les latitudes (petite ou grande) :\n\nlat_mean &lt;- piscines |&gt; summarise(mean(Latitude))\npisc1 &lt;- piscines |&gt; mutate(lat_dis=factor(Latitude&gt;as.numeric(lat_mean)))\nlevels(pisc1$lat_dis) &lt;- c(\"Low\",\"High\")\n\nIl reste maintenant à utiliser group_by pour obtenir les longitudes moyennes des 2 groupes :\n\nsummarise(group_by(pisc1,lat_dis),mean_long=mean(Longitude))\n\n# A tibble: 2 × 2\n  lat_dis mean_long\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Low          153.\n2 High         153.\n\n\n\n\n\n3.2.3 Assembler des verbes avec l’opérateur de chainage |&gt;\nUn des principaux intérêts de dplyr est bien entendu d’utiliser plusieurs verbes pour arriver au résultat souhaité. C’est ce qui est fait plus haut et nous observons que la syntaxe n’est pas facile à lire. Le package propose un opérateur de chainage ou pipe opérateur qui permet de rentre cette syntaxe plus lisible. Cet opérateur consiste à décomposer le code étape par étape et à relier ces étapes par le symbole |&gt;. On peut par exemple réécrire l’exemple précédent avec :\n\nLe jeu de données\n\npisc1\n\nÉtape group_by\n\npisc1 |&gt; group_by(lat_dis)\n\nÉtape summarise\n\npisc1 |&gt; group_by(lat_dis) |&gt; summarise(mean_long=mean(Longitude))\n\n# A tibble: 2 × 2\n  lat_dis mean_long\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Low          153.\n2 High         153.\n\n\n\nqui donne le résultat souhaité.\nCet opérateur peut être utilisé pour toutes les fonctions R. Il revient à considérer comme premier argument du terme à droite du pipe le terme à gauche de ce dernier. Par exemple\n\nmean(1:10)\n\n[1] 5.5\n\n1:10 |&gt; mean()\n\n[1] 5.5\n\n\nIl est recommandé d’utiliser cet opérateur lorsque on chaîne les verbes dplyr, la syntaxe est beaucoup plus claire.\n\n\n3.2.4 Quelques exercices\n\nExercice 3.4 (Dplyr sur les iris de Fisher) On considère le jeu de données iris\n\niris &lt;- iris |&gt; as_tibble()\n\nRépondre aux questions suivantes en utilisant les verbes dplyr et l’opérateur |&gt;.\n\nSélectionner les variables Petal.Width et Species.\n\niris |&gt; select(Petal.Width,Species)\n\n# A tibble: 150 × 2\n   Petal.Width Species\n         &lt;dbl&gt; &lt;fct&gt;  \n 1         0.2 setosa \n 2         0.2 setosa \n 3         0.2 setosa \n 4         0.2 setosa \n 5         0.2 setosa \n 6         0.4 setosa \n 7         0.3 setosa \n 8         0.2 setosa \n 9         0.2 setosa \n10         0.1 setosa \n# ℹ 140 more rows\n\n\nConstruire une table qui contient uniquement les iris d’espèce versicolor ou virginica (on pourra utiliser le symbole | pour la condition ou).\n\niris |&gt; filter(Species==\"versicolor\" | Species==\"virginica\")\n\n# A tibble: 100 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n 1          7           3.2          4.7         1.4 versicolor\n 2          6.4         3.2          4.5         1.5 versicolor\n 3          6.9         3.1          4.9         1.5 versicolor\n 4          5.5         2.3          4           1.3 versicolor\n 5          6.5         2.8          4.6         1.5 versicolor\n 6          5.7         2.8          4.5         1.3 versicolor\n 7          6.3         3.3          4.7         1.6 versicolor\n 8          4.9         2.4          3.3         1   versicolor\n 9          6.6         2.9          4.6         1.3 versicolor\n10          5.2         2.7          3.9         1.4 versicolor\n# ℹ 90 more rows\n\n\n\nOn peut également conserver tous les iris à l’exception de l’espèce setosa :\n\n\niris |&gt; filter(Species!=\"setosa\")\n\n# A tibble: 100 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n 1          7           3.2          4.7         1.4 versicolor\n 2          6.4         3.2          4.5         1.5 versicolor\n 3          6.9         3.1          4.9         1.5 versicolor\n 4          5.5         2.3          4           1.3 versicolor\n 5          6.5         2.8          4.6         1.5 versicolor\n 6          5.7         2.8          4.5         1.3 versicolor\n 7          6.3         3.3          4.7         1.6 versicolor\n 8          4.9         2.4          3.3         1   versicolor\n 9          6.6         2.9          4.6         1.3 versicolor\n10          5.2         2.7          3.9         1.4 versicolor\n# ℹ 90 more rows\n\n\nCalculer le nombre d’iris de l’espèce setosa en utilisant summarise.\n\niris |&gt; filter(Species==\"setosa\") |&gt; summarise(nb_setosa=n())\n\n# A tibble: 1 × 1\n  nb_setosa\n      &lt;int&gt;\n1        50\n\n\nCalculer la moyenne de la variable Petal.Width pour les iris de l’espèce versicolor.\n\niris |&gt; filter(Species==\"versicolor\") |&gt;\n  summarise(Mean_PW=mean(Petal.Width))\n\n# A tibble: 1 × 1\n  Mean_PW\n    &lt;dbl&gt;\n1    1.33\n\n\nAjouter dans le jeu de données la variable Sum_Petal qui correspond à la somme de Petal.Width et Sepal.Width.\n\niris1 &lt;- iris\niris1 |&gt; mutate(Sum_Petal=Petal.Width+Sepal.Width)\n\n# A tibble: 150 × 6\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sum_Petal\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;\n 1          5.1         3.5          1.4         0.2 setosa        3.7\n 2          4.9         3            1.4         0.2 setosa        3.2\n 3          4.7         3.2          1.3         0.2 setosa        3.4\n 4          4.6         3.1          1.5         0.2 setosa        3.3\n 5          5           3.6          1.4         0.2 setosa        3.8\n 6          5.4         3.9          1.7         0.4 setosa        4.3\n 7          4.6         3.4          1.4         0.3 setosa        3.7\n 8          5           3.4          1.5         0.2 setosa        3.6\n 9          4.4         2.9          1.4         0.2 setosa        3.1\n10          4.9         3.1          1.5         0.1 setosa        3.2\n# ℹ 140 more rows\n\n\nCalculer la moyenne et la variance de la variable Petal.Length pour chaque espèce (on pourra utiliser group_by).\n\niris |&gt; group_by(Species) |&gt;\n  summarise(mean_PL=mean(Petal.Length),var_PL=var(Petal.Length)) |&gt;\n  mutate(var_PL=round(var_PL,3))\n\n# A tibble: 3 × 3\n  Species    mean_PL var_PL\n  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 setosa        1.46  0.03 \n2 versicolor    4.26  0.221\n3 virginica     5.55  0.305\n\n\n\n\n\nExercice 3.5 (Traffic aérien aux USA) On considère la table hflights qui contient des informations sur les vols au départ des aéroports Houston airports IAH (George Bush Intercontinental) et HOU (Houston Hobby):\n\nlibrary(hflights)\nhflights &lt;- as_tibble(hflights)\n\nLa variable Unique Carrier renseigne sur la compagnie du vol. On recode cette variable afin que la compagnie soit plus explicite :\n\nlut1 &lt;- c(\"AA\" = \"American\", \"AS\" = \"Alaska\", \"B6\" = \"JetBlue\", \"CO\" = \"Continental\",\n         \"DL\" = \"Delta\", \"OO\" = \"SkyWest\", \"UA\" = \"United\", \"US\" = \"US_Airways\", \n         \"WN\" = \"Southwest\", \"EV\" = \"Atlantic_Southeast\", \"F9\" = \"Frontier\", \n         \"FL\" = \"AirTran\", \"MQ\" = \"American_Eagle\", \"XE\" = \"ExpressJet\", \"YV\" = \"Mesa\")\n\nOn fait de même pour la variable CancellationCode :\n\nlut2 &lt;- c(\"A\" = \"carrier\", \"B\" = \"weather\", \"C\" = \"FFA\", \"D\" = \"security\", \"E\" = \"not cancelled\")\n\nOn effectue maintenant les changements dans la table pour obtenir une nouvelle version de hflights :\n\nhflights1 &lt;- hflights\nhflights1$UniqueCarrier &lt;- lut1[hflights1$UniqueCarrier]\nhflights1$CancellationCode[hflights1$CancellationCode==\"\"] &lt;- \"Z\"\nhflights1$CancellationCode &lt;- lut2[hflights1$CancellationCode]\n\nA partir de maintenant, on travaille avec hflights1.\n\nSélectionner les variables qui se situent entre Origin et Cancelled de différentes façons.\n\nind &lt;- match(c(\"Origin\",\"Cancelled\"),names(hflights1))\nhflights1 |&gt; select(seq(ind[1],ind[2]))\n\n# A tibble: 227,496 × 6\n   Origin Dest  Distance TaxiIn TaxiOut Cancelled\n   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;   &lt;int&gt;     &lt;int&gt;\n 1 IAH    DFW        224      7      13         0\n 2 IAH    DFW        224      6       9         0\n 3 IAH    DFW        224      5      17         0\n 4 IAH    DFW        224      9      22         0\n 5 IAH    DFW        224      9       9         0\n 6 IAH    DFW        224      6      13         0\n 7 IAH    DFW        224     12      15         0\n 8 IAH    DFW        224      7      12         0\n 9 IAH    DFW        224      8      22         0\n10 IAH    DFW        224      6      19         0\n# ℹ 227,486 more rows\n\n#ou\nhflights1 |&gt; select(Origin:Cancelled) \n\n# A tibble: 227,496 × 6\n   Origin Dest  Distance TaxiIn TaxiOut Cancelled\n   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;   &lt;int&gt;     &lt;int&gt;\n 1 IAH    DFW        224      7      13         0\n 2 IAH    DFW        224      6       9         0\n 3 IAH    DFW        224      5      17         0\n 4 IAH    DFW        224      9      22         0\n 5 IAH    DFW        224      9       9         0\n 6 IAH    DFW        224      6      13         0\n 7 IAH    DFW        224     12      15         0\n 8 IAH    DFW        224      7      12         0\n 9 IAH    DFW        224      8      22         0\n10 IAH    DFW        224      6      19         0\n# ℹ 227,486 more rows\n\n\nSélectionner les variables DepTime, ArrTime, ActualElapsedTime, AirTime, ArrDelay et DepDelay. On pourra remarquer que toutes ces variables contiennent les chaînes de caractère Time ou Delay et utiliser la helper function contains().\n\nhflights1 |&gt; select(contains(\"Time\"),contains(\"Delay\"))\n\n# A tibble: 227,496 × 6\n   DepTime ArrTime ActualElapsedTime AirTime ArrDelay DepDelay\n     &lt;int&gt;   &lt;int&gt;             &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n 1    1400    1500                60      40      -10        0\n 2    1401    1501                60      45       -9        1\n 3    1352    1502                70      48       -8       -8\n 4    1403    1513                70      39        3        3\n 5    1405    1507                62      44       -3        5\n 6    1359    1503                64      45       -7       -1\n 7    1359    1509                70      43       -1       -1\n 8    1355    1454                59      40      -16       -5\n 9    1443    1554                71      41       44       43\n10    1443    1553                70      45       43       43\n# ℹ 227,486 more rows\n\n#ou\nhflights1 |&gt; select(contains(c(\"Time\",\"Delay\")))\n\n# A tibble: 227,496 × 6\n   DepTime ArrTime ActualElapsedTime AirTime ArrDelay DepDelay\n     &lt;int&gt;   &lt;int&gt;             &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n 1    1400    1500                60      40      -10        0\n 2    1401    1501                60      45       -9        1\n 3    1352    1502                70      48       -8       -8\n 4    1403    1513                70      39        3        3\n 5    1405    1507                62      44       -3        5\n 6    1359    1503                64      45       -7       -1\n 7    1359    1509                70      43       -1       -1\n 8    1355    1454                59      40      -16       -5\n 9    1443    1554                71      41       44       43\n10    1443    1553                70      45       43       43\n# ℹ 227,486 more rows\n\n\nAjouter une variable ActualGroundTime qui correspond à ActualElapsedTime moins AirTime.\n\nhflights2 &lt;- hflights1 |&gt; mutate(ActualGroundTime=ActualElapsedTime-AirTime)\nhead(hflights2)\n\n# A tibble: 6 × 22\n   Year Month DayofMonth DayOfWeek DepTime ArrTime UniqueCarrier FlightNum\n  &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;chr&gt;             &lt;int&gt;\n1  2011     1          1         6    1400    1500 American            428\n2  2011     1          2         7    1401    1501 American            428\n3  2011     1          3         1    1352    1502 American            428\n4  2011     1          4         2    1403    1513 American            428\n5  2011     1          5         3    1405    1507 American            428\n6  2011     1          6         4    1359    1503 American            428\n# ℹ 14 more variables: TailNum &lt;chr&gt;, ActualElapsedTime &lt;int&gt;, AirTime &lt;int&gt;,\n#   ArrDelay &lt;int&gt;, DepDelay &lt;int&gt;, Origin &lt;chr&gt;, Dest &lt;chr&gt;, Distance &lt;int&gt;,\n#   TaxiIn &lt;int&gt;, TaxiOut &lt;int&gt;, Cancelled &lt;int&gt;, CancellationCode &lt;chr&gt;,\n#   Diverted &lt;int&gt;, ActualGroundTime &lt;int&gt;\n\n\nAjouter la variable AverageSpeed (=Distance/AirTime) et ordonner la table selon les valeurs décroissantes de cette variable.\n\nhflights3 &lt;- hflights2 |&gt; \n  mutate(AverageSpeed=Distance/AirTime) |&gt;\n  arrange(desc(AverageSpeed))\n\nSélectionner les vols à destination de JFK.\n\nfilter(hflights3,Dest==\"JFK\")\n\n# A tibble: 695 × 23\n    Year Month DayofMonth DayOfWeek DepTime ArrTime UniqueCarrier FlightNum\n   &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;chr&gt;             &lt;int&gt;\n 1  2011     2          7         1     659    1045 JetBlue             620\n 2  2011     2          6         7     700    1045 JetBlue             620\n 3  2011     2          5         6     700    1113 JetBlue             620\n 4  2011     2          6         7    1529    1917 JetBlue             624\n 5  2011     1         24         1     707    1059 JetBlue             620\n 6  2011     1         24         1    1532    1923 JetBlue             624\n 7  2011     2         12         6     659    1105 JetBlue             620\n 8  2011    10         19         3     644    1043 JetBlue             620\n 9  2011    11         10         4    1629    2027 JetBlue             622\n10  2011     2          8         2     654    1049 JetBlue             620\n# ℹ 685 more rows\n# ℹ 15 more variables: TailNum &lt;chr&gt;, ActualElapsedTime &lt;int&gt;, AirTime &lt;int&gt;,\n#   ArrDelay &lt;int&gt;, DepDelay &lt;int&gt;, Origin &lt;chr&gt;, Dest &lt;chr&gt;, Distance &lt;int&gt;,\n#   TaxiIn &lt;int&gt;, TaxiOut &lt;int&gt;, Cancelled &lt;int&gt;, CancellationCode &lt;chr&gt;,\n#   Diverted &lt;int&gt;, ActualGroundTime &lt;int&gt;, AverageSpeed &lt;dbl&gt;\n\n\nCalculer le nombre de vols à destination de JFK.\n\nhflights3 |&gt; filter(Dest==\"JFK\") |&gt; summarise(numb_to_JFK=n())\n\n# A tibble: 1 × 1\n  numb_to_JFK\n        &lt;int&gt;\n1         695\n\n\nCréer un résumé de hflights1 qui contient :\n\nn_flights : le nombre total de vols ;\nn_dest: le nombre total de destinations ;\nn_carrier : le nombre total de compagnies.\n\nOn pourra utiliser n_distinct pour les deux derniers résumés statistiques.\n\nhflights1 |&gt; summarize(n_flights=n(),\n                       n_dest=n_distinct(Dest),\n                       n_carrier=n_distinct(UniqueCarrier))\n\n# A tibble: 1 × 3\n  n_flights n_dest n_carrier\n      &lt;int&gt;  &lt;int&gt;     &lt;int&gt;\n1    227496    116        15\n\n\nCréer un résumé de hflights1 qui contient, pour les vols de la compagnie American,\n\nle nombre total de vols ;\nle nombre total de vols annulés ;\nla valeur moyenne de ArrDelay (attention à la gestion des NA…).\n\n\nhflights1 |&gt; filter(UniqueCarrier==\"American\") |&gt; \n  summarize(n_fligths_Am=n(),\n            n_can_Am=sum(Cancelled),\n            mean_ArrDelay_am=mean(ArrDelay,na.rm=TRUE))\n\n# A tibble: 1 × 3\n  n_fligths_Am n_can_Am mean_ArrDelay_am\n         &lt;int&gt;    &lt;int&gt;            &lt;dbl&gt;\n1         3244       60            0.892\n\n\nCalculer pour chaque compagnie :\n\nle nombre total de vols ;\nLa valeur moyenne de AirTime.\n\n\nhflights1 |&gt; group_by(UniqueCarrier) |&gt;\n  summarise(n_flights=n(),\n            mean_AirTime=mean(AirTime,na.rm=TRUE))\n\n# A tibble: 15 × 3\n   UniqueCarrier      n_flights mean_AirTime\n   &lt;chr&gt;                  &lt;int&gt;        &lt;dbl&gt;\n 1 AirTran                 2139         92.7\n 2 Alaska                   365        254. \n 3 American                3244         69.7\n 4 American_Eagle          4648         93.8\n 5 Atlantic_Southeast      2204        104. \n 6 Continental            70032        145. \n 7 Delta                   2641         97.8\n 8 ExpressJet             73053         83.2\n 9 Frontier                 838        125. \n10 JetBlue                  695        184. \n11 Mesa                      79        122. \n12 SkyWest                16061        113. \n13 Southwest              45343         86.7\n14 US_Airways              4082        134. \n15 United                  2072        157. \n\n\nOrdonner les compagnies en fonction des retards moyens au départ.\n\nhflights1 |&gt; \n  group_by(UniqueCarrier) |&gt;\n  filter(!is.na(DepDelay) & DepDelay&gt;0) |&gt;\n  summarise(meanDepDelay = mean(DepDelay)) |&gt;\n  arrange(meanDepDelay)\n\n# A tibble: 15 × 2\n   UniqueCarrier      meanDepDelay\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 Continental                17.9\n 2 Alaska                     20.8\n 3 Southwest                  21.9\n 4 Frontier                   22.7\n 5 Mesa                       24.5\n 6 SkyWest                    24.6\n 7 American                   24.7\n 8 US_Airways                 26.5\n 9 ExpressJet                 26.9\n10 United                     28.8\n11 Delta                      32.4\n12 AirTran                    33.4\n13 American_Eagle             37.9\n14 JetBlue                    43.5\n15 Atlantic_Southeast         49.3\n\n\n\n\n\nExercice 3.6 (Tournois du grand chelem au tennis) On considère le données sur les résultats de tennis dans les tournois du grand chelem en 2013. Les données, ainsi que le descriptif des variables, se trouvent à l’adresse https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics.\nOn s’intéresse d’abord au tournoi masculin de Roland Garros. On répondra aux questions à l’aide des verbes dplyr.\n\nImporter les données.\n\nFrenchOpen_men_2013 &lt;- read_csv(\"data/FrenchOpen-men-2013.csv\")\nRG2013 &lt;- FrenchOpen_men_2013\nRG2013\n\n# A tibble: 125 × 42\n   Player1  Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1 ACE.1 DBF.1\n   &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Pablo C… Roger …     1      0     0     3    62    27    38    11     1     3\n 2 Somdev … Daniel…     1      1     3     0    62    54    38    22     7     3\n 3 Tobias … Paolo …     1      1     3     2    62    53    38    15     4     6\n 4 Julien … Ricard…     1      1     3     1    72    87    28    19    14     2\n 5 Lukas L… Sam Qu…     1      0     0     3    52    31    48    22     4     4\n 6 Jan Haj… Denis …     1      1     3     1    70    58    30    18     4     4\n 7 Adrian … Pablo …     1      0     2     3    63    71    37    38     5     5\n 8 Gilles … Lleyto…     1      1     3     2    59    42    41    25     7     2\n 9 Philipp… Marin …     1      0     0     3    56    27    44    13     0     6\n10 Radek S… Nick K…     1      0     0     3    63    62    37    29     5     4\n# ℹ 115 more rows\n# ℹ 30 more variables: WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;, BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;,\n#   NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;, ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;,\n#   ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;, FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;,\n#   SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;, DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;,\n#   UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;, NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;,\n#   TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;, ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, …\n\n\nAfficher le nom des adversaires de Roger Federer.\n\nRG2013 |&gt; filter(Player1==\"Roger Federer\" | Player2==\"Roger Federer\") |&gt;\n  select(Player1,Player2)\n\n# A tibble: 5 × 2\n  Player1             Player2      \n  &lt;chr&gt;               &lt;chr&gt;        \n1 Pablo Carreno-Busta Roger Federer\n2 Somdev Devvarman    Roger Federer\n3 Julien Benneteau    Roger Federer\n4 Gilles Simon        Roger Federer\n5 Jo-Wilfried Tsonga  Roger Federer\n\n\nAfficher le nom des demi-finalistes (ceux qui ont atteint le 6ème tour).\n\nRG2013 |&gt; filter(Round==6) |&gt; select(Player1,Player2)\n\n# A tibble: 2 × 2\n  Player1        Player2           \n  &lt;chr&gt;          &lt;chr&gt;             \n1 David Ferrer   Jo-Wilfried Tsonga\n2 Novak Djokovic Rafael Nadal      \n\n\nCombien y a t-il eu de points disputés en moyenne par match ? Il faudra penser à ajouter dans la table une variable correspondant au nombre de points de chaque match (verbe mutate).\n\nRG2013 |&gt; mutate(nb_points=TPW.1+TPW.2) |&gt; select(nb_points) |&gt; summarize_all(mean)\n\n# A tibble: 1 × 1\n  nb_points\n      &lt;dbl&gt;\n1      219.\n\n\nCombien y a t-il eu d’aces par match en moyenne ?\n\nRG2013 |&gt; mutate(nb_aces=ACE.1+ACE.2) |&gt; summarize(mean_aces=mean(nb_aces))\n\n# A tibble: 1 × 1\n  mean_aces\n      &lt;dbl&gt;\n1      12.7\n\n\nCombien y a t-il eu d’aces par match en moyenne à chaque tour ?\n\nRG2013 |&gt; group_by(Round) |&gt; mutate(nb_aces=ACE.1+ACE.2) |&gt;\n  summarize(mean_aces=mean(nb_aces))\n\n# A tibble: 7 × 2\n  Round mean_aces\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     1     13.5 \n2     2     13.2 \n3     3     12.6 \n4     4      9.12\n5     5      7   \n6     6     10   \n7     7      6   \n\n\nCombien y a t-il eu de doubles fautes au total dans le tournoi (attention aux données manquantes, taper help(sum) pour voir comment les gérer) ?\n\nRG2013 |&gt; mutate(nb_df=DBF.1+DBF.2) |&gt; \n  summarize(nb_dbfaults=sum(nb_df,na.rm=TRUE))\n\n# A tibble: 1 × 1\n  nb_dbfaults\n        &lt;dbl&gt;\n1         812\n\n\nImporter les données pour le tournoi masculin de Wimbledon 2013.\n\nWIMB2013 &lt;- read_csv(\"data/Wimbledon-men-2013.csv\")\nWIMB2013\n\n# A tibble: 114 × 42\n   Player1  Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1 ACE.1 DBF.1\n   &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 B.Becker A.Murr…     1      0     0     3    59    29    41    14     5     1\n 2 J.Ward   Y-H.Lu      1      0     1     3    62    77    38    35    18     4\n 3 N.Mahut  J.Hajek     1      1     3     0    72    44    28    10    17     3\n 4 T.Robre… A.Bogo…     1      1     3     0    77    40    23    12     6     0\n 5 R.Haase  M.Youz…     1      0     0     3    68    61    32    15     7     2\n 6 M.Gicqu… V.Posp…     1      0     0     3    59    41    41    27     7     6\n 7 A.Kuzne… A.Mont…     1      1     3     1    63    56    37    21    21     3\n 8 J.Tipsa… V.Troi…     1      0     0     3    61    47    39    21     3     1\n 9 M.Baghd… M.Cilic     1      0     0     3    61    31    39    16     4     5\n10 K.De Sc… P.Lore…     1      1     3     0    67    56    33    21    22     6\n# ℹ 104 more rows\n# ℹ 30 more variables: WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;, BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;,\n#   NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;lgl&gt;, ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;,\n#   ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;, FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;,\n#   SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;, DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;,\n#   UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;, NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;,\n#   TPW.2 &lt;lgl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;, ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, …\n\n\nConcaténer les tables en ajoutant une variable permettant d’identifier le tournoi. On pourra utiliser bind_rows abev l’option .id.\n\nRG_WIMB2013 &lt;- bind_rows(\"RG\"=RG2013,\"WIMB\"=WIMB2013,.id=\"Tournament\")\n\nAfficher les matchs de Federer pour chaque tournoi.\n\nRG_WIMB2013  |&gt; filter(Player1==\"Roger Federer\" | \n                      Player2==\"Roger Federer\" |\n                      Player1==\"R.Federer\" | \n                      Player2==\"R.Federer\") \n\n# A tibble: 7 × 43\n  Tournament Player1    Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 RG         Pablo Car… Roger …     1      0     0     3    62    27    38    11\n2 RG         Somdev De… Roger …     2      0     0     3    61    19    39    16\n3 RG         Julien Be… Roger …     3      0     0     3    82    41    18     8\n4 RG         Gilles Si… Roger …     4      0     2     3    61    65    39    28\n5 RG         Jo-Wilfri… Roger …     5      1     3     0    75    46    25    10\n6 WIMB       V.Hanescu  R.Fede…     1      0     0     3    85    26    15     3\n7 WIMB       S.Stakhov… R.Fede…     2      1     3     1    66    83    34    36\n# ℹ 32 more variables: ACE.1 &lt;dbl&gt;, DBF.1 &lt;dbl&gt;, WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;,\n#   BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;, NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;,\n#   ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;, ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;,\n#   FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;, SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;,\n#   DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;, UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;,\n#   NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;, TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;,\n#   ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, ST5.2 &lt;dbl&gt;\n\n\nou\n\nRG_WIMB2013  |&gt; filter(grepl(\"Federer\",Player2) | grepl(\"Federer\",Player2))\n\n# A tibble: 7 × 43\n  Tournament Player1    Player2 Round Result FNL.1 FNL.2 FSP.1 FSW.1 SSP.1 SSW.1\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 RG         Pablo Car… Roger …     1      0     0     3    62    27    38    11\n2 RG         Somdev De… Roger …     2      0     0     3    61    19    39    16\n3 RG         Julien Be… Roger …     3      0     0     3    82    41    18     8\n4 RG         Gilles Si… Roger …     4      0     2     3    61    65    39    28\n5 RG         Jo-Wilfri… Roger …     5      1     3     0    75    46    25    10\n6 WIMB       V.Hanescu  R.Fede…     1      0     0     3    85    26    15     3\n7 WIMB       S.Stakhov… R.Fede…     2      1     3     1    66    83    34    36\n# ℹ 32 more variables: ACE.1 &lt;dbl&gt;, DBF.1 &lt;dbl&gt;, WNR.1 &lt;dbl&gt;, UFE.1 &lt;dbl&gt;,\n#   BPC.1 &lt;dbl&gt;, BPW.1 &lt;dbl&gt;, NPA.1 &lt;dbl&gt;, NPW.1 &lt;dbl&gt;, TPW.1 &lt;dbl&gt;,\n#   ST1.1 &lt;dbl&gt;, ST2.1 &lt;dbl&gt;, ST3.1 &lt;dbl&gt;, ST4.1 &lt;dbl&gt;, ST5.1 &lt;dbl&gt;,\n#   FSP.2 &lt;dbl&gt;, FSW.2 &lt;dbl&gt;, SSP.2 &lt;dbl&gt;, SSW.2 &lt;dbl&gt;, ACE.2 &lt;dbl&gt;,\n#   DBF.2 &lt;dbl&gt;, WNR.2 &lt;dbl&gt;, UFE.2 &lt;dbl&gt;, BPC.2 &lt;dbl&gt;, BPW.2 &lt;dbl&gt;,\n#   NPA.2 &lt;dbl&gt;, NPW.2 &lt;dbl&gt;, TPW.2 &lt;dbl&gt;, ST1.2 &lt;dbl&gt;, ST2.2 &lt;dbl&gt;,\n#   ST3.2 &lt;dbl&gt;, ST4.2 &lt;dbl&gt;, ST5.2 &lt;dbl&gt;\n\n\nComparer les nombres d’aces par matchs à chaque tour pour les tournois de Roland Garros et Wimbledon.\n\nRG_WIMB2013 |&gt; group_by(Tournament,Round) |&gt; \n  mutate(nb_aces=ACE.1+ACE.2) |&gt; summarize(mean_ace=mean(nb_aces))\n\n# A tibble: 14 × 3\n# Groups:   Tournament [2]\n   Tournament Round mean_ace\n   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 RG             1    13.5 \n 2 RG             2    13.2 \n 3 RG             3    12.6 \n 4 RG             4     9.12\n 5 RG             5     7   \n 6 RG             6    10   \n 7 RG             7     6   \n 8 WIMB           1    21.1 \n 9 WIMB           2    23.9 \n10 WIMB           3    24   \n11 WIMB           4    24.4 \n12 WIMB           5    26.5 \n13 WIMB           6    27.5 \n14 WIMB           7    13   \n\n\nou pour une présentation plus synthétique\n\nRG_WIMB2013 |&gt; group_by(Tournament,Round) |&gt; \n  mutate(nb_aces=ACE.1+ACE.2) |&gt; \n  summarize(mean_ace=mean(nb_aces)) |&gt;\n  pivot_wider(names_from = \"Round\",values_from = \"mean_ace\")\n\n# A tibble: 2 × 8\n# Groups:   Tournament [2]\n  Tournament   `1`   `2`   `3`   `4`   `5`   `6`   `7`\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 RG          13.5  13.2  12.6  9.12   7    10       6\n2 WIMB        21.1  23.9  24   24.4   26.5  27.5    13\n\n\n\n\n\n\n3.2.5 Compléments : Tidy data avec tidyr\nL’utilisation de dplyr et de ggplot (que nous verrons dans la partie suivante) suppose que les données sont présentées sous un format adéquat : une ligne est un individu et une colonne une variable, on parle alors de tidy data. Cette représentation peut dépendre du contexte, et surtout de ce que l’on souhaite faire avec les données. Considérons par exemple le tableau suivant qui présente les taux de chômage des départements français en 2002, 2006, 2011\n\ndf &lt;- read_delim(\"data/tauxchomage.csv\",delim=\";\") |&gt; select(-1)\ndf\n\n# A tibble: 96 × 4\n   NOM_DPT                 TCHOMB1T01 TCHOMB1T06 TCHOMB1T11\n   &lt;chr&gt;                        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ain                            3.9        5.9        6.6\n 2 Aisne                         10.6       12         13.2\n 3 Allier                         9          9.2        9.7\n 4 Alpes-de-Haute-Provence        9.5        9.7       10.3\n 5 Hautes-Alpes                   7.1        7.7        8.3\n 6 Alpes-Maritimes                9.1        8.9        9.2\n 7 Ardèche                        8.1        9.6        9.7\n 8 Ardennes                      11.5       12.8       10.9\n 9 Ariège                         9.2       10.1       10.6\n10 Aube                           8.2       10         10  \n# ℹ 86 more rows\n\n\nPrésenté ainsi ce tableau comporte 4 variables (en comptant l’identifiant du département). Dans certaines situations, on peut préférer une structure à 3 variables :\n\nle département\nl’année\nle taux de chômage\n\nNous verrons qu’il n’est par exemple pas possible de faire un boxplot permettant de visualiser la distribution du taux de chômage en fonction de l’année à l’aide de ggplot2. Pour passer à ce format il est nécessaire d’assembler les 3 colonnes correspondant aux taux de chômage en une seule colonne et ajouter une colonne qui permette d’identifier l’année. La table obtenue aura plus de lignes, on parle de format long. La fonction pivot_longer du package tidyr permet de faire cette transformation :\n\ndf1 &lt;- df |&gt; pivot_longer(-NOM_DPT,names_to=\"Année\",values_to=\"TCHOM\") |&gt; \n  mutate(Année=fct_recode(Année,\"2001\"=\"TCHOMB1T01\",\"2006\"=\"TCHOMB1T06\",\"2011\"=\"TCHOMB1T11\"))\ndf1\n\n# A tibble: 288 × 3\n   NOM_DPT                 Année TCHOM\n   &lt;chr&gt;                   &lt;fct&gt; &lt;dbl&gt;\n 1 Ain                     2001    3.9\n 2 Ain                     2006    5.9\n 3 Ain                     2011    6.6\n 4 Aisne                   2001   10.6\n 5 Aisne                   2006   12  \n 6 Aisne                   2011   13.2\n 7 Allier                  2001    9  \n 8 Allier                  2006    9.2\n 9 Allier                  2011    9.7\n10 Alpes-de-Haute-Provence 2001    9.5\n# ℹ 278 more rows\n\n\nIl sera alors aisé de faire le boxplot souhaité avec\n\nggplot(df1)+aes(x=Année,y=TCHOM)+geom_boxplot()\n\n\n\n\nL’opération inverse peut être effectuée avec pivot_wider :\n\ndf1 |&gt; pivot_wider(names_from=\"Année\",values_from=\"TCHOM\")\n\n# A tibble: 96 × 4\n   NOM_DPT                 `2001` `2006` `2011`\n   &lt;chr&gt;                    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Ain                        3.9    5.9    6.6\n 2 Aisne                     10.6   12     13.2\n 3 Allier                     9      9.2    9.7\n 4 Alpes-de-Haute-Provence    9.5    9.7   10.3\n 5 Hautes-Alpes               7.1    7.7    8.3\n 6 Alpes-Maritimes            9.1    8.9    9.2\n 7 Ardèche                    8.1    9.6    9.7\n 8 Ardennes                  11.5   12.8   10.9\n 9 Ariège                     9.2   10.1   10.6\n10 Aube                       8.2   10     10  \n# ℹ 86 more rows\n\n\nLe package tidyr possède plusieurs autres verbes qui pourront aider l’utilisateur à mettre la table sous le meilleur format pour les analyses. Citons par exemple le verbe separate qui va séparer une colonne en plusieurs :\n\n(df &lt;- tibble(date=as.Date(c(\"01/03/2015\",\"05/18/2017\",\n                             \"09/14/2018\"),\"%m/%d/%Y\"),\n              temp=c(18,21,15)))\n\n# A tibble: 3 × 2\n  date        temp\n  &lt;date&gt;     &lt;dbl&gt;\n1 2015-01-03    18\n2 2017-05-18    21\n3 2018-09-14    15\n\n (df1 &lt;- df |&gt; separate_wider_delim(date,delim=\"-\",\n                                       names=c(\"year\",\"month\",\"day\")))\n\n# A tibble: 3 × 4\n  year  month day    temp\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 2015  01    03       18\n2 2017  05    18       21\n3 2018  09    14       15\n\n\nou le verbe unite qui fera l’opération inverse\n\ndf1 |&gt; \n  unite(date,year,month,day,sep=\"/\") |&gt;\n  mutate(date1=lubridate::as_date(date))\n\n# A tibble: 3 × 3\n  date        temp date1     \n  &lt;chr&gt;      &lt;dbl&gt; &lt;date&gt;    \n1 2015/01/03    18 2015-01-03\n2 2017/05/18    21 2017-05-18\n3 2018/09/14    15 2018-09-14\n\n\nCitons enfin les verbes :\n\nseparate_longer_delim qui permettra de séparer des informations en plusieurs lignes ;\nseparate_wider_regex pour créer de nouvelles colonnes ;\ncomplete pour ajouter des lignes dans un tableau, par exemple des non réponses à un questionnaire."
  },
  {
    "objectID": "031-programmer.html#structures-de-contrôle",
    "href": "031-programmer.html#structures-de-contrôle",
    "title": "4  Programmer",
    "section": "4.1 Structures de contrôle",
    "text": "4.1 Structures de contrôle\nOn énumère les principales structures :\n\nBoucles for :\n\nfor (i in vecteur){\n  expr1\n  expr2\n  ...\n}\n\nPar exemple\n\nfor (i in 1:3){print(i)}\n\n[1] 1\n[1] 2\n[1] 3\n\nfor (i in c(\"lundi\",\"mardi\",\"mercredi\")){print(i)}\n\n[1] \"lundi\"\n[1] \"mardi\"\n[1] \"mercredi\"\n\n\nCondition while\n\nwhile (condition) {expression}\n\nPar exemple :\n\ni &lt;- 1\nwhile (i&lt;=3) {\n  print(i)\n  i &lt;- i+1\n}\n\n[1] 1\n[1] 2\n[1] 3\n\n\nCondition if else\n\nif (condition){\n  expr1\n  ...\n} else {\n  expre2\n  ...\n}\n\nPar exemple :\n\na &lt;- -2\nif (a&gt;0){\n  a &lt;- a+1\n} else {\n  a &lt;- a-1\n}\nprint(a)\n\n[1] -3\n\n\nswitch\n\nswitch(expression,\n       \"cond1\" = action1,\n       \"cond2\" = action2,\n       ...)\n\nPar exemple :\n\nX &lt;- matrix(0,nrow = 5,ncol = 5)\nswitch(class(X)[1],\n       \"matrix\"=print(\"X est une matrice\"),\n       \"data.frame\"=print(\"X est un data.frame\"),\n       \"numeric\"=print(\"X est de classe numérique\"))\n\n[1] \"X est une matrice\""
  },
  {
    "objectID": "031-programmer.html#écrire-une-fonction",
    "href": "031-programmer.html#écrire-une-fonction",
    "title": "4  Programmer",
    "section": "4.2 Écrire une fonction",
    "text": "4.2 Écrire une fonction\nOn peut définir sa propre fonction dans un objet avec function :\n\nmafonct &lt;- function(param1,param2,...){\n  expr1\n  expr2\n  return(...)\n  }\n\nConstruisons par exemple la fonction factorielle qui calcule la factorielle d’un entier n :\n\nfactorielle &lt;- function(n){\n  return(prod(1:n))\n  }\n\nOn peut la tester\n\nfactorielle(5)\n\n[1] 120\n\n\nOn propose d’améliorer cette fonction en spécifiant des messages d’erreur ou d’alerte :\n\nfactorielle &lt;- function(n){\n  if (n&lt;=0) stop(\"l'entier doit être strictement positif\")\n  if (ceiling(n)!=n) warning(paste(\"arrondi de\",n,\"en\",ceiling(n)))\n  return(prod(1:ceiling(n)))\n  }\n\nOn a alors un message d’erreur lorsque le paramètre est négatif\n\nfactorielle(-2)\n\nError in factorielle(-2): l'entier doit être strictement positif\n\n\nou un avertissement si ce n’est pas un entier\n\nfactorielle(2.8)\n\nWarning in factorielle(2.8): arrondi de 2.8 en 3\n\n\n[1] 6"
  },
  {
    "objectID": "031-programmer.html#les-fonctions-map",
    "href": "031-programmer.html#les-fonctions-map",
    "title": "4  Programmer",
    "section": "4.3 Les fonctions map",
    "text": "4.3 Les fonctions map\nCes fonctions appartiennent au package purrr du tidyverse. Elles permettent d’appliquer des fonctions à des listes et donc à des tibbles. On peut les voir comme des versions améliorées des fonctions apply. On peut par exemple retrouver les sorties de\n\napply(iris[,-5],2,mean)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n\navec\n\nmap(iris[,-5],mean)\n\n$Sepal.Length\n[1] 5.843333\n\n$Sepal.Width\n[1] 3.057333\n\n$Petal.Length\n[1] 3.758\n\n$Petal.Width\n[1] 1.199333\n\n\nou encore\n\nmap_dbl(iris[,-5],mean)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n\nqui renvoie un vecteur de classe numeric plutôt qu’une liste. On peut citer également les fonctions map_lgl, map_chr, map_dbl qui retournent des vecteurs de logiques, de caractères ou d’entiers.\nDans le même style, on dispose des fonctions map2_... pour appliquer des fonctions à des paires d’éléments de listes. On peut par exemple sommer les élément de deux listes avec\n\nl1 &lt;- list(1,2,3)\nl2 &lt;- list(4,5,6)\nmap2(l1,l2,`+`)\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 7\n\n[[3]]\n[1] 9\n\n#ou pour obtenir un vecteur\nmap2_dbl(l1,l2,`+`)\n\n[1] 5 7 9\n\n\nIl est également possible de spécifier explicitement sa propre fonction lorsqu’elle n’existe pas\n\nset.seed(123)\ntbl1 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\ntbl2 &lt;- tibble(age=runif(5,20,50),taille=runif(5,150,180))\nmap2_dbl(tbl1,tbl2,function(d1,d2) mean(rbind(d1,d2)))\n\n      age    taille \n 38.21492 164.83358 \n\n\nLa syntaxe peut paraître un peu lourde, avec notamment l’utilisation de function. On utilise régulièrement des fonctions anonymes qui peuvent se définir à l’aide d’une formule :\n\nmap2_dbl(tbl1,tbl2,~mean(rbind(.x,.y)))\n\n      age    taille \n 38.21492 164.83358 \n\n\nou en spécifiant explicitement les arguments\n\nmap2_dbl(tbl1,tbl2,\\(d1,d2) mean(rbind(d1,d2)))\n\n      age    taille \n 38.21492 164.83358 \n\n\nNotons enfin que l’utilisation des fonctions anonymes diffèrent lorsqu’on chaîne les opérations avec le pipe de la distribution de R de base |&gt; ou avec celui de dplyr %&gt;% :\n\nset.seed(123)\nX1 &lt;- rnorm(100)\nc(0.25,0.5,0.75) %&gt;% quantile(X1,probs = .)\n\n        25%         50%         75% \n-0.49385424  0.06175631  0.69181917 \n\nc(0.25,0.5,0.75) |&gt; quantile(X1,probs = .)\n\nError in if (na.rm) x &lt;- x[!is.na(x)] else if (anyNA(x)) stop(\"missing values and NaN's not allowed if 'na.rm' is FALSE\"): the condition has length &gt; 1\n\n\nLe . permet d’indiquer la place de la quantité à gauche du pipe %&gt;%. Lorsqu’on utilise |&gt;, il faut utiliser une fonction anonyme :\n\nc(0.25,0.5,0.75) |&gt; (\\(p) quantile(X1,probs = p))()\n\n        25%         50%         75% \n-0.49385424  0.06175631  0.69181917"
  },
  {
    "objectID": "031-programmer.html#exercices",
    "href": "031-programmer.html#exercices",
    "title": "4  Programmer",
    "section": "4.4 Exercices",
    "text": "4.4 Exercices\n\nExercice 4.1 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui admet en entrée un entier positif n et qui renvoie la somme des entiers qui vont de 1 à n.\n\nmasomme &lt;- function(n){\n  sum(1:n)\n}\nmasomme(5)\n\n[1] 15\n\n\nÉcrire une fonction qui remplace les données manquantes d’un jeu de données par la moyenne ou la médiane de la variable. Choisir la moyenne ou la médiane doit être un paramètre de la fonction. On pourra tester la fonction sur le tibble suivant :\n\nset.seed(123)\ntbl &lt;- tibble(X1=as.numeric(sample(10,5)),X2=as.numeric(sample(10,5)))\ntbl[3,1] &lt;- NA;tbl[4,2] &lt;- NA\ntbl\n\n# A tibble: 5 × 2\n     X1    X2\n  &lt;dbl&gt; &lt;dbl&gt;\n1     3     5\n2    10     4\n3    NA     6\n4     8    NA\n5     6     1\n\n\n\nimputation &lt;- function(tbl,choix=\"moyenne\"){\n  if (choix==\"moyenne\"){\n    moy &lt;- map_dbl(tbl,\\(x) mean(x,na.rm = TRUE)) |&gt; as.numeric()\n    for (i in 1:ncol(tbl)){\n      tbl[is.na(tbl[,i]),i] &lt;- as.numeric(moy[i])\n      }\n    } else {\n      med &lt;- map_dbl(tbl,\\(x) median(x,na.rm = TRUE)) |&gt; as.numeric()\n      for (i in 1:ncol(tbl)){\n        tbl[is.na(tbl[,i]),i] &lt;- med[i]\n      }\n    }\n  return(tbl)\n}\nimputation(tbl)\n\n# A tibble: 5 × 2\n     X1    X2\n  &lt;dbl&gt; &lt;dbl&gt;\n1  3        5\n2 10        4\n3  6.75     6\n4  8        4\n5  6        1\n\nimputation(tbl,choix=\"mediane\")\n\n# A tibble: 5 × 2\n     X1    X2\n  &lt;dbl&gt; &lt;dbl&gt;\n1     3   5  \n2    10   4  \n3     7   6  \n4     8   4.5\n5     6   1  \n\n\n\nOn peut également utiliser la fonction replace_na de tidyr :\n\n\nimputation1 &lt;- function(tbl,choix=\"moyenne\"){\n  if (choix==\"moyenne\"){\n    moy &lt;- map_dfc(tbl,\\(x) mean(x,na.rm = TRUE)) \n    tbl1 &lt;- map2_df(tbl,moy,\\(x,y) replace_na(x,y))\n    } else {\n      med &lt;- map_dfc(tbl,\\(x) median(x,na.rm = TRUE))\n      tbl1 &lt;- map2_df(tbl,med,\\(x,y) replace_na(x,y))\n    }\n  return(tbl1)\n}\nimputation1(tbl)\n\n# A tibble: 5 × 2\n     X1    X2\n  &lt;dbl&gt; &lt;dbl&gt;\n1  3        5\n2 10        4\n3  6.75     6\n4  8        4\n5  6        1\n\nimputation1(tbl,choix=\"mediane\")\n\n# A tibble: 5 × 2\n     X1    X2\n  &lt;dbl&gt; &lt;dbl&gt;\n1     3   5  \n2    10   4  \n3     7   6  \n4     8   4.5\n5     6   1  \n\n\n\n\n\nExercice 4.2 (Calculs d’indicateurs)  \n\nÉcrire une fonction qui calcule la moyenne et la variance des colonnes d’un jeu de données qui ne contient que des variables continues. On utilisera une boucle for et on testera la fonction sur les 4 premières colonnes des données iris.\n\nmoy_var &lt;- function(tbl){\n  p &lt;- ncol(tbl)\n  moyenne &lt;- rep(0,p)\n  variance &lt;- rep(0,p)\n  for (i in 1:ncol(tbl)){\n    moyenne[i] &lt;- mean(tbl[,i])\n    variance[i] &lt;- var(tbl[,i])\n  }\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n\n$moy\n[1] 5.843333 3.057333 3.758000 1.199333\n\n$var\n[1] 0.6856935 0.1899794 3.1162779 0.5810063\n\n\nMême question en utilisant la fonction apply.\n\nmoy_var &lt;- function(tbl){\n  moyenne &lt;- apply(tbl,2,mean)\n  variance &lt;- apply(tbl,2,var)\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n\n$moy\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n$var\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.6856935    0.1899794    3.1162779    0.5810063 \n\n\nMême question en utilisant une fonction map_....\n\nmoy_var &lt;- function(tbl){\n  moyenne &lt;- map_dbl(tbl,mean)\n  variance &lt;- map_dbl(tbl,var)\n  return(list(moy=moyenne,var=variance))\n}\nmoy_var(iris[,1:4])\n\n$moy\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n$var\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.6856935    0.1899794    3.1162779    0.5810063 \n\n\n\nou encore\n\n\nmoy_var &lt;- function(tbl){\n  map(tbl,\\(x) c(moy=mean(x),var=var(x))) |&gt; as_tibble()\n}\nmoy_var(iris[,1:4])\n\n# A tibble: 2 × 4\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1        5.84        3.06          3.76       1.20 \n2        0.686       0.190         3.12       0.581\n\n\nUtiliser la méthode de votre choix pour un tibble qui peut comporter des variables qualitatives. La fonction renverra un warning qui liste les variables qualitatives.\n\nmoy_var &lt;- function(tbl){\n  nature &lt;- map_chr(tbl,class)\n  if (any(nature!=\"numeric\")){\n    warning(paste(\"Variable(s)\",names(tbl)[nature!=\"numeric\"],\"non continue(s)\"))\n  }\n  res &lt;- map(tbl[,nature==\"numeric\"],\\(x) c(moy=mean(x),var=var(x))) |&gt;\n    as_tibble()\n  return(res)\n}\nmoy_var(iris)\n\nWarning in moy_var(iris): Variable(s) Species non continue(s)\n\n\n# A tibble: 2 × 4\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1        5.84        3.06          3.76       1.20 \n2        0.686       0.190         3.12       0.581"
  },
  {
    "objectID": "03-2-bdd.html#sql-structured-query-language",
    "href": "03-2-bdd.html#sql-structured-query-language",
    "title": "5  Base de données",
    "section": "5.1 SQL : Structured Query Language",
    "text": "5.1 SQL : Structured Query Language\nLa package DBI (DataBase Interface) offre une interface de communication entre R et différentes bases de données de type SQL à l’aide de pilotes dédiés : https://dbi.r-dbi.org. R possède différents packages permettant d’accéder à des bases SQL :\n\n\n\nBase\nPackage\n\n\n\n\nMysSQL\nRMySQL\n\n\nMariaDB\nRMariaDB\n\n\nPostgres\nRPostgres\n\n\nSQLite\nRSQLite\n\n\n\nDBI propose une manière unifiée d’accéder à ces différentes bases en précisant le nom de la base de données, le nom de l’hôte, le port ) écouter ainsi que l’identifiant et le mot de passe de l’utilisateur. Par exemple, dans le cas d’une base PostGreSQL:\n\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"DATABASE_NAME\",\n  host = \"HOST\",\n  port = 5432,\n  user = \"USERNAME\",\n  password = \"PASSWORD\")\n\nAfin de simplifier les choses, on propose de se connecter à une base de données éphémère créée en mémoire vive :\n\nlibrary(DBI)\ncon &lt;- dbConnect(RSQLite::SQLite(), dbname = \":memory:\")\n\nÀ ce stade la base ne contient aucune table :\n\ndbListTables(con)\n\ncharacter(0)\n\n\nOn peuple la base de deux tables simples :\n\nset.seed(1234)\ntbl1 &lt;- tibble(ID=sample(LETTERS),age=sample(1:100,26))\ntbl2 &lt;- tibble(ID=sample(LETTERS),taille=sample(160:180,26,replace = TRUE))\n\ndf &lt;- data.frame(\n  x = runif(25),\n  label = sample(c(\"A\", \"B\"), size = 25, replace = TRUE)\n)\ndbWriteTable(con, name = \"table1\",value = tbl1)\ndbWriteTable(con, name = \"table2\",value = tbl2)\ndbListTables(con)\n\n[1] \"table1\" \"table2\"\n\n\nOn peut lire la liste des colonnes d’une table avec\n\ndbListFields(con,\"table1\")\n\n[1] \"ID\"  \"age\"\n\n\nIl est possible de lire la table avec\n\ndbReadTable(con,\"table1\") |&gt; head()\n\n  ID age\n1  P   5\n2  V  66\n3  E  47\n4  L  40\n5  O  84\n6  I  48\n\n\n\n5.1.1 Requêtes SQL\nDBI permet d’effectuer des requêtes SQL du genre\n\nSELECT j FROM df WHERE i GROUP BY by\n\nsur les bases de données. Par exemple\n\nreq1 &lt;- dbSendQuery(con,\"SELECT * FROM table1 WHERE age&gt;85\")\nreq1\n\n&lt;SQLiteResult&gt;\n  SQL  SELECT * FROM table1 WHERE age&gt;85\n  ROWS Fetched: 0 [incomplete]\n       Changed: 0\n\n\nOn peut collecter, ramener vers R, les données issues de la requête avec dbFetch :\n\nres1 &lt;- dbFetch(req1)\nclass(res1)\n\n[1] \"data.frame\"\n\nres1\n\n  ID age\n1  F  87\n2  M  96\n\n\nLa requête peut être soumise et exécutée directement avec dbGetQuery :\n\ndbGetQuery(con,\"SELECT * FROM table1 WHERE age&gt;85\")\n\n  ID age\n1  F  87\n2  M  96\n\n\nÀ titre d’autre exemple, on peut effectuer une jointure des deux tables de la base avec\n\nres &lt;- dbGetQuery(con,\"\n                   SELECT *\n                   FROM table1\n                   INNER JOIN table2 ON table1.id = table2.id\n                   ORDER BY ID\n                   \")\nhead(res)\n\n  ID age ID taille\n1  A  26  A    180\n2  B  32  B    165\n3  C  80  C    167\n4  D  72  D    165\n5  E  47  E    180\n6  F  87  F    161\n\n\nDBI possède de nombreuses autres fonctions pour gérer les bases de données, par exemple\n\ndbExistsTable(con,name) \\(\\Longrightarrow\\) vérifier si la table name existe pour la connexion con.\ndbRemoveTable(con,name,...) \\(\\Longrightarrow\\) effacer la table name de la connexion con.\ndbGetRowsAffected(req,...) \\(\\Longrightarrow\\) nombre de lignes affectés (extraction, effacement, modification) par la requête req.\ndbGetRowCount(req,...) \\(\\Longrightarrow\\) nombre de lignes collectées lors de la requête req.\n\n\n\n5.1.2 Requêter avec dplyr\nL’approche présentée dans la partie précédente requiert des connaissances solides en SQL. Elle n’est pas forcément nécessaire puisqu’il est également possible d’utiliser dplyr (voir Chapitre 3) sur des bases SQL.\nLa fonction tbl permet notamment de se connecter à une table de la base de données.\n\nT1 &lt;- tbl(con,\"table1\") \n\nIl est intéressante de regarder la classe de l’objet construit :\n\nclass(T1)\n\n[1] \"tbl_SQLiteConnection\" \"tbl_dbi\"              \"tbl_sql\"             \n[4] \"tbl_lazy\"             \"tbl\"                 \n\n\nSans surprise on retrouve un tibble mais également la présence du mot paresseux (lazy). En affichant T1\n\nT1\n\n# Source:   table&lt;table1&gt; [?? x 2]\n# Database: sqlite 3.43.2 [:memory:]\n   ID      age\n   &lt;chr&gt; &lt;int&gt;\n 1 P         5\n 2 V        66\n 3 E        47\n 4 L        40\n 5 O        84\n 6 I        48\n 7 X         3\n 8 F        87\n 9 Z        41\n10 D        72\n# ℹ more rows\n\n\non remarque que le nombre de lignes n’est pas connu. En effet\n\ndim(T1)\n\n[1] NA  2\n\n\nLorsqu’elle s’applique à un tableau distant, une suite de commandes dplyr ne fait rien. En effet, la requête\n\n(req &lt;- T1 |&gt; filter(age&gt;85))\n\n# Source:   SQL [2 x 2]\n# Database: sqlite 3.43.2 [:memory:]\n  ID      age\n  &lt;chr&gt; &lt;int&gt;\n1 F        87\n2 M        96\n\n\nne peut être utilisé directement sur R. Par exemple\n\nreq$age+1\n\nError in `req$age`:\n! The `$` method of &lt;tbl_lazy&gt; is for internal use only.\nℹ Use `dplyr::pull()` to get the values in a column.\n\n\nCe n’est que lorsqu’on demande un résultat que dplyr effectue une action. On peut le faire avec la fonction collect :\n\nres &lt;- collect(req)\ndim(res)\n\n[1] 2 2\n\nres$age+1\n\n[1] 88 97\n\n\nCe principe d’évaluation retardée se retrouver fréquemment dans R sous le nom d’évaluation paresseuse, d’où lazy dans tbl_lazy.\nNotons qu’on peut visualiser la requête construite avec la fonction show_query :\n\nreq |&gt; show_query()\n\n&lt;SQL&gt;\nSELECT `table1`.*\nFROM `table1`\nWHERE (`age` &gt; 85.0)\n\n\nEnfin, on n’oublie pas de se déconnecter de la base à la fin de l’étude :\n\ndbDisconnect(con)"
  },
  {
    "objectID": "03-2-bdd.html#exercices",
    "href": "03-2-bdd.html#exercices",
    "title": "5  Base de données",
    "section": "5.2 Exercices",
    "text": "5.2 Exercices\n\nExercice 5.1 (Le vélo star) On s’intéresse dans cet exercice aux données sur les stations velib présentes sur le site de Rennes Métropole https://data.rennesmetropole.fr/explore/?sort=modified. Plus particulièreement, aux tables\n\nEtat qui propose des informations sur l’état des stations velib en temps réel\nTopologie qui contient la liste des stations et la géolocalisation.\n\n\nCréer une base de données SQL qui contient ces deux tables et connectez vous à cette base.\n\netat &lt;- read_csv2(\"data/etat_velib_rennes\")\ntopologie &lt;- read_csv2(\"data/topologie_velib_rennes.csv\")\n#con &lt;- dbConnect(RSQLite::SQLite(), dbname = \"data/velib_rennes.sqlite\")\ncon &lt;- dbConnect(RSQLite::SQLite(), dbname = \":memory:\")\ndbWriteTable(con,\"etat\",etat)\ndbWriteTable(con,\"topologie\",topologie)\n\n\nOn peut maintenant se connecter :\n\n\ndbListTables(con)\n\n[1] \"etat\"      \"topologie\"\n\nfor(table in dbListTables(con)) {\n  cat(\"--- Table\", table, \"---\\n\")\n  print(dbListFields(con, table))\n}\n\n--- Table etat ---\n[1] \"Station (ID)\"             \"Nom\"                     \n[3] \"Coordonnées\"              \"Etat\"                    \n[5] \"Emplacements actuels\"     \"Emplacements disponibles\"\n[7] \"Vélos disponibles\"        \"Dernière mise à jour\"    \n--- Table topologie ---\n [1] \"Identifiant\"                            \n [2] \"Date de début de version\"               \n [3] \"Date de fin de version\"                 \n [4] \"Est la version active\"                  \n [5] \"Code\"                                   \n [6] \"Nom\"                                    \n [7] \"Adresse (numéro)\"                       \n [8] \"Adresse (voie)\"                         \n [9] \"Commune (code INSEE)\"                   \n[10] \"Commune (nom)\"                          \n[11] \"Coordonnées\"                            \n[12] \"Station de métro en correspondance (ID)\"\n[13] \"Emplacements\"                           \n[14] \"Station la plus proche 1 (ID)\"          \n[15] \"Station la plus proche 2 (ID)\"          \n[16] \"Station la plus proche 3 (ID)\"          \n[17] \"Avec terminal CB\"                       \n\n\nSélectionner l’identifiant Identifiant, le nom Nom et l’identifiant de la station proche Station la plus proche 1 (ID) depuis la table topologie.\n\nquery &lt;- \"SELECT Identifiant, Nom, `Station la plus proche 1 (ID)` FROM topologie\"\ndbGetQuery(con, query) |&gt;  head(3)\n\n  Identifiant               Nom Station la plus proche 1 (ID)\n1        5516     Champs Libres                          5584\n2        5517 Charles de Gaulle                          5516\n3        5520    Pont de Nantes                          5543\n\n\nFaire une jointure pour créer une table qui contient la liste des stations avec l’identifiant, le nom et le nom de la station la plus proche.\n\nquery &lt;- \"\nSELECT left.identifiant AS Identifiant,\n       left.Nom AS nom,\n       right.Nom AS nom_proche\nFROM topologie AS left\nLEFT JOIN topologie AS right\nON (left.`Station la plus proche 1 (ID)` = right.Identifiant)\"\ndbGetQuery(con, query) |&gt;  head(3)\n\n  Identifiant               nom      nom_proche\n1        5516     Champs Libres            &lt;NA&gt;\n2        5517 Charles de Gaulle   Champs Libres\n3        5520    Pont de Nantes Cité Judiciaire\n\n\nAjouter à la table précédente la distance euclidienne entre la station et la station proche associée à l’identifiant Station la plus proche 1 (ID) de la table Topologie.\n\nOn commence par créer les colonnes latitude et longitude :\n\n\n# une seule colonne en sqlite\nquery_add_latitude &lt;- \"\nALTER TABLE topologie \nADD COLUMN latitude DOUBLE\n;\n\"\ndbExecute(con, query_add_latitude)\n\n[1] 0\n\nquery_add_longitude &lt;- \"\nALTER TABLE topologie \nADD COLUMN longitude DOUBLE\n;\n\"\ndbExecute(con, query_add_longitude)\n\n[1] 0\n\n\n\nquery_update_lon_lat &lt;- \"\nUPDATE topologie SET latitude = SUBSTR(`Coordonnées`, 1, INSTR(`Coordonnées`, ',') - 1), \n                     longitude=SUBSTR(`Coordonnées`, INSTR(`Coordonnées`, ' ') + 1);\"\ndbExecute(con, query_update_lon_lat)\n\n[1] 57\n\n\n\nOn peut maintenant calculer la distance :\n\n\nquery &lt;- \"\nSELECT left.identifiant AS identifiant,\n       left.nom AS nom,\n       right.nom AS nom_proche,\n       (\n         POWER((left.latitude - right.latitude), 2.0) +\n         POWER((left.longitude - right.longitude), 2.0)\n       ) AS distance\nFROM topologie AS left\nLEFT JOIN topologie AS right\nON (left.`Station la plus proche 1 (ID)` = right.identifiant)\n\"\ndbGetQuery(con, query) |&gt; head(3)\n\n  identifiant               nom      nom_proche     distance\n1        5516     Champs Libres            &lt;NA&gt;           NA\n2        5517 Charles de Gaulle   Champs Libres 7.971157e-06\n3        5520    Pont de Nantes Cité Judiciaire 7.604561e-06\n\n\nNous nous trouvons au point de coordonnées (48.1179151,-1.7028661). Créer une table avec le nom des trois stations les plus proches classées par ordre de distance et le nombre d’emplacements libres dans ces stations.\n\nquery_add_latitude &lt;- \"\nALTER TABLE etat \nADD COLUMN latitude DOUBLE\n;\n\"\ndbExecute(con, query_add_latitude)\n\n[1] 0\n\nquery_add_longitude &lt;- \"\nALTER TABLE etat \nADD COLUMN longitude DOUBLE\n;\n\"\ndbExecute(con, query_add_longitude)\n\n[1] 0\n\n\n\nquery_update_lon_lat &lt;- \"\nUPDATE etat SET latitude = SUBSTR(`Coordonnées`, 1, INSTR(`Coordonnées`, ',') - 1), longitude=SUBSTR(`Coordonnées`, INSTR(`Coordonnées`, ' ') + 1);\"\ndbExecute(con, query_update_lon_lat)\n\n[1] 57\n\n\n\nma_latitude &lt;- 48.1179151\nma_longitude = -1.7028661\n\nquery &lt;- paste0(\"\nSELECT nom,\n       (\n         POWER((latitude - \", ma_latitude, \"), 2.0) +\n         POWER((longitude - \", ma_longitude, \"), 2.0)\n       ) AS distance,\n       `emplacements disponibles`\nFROM Etat\nORDER BY distance\nLIMIT 3\n\")\ndbGetQuery(con, query)\n\n                   Nom     distance Emplacements disponibles\n1               Berger 7.540436e-06                        3\n2 Villejean-Université 1.197776e-05                       14\n3              Marbeuf 3.864347e-05                       11\n\n\nReprendre les questions précédentes en utilisant les fonctions de dplyr.\n\ndb_etat &lt;- tbl(con, \"Etat\")\ncolnames(db_etat)\n\n [1] \"Station (ID)\"             \"Nom\"                     \n [3] \"Coordonnées\"              \"Etat\"                    \n [5] \"Emplacements actuels\"     \"Emplacements disponibles\"\n [7] \"Vélos disponibles\"        \"Dernière mise à jour\"    \n [9] \"latitude\"                 \"longitude\"               \n\ndb_topologie &lt;- tbl(con, \"Topologie\")\ncolnames(db_topologie)\n\n [1] \"Identifiant\"                            \n [2] \"Date de début de version\"               \n [3] \"Date de fin de version\"                 \n [4] \"Est la version active\"                  \n [5] \"Code\"                                   \n [6] \"Nom\"                                    \n [7] \"Adresse (numéro)\"                       \n [8] \"Adresse (voie)\"                         \n [9] \"Commune (code INSEE)\"                   \n[10] \"Commune (nom)\"                          \n[11] \"Coordonnées\"                            \n[12] \"Station de métro en correspondance (ID)\"\n[13] \"Emplacements\"                           \n[14] \"Station la plus proche 1 (ID)\"          \n[15] \"Station la plus proche 2 (ID)\"          \n[16] \"Station la plus proche 3 (ID)\"          \n[17] \"Avec terminal CB\"                       \n[18] \"latitude\"                               \n[19] \"longitude\"                              \n\n\n\ndb_topologie |&gt;\n  select(Identifiant, Nom, `Station la plus proche 1 (ID)`) |&gt;\n  head(3) |&gt;\n  collect()\n\n# A tibble: 3 × 3\n  Identifiant Nom               `Station la plus proche 1 (ID)`\n        &lt;dbl&gt; &lt;chr&gt;                                       &lt;dbl&gt;\n1        5516 Champs Libres                                5584\n2        5517 Charles de Gaulle                            5516\n3        5520 Pont de Nantes                               5543\n\n\n\ndb_topologie |&gt;\n  left_join(db_topologie, by = join_by(`Station la plus proche 1 (ID)` == Identifiant)) |&gt; \n  rename(Nom = Nom.x, nom_proche = Nom.y) |&gt;\n  select(Identifiant, Nom, nom_proche) |&gt;\n  head(3) |&gt;\n  collect()\n\n# A tibble: 3 × 3\n  Identifiant Nom               nom_proche     \n        &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;          \n1        5516 Champs Libres     &lt;NA&gt;           \n2        5517 Charles de Gaulle Champs Libres  \n3        5520 Pont de Nantes    Cité Judiciaire\n\n\n\ndb_topologie |&gt;\n  left_join(db_topologie, by = join_by(`Station la plus proche 1 (ID)` == Identifiant)) |&gt;\n  mutate(distance = (latitude.x - latitude.y)^2 + (longitude.x - longitude.y)^2) |&gt;\n  rename(nom = Nom.x, nom_proche = Nom.y) |&gt;\n  select(Identifiant, nom, nom_proche, distance) |&gt;\n  head(3) |&gt;\n  collect()\n\n# A tibble: 3 × 4\n  Identifiant nom               nom_proche         distance\n        &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;                 &lt;dbl&gt;\n1        5516 Champs Libres     &lt;NA&gt;            NA         \n2        5517 Charles de Gaulle Champs Libres    0.00000797\n3        5520 Pont de Nantes    Cité Judiciaire  0.00000760\n\n\n\ndb_etat |&gt;\n  mutate(distance = (latitude - ma_latitude)^2 + (longitude - ma_longitude)^2) |&gt;\n  arrange(distance) |&gt;\n  select(Nom, distance, `Emplacements disponibles`) |&gt;\n  head(3) |&gt;\n  collect()\n\n# A tibble: 3 × 3\n  Nom                    distance `Emplacements disponibles`\n  &lt;chr&gt;                     &lt;dbl&gt;                      &lt;dbl&gt;\n1 Berger               0.00000754                          3\n2 Villejean-Université 0.0000120                          14\n3 Marbeuf              0.0000386                          11\n\n\nViualiser les 3 stations de la question 5 sur une carte mapview.\n\nOn créé tout d’abors un objet sf avec les informations nécessaires :\n\n\nstations &lt;- \n  db_etat |&gt;\n      mutate(distance = (latitude - ma_latitude)^2 + (longitude - ma_longitude)^2) |&gt;\n      arrange(distance) |&gt;\n      select(Nom, distance, `Emplacements disponibles`) |&gt;\n      head(3) |&gt;\n      collect()\n\nstations1 &lt;- stations |&gt; \n  inner_join(collect(db_etat),by=join_by(Nom==Nom)) |&gt; \n  rename(Dispo=`Emplacements disponibles.x`) |&gt; \n  select(Nom,Dispo,longitude,latitude)\n\nlibrary(sf)\nsta_geom &lt;- stations1 |&gt; \n  select(longitude,latitude) |&gt; \n  as.matrix() |&gt; \n  st_multipoint() |&gt; \n  st_geometry() |&gt; \n  st_cast(to=\"POINT\") |&gt; \n  st_sfc(crs=4326)\nst_geometry(stations1) &lt;- sta_geom\nstations1\n\nSimple feature collection with 3 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -1.705097 ymin: 48.11175 xmax: -1.702077 ymax: 48.12107\nGeodetic CRS:  WGS 84\n# A tibble: 3 × 5\n  Nom                  Dispo longitude latitude             geometry\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;          &lt;POINT [°]&gt;\n1 Berger                   3     -1.71     48.1 (-1.705097 48.11631)\n2 Villejean-Université    14     -1.70     48.1  (-1.70428 48.12107)\n3 Marbeuf                 11     -1.70     48.1 (-1.702077 48.11175)\n\n\n\nOn construit la carte\n\n\nmapview::mapview(stations1,\n                 cex=\"Dispo\",\n                 popup=leafpop::popupTable(stations1,\n                                           zcol=c(\"Nom\",\"Dispo\")),\n                 legend=FALSE)\n\n\n\n\n\n\nTerminer correctement en fermant la connexion à la base de données.\n\ndbDisconnect(con)\n\n\n\n\nExercice 5.2 (Un peu de musique) Sur le site https://github.com/lerocha/chinook-database, nous pouvons trouver des bases de données de bibliothèques musicales. Une copie de la base SQLite est disponible dans le fichier Chinook_Sqlite.sqlite.\n\nSe connecter à la base de données et afficher les tables. Explorer le jeu de données pour le découvrir. En particulier, étudier comment les tables Playlist, PlaylistTrack et Track sont liées.\n\ncon &lt;- dbConnect(RSQLite::SQLite(), dbname = \"data/Chinook_Sqlite.sqlite\")\ndbListTables(con)\n\n [1] \"Album\"         \"Artist\"        \"Customer\"      \"Employee\"     \n [5] \"Genre\"         \"Invoice\"       \"InvoiceLine\"   \"MediaType\"    \n [9] \"Playlist\"      \"PlaylistTrack\" \"Track\"        \n\ndb_playlist &lt;- tbl(con, \"Playlist\")\ndb_playlist |&gt; head(3) |&gt; collect()\n\n# A tibble: 3 × 2\n  PlaylistId Name    \n       &lt;int&gt; &lt;chr&gt;   \n1          1 Music   \n2          2 Movies  \n3          3 TV Shows\n\ndb_playlist_track &lt;- tbl(con, \"PlaylistTrack\")\ndb_playlist_track |&gt; head(3) |&gt; collect()\n\n# A tibble: 3 × 2\n  PlaylistId TrackId\n       &lt;int&gt;   &lt;int&gt;\n1          1    3402\n2          1    3389\n3          1    3390\n\ndb_track &lt;- tbl(con, \"Track\")\ndb_track |&gt; head(3) |&gt; collect()\n\n# A tibble: 3 × 9\n  TrackId Name          AlbumId MediaTypeId GenreId Composer Milliseconds  Bytes\n    &lt;int&gt; &lt;chr&gt;           &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;chr&gt;           &lt;int&gt;  &lt;int&gt;\n1       1 For Those Ab…       1           1       1 Angus Y…       343719 1.12e7\n2       2 Balls to the…       2           2       1 &lt;NA&gt;           342562 5.51e6\n3       3 Fast As a Sh…       3           2       1 F. Balt…       230619 3.99e6\n# ℹ 1 more variable: UnitPrice &lt;dbl&gt;\n\n\nUtiliser les verbes de dplyr pour savoir quelles sont les playlists qui contiennent le plus de pistes.\n\ndb_playlist_track |&gt;\n  group_by(PlaylistId) |&gt;\n  summarise(n = n()) |&gt;\n  left_join(db_playlist, by = \"PlaylistId\") |&gt;\n  arrange(desc(n)) |&gt;\n  collect()\n\n# A tibble: 14 × 3\n   PlaylistId     n Name                      \n        &lt;int&gt; &lt;int&gt; &lt;chr&gt;                     \n 1          1  3290 Music                     \n 2          8  3290 Music                     \n 3          5  1477 90’s Music                \n 4          3   213 TV Shows                  \n 5         10   213 TV Shows                  \n 6         12    75 Classical                 \n 7         11    39 Brazilian Music           \n 8         17    26 Heavy Metal Classic       \n 9         13    25 Classical 101 - Deep Cuts \n10         14    25 Classical 101 - Next Steps\n11         15    25 Classical 101 - The Basics\n12         16    15 Grunge                    \n13          9     1 Music Videos              \n14         18     1 On-The-Go 1               \n\n\nEn utilisant dplyr, construire une table contenant les informations suivantes sur la playlist appelée Classical : le titre de chaque piste ainsi que le titre de l’album dont cette piste est tirée.\n\ndb_album &lt;- tbl(con, \"Album\")\ndb_playlist_track |&gt;\n  left_join(db_playlist, by = \"PlaylistId\") |&gt;\n  rename(PlaylistName = Name) |&gt;\n  filter(PlaylistName == \"Classical\") |&gt;\n  left_join(db_track, by = \"TrackId\") |&gt;\n  left_join(db_album, by = \"AlbumId\") |&gt;\n  select(Name, Title) |&gt;\n  collect()\n\n# A tibble: 75 × 2\n   Name                                                                   Title \n   &lt;chr&gt;                                                                  &lt;chr&gt; \n 1 \"Intoitus: Adorate Deum\"                                               Adora…\n 2 \"Miserere mei, Deus\"                                                   Alleg…\n 3 \"Canon and Gigue in D Major: I. Canon\"                                 Pache…\n 4 \"Concerto No. 1 in E Major, RV 269 \\\"Spring\\\": I. Allegro\"             Vival…\n 5 \"Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\"               Bach:…\n 6 \"Aria Mit 30 Veränderungen, BWV 988 \\\"Goldberg Variations\\\": Aria\"     Bach:…\n 7 \"Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\"          Bach:…\n 8 \"The Messiah: Behold, I Tell You a Mystery... The Trumpet Shall Sound\" Hande…\n 9 \"Solomon HWV 67: The Arrival of the Queen of Sheba\"                    The W…\n10 \"\\\"Eine Kleine Nachtmusik\\\" Serenade In G, K. 525: I. Allegro\"         Sir N…\n# ℹ 65 more rows\n\n\nMême question en écrivant directement la requête en SQL.\n\nquery &lt;- \"\nSELECT Name, Title\nFROM (\n  SELECT Name, AlbumId\n  FROM (\n    SELECT TrackId\n    FROM PlaylistTrack AS left\n    LEFT JOIN Playlist AS right\n    ON (left.PlaylistId = right.PlaylistId)\n    WHERE (Name = 'Classical')\n  ) AS left\n  LEFT JOIN Track AS right\n  ON (left.TrackId = right.TrackId)\n) AS left\nLEFT JOIN Album AS right\nON (left.AlbumId = right.AlbumId)\n\"\ndbGetQuery(con, query) |&gt; head(3)\n\n                                  Name\n1               Intoitus: Adorate Deum\n2                   Miserere mei, Deus\n3 Canon and Gigue in D Major: I. Canon\n                                                      Title\n1 Adorate Deum: Gregorian Chant from the Proper of the Mass\n2                                         Allegri: Miserere\n3                                  Pachelbel: Canon & Gigue\n\n\nTerminer correctement en fermant la connexion à la base de données.\n\ndbDisconnect(con)"
  },
  {
    "objectID": "03-2-bdd.html#json-javascript-object-notation",
    "href": "03-2-bdd.html#json-javascript-object-notation",
    "title": "5  Base de données",
    "section": "5.3 JSON : JavaScript Object Notation",
    "text": "5.3 JSON : JavaScript Object Notation\nIl s’agit d’une alternative aux bases de données relationnelles qui encode les infromations dans des fichiers structurés. Il est très utilisé dans :\n\nles bases de données NoSQL avec MongoDB\nles API WEB\nle monde de l’open data, par exemple sur le site des données publiques de l’état français https://www.data.gouv.fr/fr/.\n\nUn fichier JSON est articulé autour d’une syntaxe simple et d’un petit nombre de type de données. Deux types sont structurés, les autres sont des types simples.\nLes types structurés sont :\n\nles objets, proches des dictionnaires Python ou des listes R. Ils permettent de structurer les données selon un principe clé/valeur et sont codés de la façon suivante :\n\n{\n  \"clé1\": valeur1,\n  \"clé2\": valeur2,\n  ...\n}\n\nles tableaux, proches des listes Python ou des vecteurs R\n\n[\n  valeur1,\n  valeur2,\n  ...\n]\n\n\nLes valeurs peuvent prendre différents types comme des chaînes de caractères, des nombres, des booléens… Par exemple\n\n{\n  \"prénom\": \"Jean-Sébastien\",\n  \"nom\": \"Bach\",\n  \"nombre_enfants\": 20\n  \"compositeur\": true\n}\n\nSur R, la manipulation du format JSON se fait avec le package jsonlite. Il propose notamment les fonctions :\n\nfromJSON pour importer du texte ou des fichier au format JSON ;\ntoJSON pour exporter au format JSON.\n\nPar exemple\n\nlibrary(jsonlite)\ndf &lt;- tibble(x = c(0, pi),y = cos(x))\ntoJSON(df);class(df)\n\n[{\"x\":0,\"y\":1},{\"x\":3.1416,\"y\":-1}] \n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\net\n\ndf |&gt; toJSON() |&gt; fromJSON()\n\n       x  y\n1 0.0000  1\n2 3.1416 -1\n\n\n\nExercice 5.3 (Première commandes)  \n\nOn considère les données suivantes :\nConstruire dans R un tableau au format JSON et le convertir en tibble à l’aide de la fonction fromJSON.\n\n\nfromJSON('[{\"nom\": \"Peter\",\"age\": 24},\n           {\"nom\": \"Marie\",\"age\": 18},\n           {\"nom\": \"Eric\",\"age\": 32}\n         ]')\n\n    nom age\n1 Peter  24\n2 Marie  18\n3  Eric  32\n\n\n\nOn construit l’objet suivant :\n\naa &lt;- fromJSON(\n  '[{\n      \"prénom\": \"Jean-Sébastien\",\n      \"nom\": \"Bach\",\n      \"épouses\": [\n        {\n          \"prénom\": [\"Maria\", \"Barbara\"],\n          \"nom\": \"Bach\"\n        },\n        {\n          \"prénom\": [\"Anna\", \"Magdalena\"],\n          \"nom\": \"Wilcke\"\n        }]\n  }]'\n)\n\nAnalyser cet objet et plus particulièrement la colonne épouses.\n\nOn observe que l’objet suivant est un data-frame avec une ligne et 3 colonnes. Néanmoins l’élement de la troisième colonne est étrange lorsqu’il s’affiche :\n\n\nclass(aa)\n\n[1] \"data.frame\"\n\ndim(aa)\n\n[1] 1 3\n\naa\n\n          prénom  nom                                       épouses\n1 Jean-Sébastien Bach Maria, Barbara, Anna, Magdalena, Bach, Wilcke\n\n\n\nIl s’agit d’une liste qui contient un data-frame :\n\n\nclass(aa[1,3])\n\n[1] \"list\"\n\nclass(aa[1,3][[1]])\n\n[1] \"data.frame\"\n\naa[1,3][[1]]\n\n           prénom    nom\n1  Maria, Barbara   Bach\n2 Anna, Magdalena Wilcke\n\n\n\nOn peut retrouver ces informations avec la fonction glimpse:\n\n\nglimpse(aa)\n\nRows: 1\nColumns: 3\n$ prénom  &lt;chr&gt; \"Jean-Sébastien\"\n$ nom     &lt;chr&gt; \"Bach\"\n$ épouses &lt;list&gt; [&lt;data.frame[2 x 2]&gt;]\n\nglimpse(aa[1,3])\n\nList of 1\n $ :'data.frame':   2 obs. of  2 variables:\n  ..$ prénom:List of 2\n  .. ..$ : chr [1:2] \"Maria\" \"Barbara\"\n  .. ..$ : chr [1:2] \"Anna\" \"Magdalena\"\n  ..$ nom   : chr [1:2] \"Bach\" \"Wilcke\"\n\nglimpse(aa[1,3][[1]])\n\nRows: 2\nColumns: 2\n$ prénom &lt;list&gt; &lt;\"Maria\", \"Barbara\"&gt;, &lt;\"Anna\", \"Magdalena\"&gt;\n$ nom    &lt;chr&gt; \"Bach\", \"Wilcke\"\n\n\n\n\n\nExercice 5.4 (Importation JSON et API)"
  },
  {
    "objectID": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "href": "04-ggplot.html#fonctions-graphiques-conventionnelles",
    "title": "6  Visualisation avec ggplot2",
    "section": "6.1 Fonctions graphiques conventionnelles",
    "text": "6.1 Fonctions graphiques conventionnelles\nPour commencer il est intéressant d’examiner quelques exemples de représentations graphiques construits avec R. On peut les obtenir à l’aide de la fonction demo.\n\ndemo(graphics)\n\n\n6.1.1 La fonction plot\nC’est une fonction générique que l’on peut utiliser pour représenter différents types de données. L’utilisation standard consiste à visualiser une variable y en fonction d’une variable x. On peut par exemple obtenir le graphe de la fonction \\(x\\mapsto \\sin(2\\pi x)\\) sur \\([0,1]\\), à l’aide de\n\nx &lt;- seq(-2*pi,2*pi,by=0.05)\ny &lt;- sin(x)\nplot(x,y) #points (par défaut)\n\n\n\nplot(x,y,type=\"l\") #représentation sous forme de ligne\n\n\n\n\nNous proposons des exemples de représentations de variables quantitatives et qualitatives à travers du jeu de données ozone.txt que l’on importe avec\n\nozone &lt;- read.table(\"data/ozone.txt\")\nsummary(ozone)\n\n     maxO3              T9             T12             T15       \n Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  \n 1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  \n Median : 81.50   Median :17.80   Median :20.55   Median :22.05  \n Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  \n 3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  \n Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  \n      Ne9             Ne12            Ne15           Vx9         \n Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  \n 1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  \n Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  \n Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  \n 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  \n Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  \n      Vx12             Vx15            maxO3v           vent          \n Min.   :-7.878   Min.   :-9.000   Min.   : 42.00   Length:112        \n 1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00   Class :character  \n Median :-1.879   Median :-1.550   Median : 82.50   Mode  :character  \n Mean   :-1.611   Mean   :-1.691   Mean   : 90.57                     \n 3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00                     \n Max.   : 6.578   Max.   : 5.000   Max.   :166.00                     \n    pluie          \n Length:112        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nOn visualise tout d’abord 2 variables quantitatives à l’aide d’un nuage de points : la concentration en ozone maximale maxO3 en fonction de la température à 12h T12.\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"])\n\n\n\n\nComme les deux variables appartiennent au même jeu de données, on peut obtenir la même représentation à l’aide d’une sytaxe plus claire qui ajoute automatiquement les noms des variables sur les axes :\n\nplot(maxO3~T12,data=ozone)\n\n\n\n\nUne autre façon de faire (moins naturelle) :\n\nplot(ozone[,\"T12\"],ozone[,\"maxO3\"],xlab=\"T12\",ylab=\"maxO3\")\n\n\n\n\nIl existe des fonctions spécifiques pour chaque type de graphes, par exemple histogram, barplot et boxplot :\n\nhist(ozone$maxO3,main=\"Histogram\")\n\n\n\nbarplot(table(ozone$vent)/nrow(ozone),col=\"blue\")\n\n\n\nboxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n6.1.2 Graphes interactifs avec rAmCharts\nOn peut utiliser ce package pour obtenir des graphes dynamiques. L’utilisation est relativement simple, il suffit d’ajouter le préfixe am devant le nom de la fonction :\n\nlibrary(rAmCharts)\namHist(ozone$maxO3)\n\n\n\n\namPlot(ozone,col=c(\"T9\",\"T12\"))\n\n\n\n\namBoxplot(maxO3~vent,data=ozone)\n\n\n\n\n\n\n\n6.1.3 Quelques exercices\n\nExercice 6.1 (Premier graphe) On s’intéresse à quelques graphes simples.\n\nTracer la fonction sinus entre \\(0\\) et \\(2\\pi\\).\n\nx &lt;- seq(0,2*pi,length=1000)\nplot(x,sin(x),type=\"l\")\n\n\n\n\nA l’aide de la fonction title ajouter le titre Représentation de la fonction sinus.\n\ntitle(\"Représentation de la fonction sinus\")\n\n\n\n\n\n\n\n\n\nExercice 6.2 (Tracé de densités) On souhaite ici visualiser et comparer des densités de probabilité.\n\nTracer la densité de la loi normale centrée réduite entre \\(-4\\) et 4 (utiliser dnorm).\n\nx &lt;- seq(-4,4,by=0.01)\nplot(x,dnorm(x),type=\"l\")\n\n\n\n\nAjouter une ligne verticale (en tirets) qui passe par \\(x=0\\) (utiliser abline avec l’option lty=2).\n\nabline(v=0,lty=2)\n\n\n\n\n\n\nSur le même graphe, ajouter les densités de loi la de Student à 5 et 30 degrés de liberté (utiliser dt). On utilisera la fonction lines et des couleurs différentes pour chaque densité.\n\nlines(x,dt(x,5),col=2)\nlines(x,dt(x,30),col=3)\n\n\n\n\n\n\nAjouter une légende qui permette d’identifier chaque densité (fonction legend).\n\nlegend(\"topleft\",legend=c(\"Normal\",\"Student(5)\",\"Student(30)\"),\n   col=1:3,lty=1)\n\n\n\n\n\n\n\n\n\nExercice 6.3 (Tâches solaires) On souhaite ici visualiser une série temporelle.\n\nImporter la série taches_solaires.csv qui donne, date par date, un nombre de taches solaires observées.\n\ntaches &lt;- read.table(\"data/taches_solaires.csv\",sep=\";\",header=TRUE,dec=\",\")\n\nA l’aide de la fonction cut_interval du package ggplot2, créer un facteur qui sépare l’intervalle d’années d’observation en 8 intervalles de tailles à peu près égales. On appellera periode ce facteur.\n\nperiode &lt;- ggplot2::cut_interval(taches$annee,n=8)\n\nUtiliser les levels suivants pour le facteur periode.\n\ncouleurs &lt;- c(\"yellow\", \"magenta\", \"orange\", \"cyan\",\n          \"grey\", \"red\", \"green\", \"blue\")\n\n\nlevels(periode) &lt;- couleurs\n\nExpliquer la sortie de la fonction\n\ncoordx &lt;- seq(along=taches[,1])\n\n\nOn crée une séquence avec un pas de 1 de longueur égale à la dimension de taches[,1].\n\nVisualiser la série du nombre de taches en utilisant une couleur différente pour chaque période.\n\nplot(coordx,taches[,1],xlab=\"Temps\",ylab=\"Nombre de taches\",\n col=periode,type=\"p\",pch=\"+\")\n\n\n\n\n\n\n\nExercice 6.4 (Layout) On reprend le jeu de données sur l’ozone. A l’aide de la fonction layout séparer la fenêtre graphique en deux lignes avec\n\nun graphe sur la première ligne (nuage de points maxO3 vs T12)\n2 graphes sur la deuxième ligne (histogramme de T12 et boxplot de maxO3).\n\nlayout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))\nplot(maxO3~T12,data=ozone)\nhist(ozone$T12)\nboxplot(ozone$maxO3)"
  },
  {
    "objectID": "04-ggplot.html#la-grammaire-ggplot2",
    "href": "04-ggplot.html#la-grammaire-ggplot2",
    "title": "6  Visualisation avec ggplot2",
    "section": "6.2 La grammaire ggplot2",
    "text": "6.2 La grammaire ggplot2\nCe package propose de définir des graphes sur R en utilisant une grammaire des graphiques (tout comme dplyr pour manipuler les données). On peut trouver de la documentation sur ce package aux url https://ggplot2.tidyverse.org et https://ggplot2-book.org/index.html\n\n6.2.1 Premiers graphes ggplot2\nNous considérons un sous échantillon du jeu de données diamonds du package ggplot2 (que l’on peut également charger avec le package tidyverse).\n\nlibrary(tidyverse)\nset.seed(1234)\ndiamonds2 &lt;- diamonds[sample(nrow(diamonds),5000),] \nsummary(diamonds2)\n\n     carat               cut       color       clarity         depth      \n Min.   :0.2000   Fair     : 158   D: 640   SI1    :1189   Min.   :43.00  \n 1st Qu.:0.4000   Good     : 455   E: 916   VS2    :1157   1st Qu.:61.10  \n Median :0.7000   Very Good:1094   F: 900   SI2    : 876   Median :61.80  \n Mean   :0.7969   Premium  :1280   G:1018   VS1    : 738   Mean   :61.76  \n 3rd Qu.:1.0400   Ideal    :2013   H: 775   VVS2   : 470   3rd Qu.:62.50  \n Max.   :4.1300                    I: 481   VVS1   : 326   Max.   :71.60  \n                                   J: 270   (Other): 244                  \n     table           price             x                y        \n Min.   :49.00   Min.   :  365   Min.   : 0.000   Min.   :3.720  \n 1st Qu.:56.00   1st Qu.:  945   1st Qu.: 4.720   1st Qu.:4.720  \n Median :57.00   Median : 2376   Median : 5.690   Median :5.700  \n Mean   :57.43   Mean   : 3917   Mean   : 5.728   Mean   :5.731  \n 3rd Qu.:59.00   3rd Qu.: 5294   3rd Qu.: 6.530   3rd Qu.:6.520  \n Max.   :95.00   Max.   :18757   Max.   :10.000   Max.   :9.850  \n                                                                 \n       z        \n Min.   :0.000  \n 1st Qu.:2.920  \n Median :3.520  \n Mean   :3.538  \n 3rd Qu.:4.030  \n Max.   :6.430  \n                \n\nhelp(diamonds)\n\nUn graphe ggplot est défini à partir de couches que l’on assemblera avec l’opérateur +. Il faut a minima spécifier :\n\nles données\nles variables que l’on souhaite représenter\nle type de représentation (nuage de points, boxplot…).\n\nIl existe un verbe pour définir chacune de ces couches :\n\nggplot pour les données\naes (aesthetics) pour les variables\ngeom_ pour le type de représentation.\n\nOn peut obtenir le nuage de points carat vs price avec la fonction plot :\n\nplot(price~carat,data=diamonds2)\n\n\n\n\nAvec ggplot, on va faire\n\nggplot(diamonds2) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price) #rien\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point() #bon\n\n\n\n\n\nExercice 6.5 (Premiers graphes ggplot) \n\n\nTracer l’histogramme de la variable carat (utiliser geom_histogram).\n\nggplot(diamonds2)+aes(x=carat)+geom_histogram()\n\n\n\n\nMême question en utilisant 10 classes pour l’histogramme (help(geom_histogram)).\n\nggplot(diamonds2)+aes(x=carat)+geom_histogram(bins=10)\n\n\n\n\nTracer le diagramme en barres de la variable cut (utiliser geom_bar).\n\nggplot(diamonds2)+aes(x=cut)+geom_bar()\n\n\n\n\n\n\nLa syntaxe ggplot est définie à partir d’éléments indépendants qui définissent la grammaire de ggplot. Les principaux verbes sont :\n\nData (ggplot) : les données au format dataframe ou tibble\nAesthetics (aes) : pour sépecifier les variables à représenter dans le graphe.\nGeometrics (geom_...) : le type de graphe (nuage de points, histogramme…).\nStatistics (stat_...) : utile pour spécifier des transformations des données nécessaires pour obtenir le graphe.\nScales (scale_...) : pour controler les paramètres permettant d’affiner le graphe (changement de couleurs, paramètres des axes…).\n\nTous ces éléments sont reliés avec le symbole +.\n\n\n6.2.2 Data et aesthetics\nCes deux verbes sont à utiliser pour tous les graphes ggplot. Le verbe ggplot sert à spécifier le jeu de données que l’on souhaite utiliser. Si le code est bien fait, nous n’aurons plus à utiliser le nom du jeu de données par la suite pour construire le graphe. Le verbe aes est quant à lui utile pour spécifier les variables que l’on souhaite visualiser. Par exemple, pour le nuage de points price vs carat la syntaxe débute avec\n\nggplot(diamonds2)+aes(x=carat,y=price)\n\nLes variables peuvent également être utilisées pour colorier des points ou des barres, définir des tailles… Dans ce cas on pourra renseigner les options color, size, fill dans la fonction aes. Par exemple\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)\n\n\n\n6.2.3 Geometrics\nCe verbe décrira le type de représentation souhaité. Pour un nuage de points, on utilisera par exemple geom_point :\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\n\n\n\n\nOn observe que ggplot ajoute la légende automatiquement. Voici les principaux exemples de geometrics :\n\n\nTable 6.1: Principaux geometrics\n\n\n\n\n\n\n\nGeom\nDescription\nAesthetics\n\n\n\n\ngeom_point()\nnuage de points\nx, y, shape, fill\n\n\ngeom_line()\nLigne (ordonnée selon x)\nx, y, linetype\n\n\ngeom_abline()\nLigne\nslope, intercept\n\n\ngeom_path()\nLigne (ordonnée par l’index)\nx, y, linetype\n\n\ngeom_text()\nTexte\nx, y, label, hjust, vjust\n\n\ngeom_rect()\nRectangle\nxmin, xmax, ymin, ymax, fill, linetype\n\n\ngeom_polygon()\nPolygone\nx, y, fill, linetype\n\n\ngeom_segment()\nSegment\nx, y, xend, yend, fill, linetype\n\n\ngeom_bar()\nDiagramme en barres\nx, fill, linetype, weight\n\n\ngeom_histogram()\nHistogramme\nx, fill, linetype, weight\n\n\ngeom_boxplot()\nBoxplot\nx, fill, weight\n\n\ngeom_density()\nDensité\nx, y, fill, linetype\n\n\ngeom_contour()\nLignes de contour\nx, y, fill, linetype\n\n\ngeom_smooth()\nLisseur (linéaire ou non linéaire)\nx, y, fill, linetype\n\n\nTous\n\ncolor, size, group\n\n\n\n\n\nExercice 6.6 (Diagrammes en barres) On étudie différentes façons de changer la couleur dans un diagramme en barres.\n\nTracer le diagramme en barres de la variable cut avec des barres bleues.\n\nggplot(diamonds2)+aes(x=cut)+geom_bar(fill=\"blue\")\n\n\n\n\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité de cut ainsi qu’une légende qui permet de repérer la couleur.\n\nggplot(diamonds2)+aes(x=cut,fill=cut)+geom_bar()\n\n\n\n\nTracer le diagramme en barres de la variable cut avec une couleur pour chaque modalité que vous choisirez (et sans légende).\n\nOn peut ajouter l’option show.legend = FALSE dans geom_bar :\n\n\nggplot(diamonds2)+aes(x=cut,fill=cut)+geom_bar(show.legend = FALSE)\n\n\n\n\n\nou spécifier directement les couleurs (toujours dans geom_bar) :\n\n\nggplot(diamonds2)+aes(x=cut)+geom_bar(fill=c(\"blue\",\"red\",\"green\",\"yellow\",\"black\"))\n\n\n\n\n\n\n\n\n6.2.4 Statistics\nCertains graphes nécessitent des calculs d’indicateurs statistiques pour être tracé. C’est par exemple le cas pour le diagramme en barres et l’histogramme où il faut calculer des hauteurs de rectangles ou barres. On peut spécifier les transformations simples facilement, par exemple\n\nD &lt;- data.frame(X=seq(-2*pi,2*pi,by=0.01))\nggplot(D)+aes(x=X,y=sin(X))+geom_line()\n\n\n\n\nLa transformation est spécifiée dans la fonction aes. Pour des transformations plus complexes, nous devons utiliser le verbe statistics. Une fonction stat_ permet de définir des nouvelles variables à partir du jeu de données initial, il est ensuite possible de représenter ces nouvelles variables. Par exemple, la fonction stat_bin, qui est utilisée par défaut pour construire des histogrammes, calcule les variables suivantes :\n\ncount, le nombre d’observations dans chaque classes.\ndensity, la valeur de la densité des observations dans chaque classe (fréqunce divisée par largeur de la classe).\nx, le centre de la classe.\n\nPar défaut geom_histogram fait appel à cette fonction stat_bin grâce à l’option stat=\"bin\". On visualise ainsi sur l’axe \\(y\\) le nombre d’observations dans chaque classe (la variable count).\n\nggplot(diamonds2)+aes(x=price)+geom_histogram(bins=40)\n\n\n\n\nSi on souhaite une autre variable issue de stat_bin, comme par exemple la densité, il faudra utiliser\n\nggplot(diamonds2)+aes(x=price,y=..density..)+geom_histogram(bins=40)\n\n\n\n\nLes fonctions stat_ peuvent être utilisées à la place des geom_ pour certaines représentations. Chaque fonction stat_ possède par défaut un geom_ et réciproquement. On peut par exemple obtenir le même graphe que précédemment avec\n\nggplot(diamonds2)+aes(x=price,y=..density..)+stat_bin()\n\nVoici quelques exemple de fonctions stat_\n\n\nTable 6.2: Exemple de statistics\n\n\nStat\nDescription\nParamètres\n\n\n\n\nstat_identity()\naucune transformation\n\n\n\nstat_bin()\nCount\nbinwidth, origin\n\n\nstat_density()\nDensity\nadjust, kernel\n\n\nstat_smooth()\nSmoother\nmethod, se\n\n\nstat_boxplot()\nBoxplot\ncoef\n\n\n\n\nstat et geom ne sont pas toujours simples à combiner. Nous recommandons d’utiliser geom lorsqu’on débute avec ggplot, les statisticspar défaut ne doivent en effet être changés que rarement.\n\nExercice 6.7 (Diagramme en barres “très simple”…) On considère une variable qualitative \\(X\\) dont la loi est donnée par \\[P(X=\\text{red})=0.3,\\ P(X=\\text{blue})=0.2,\\ P(X=\\text{green})=0.4,\\ P(X=\\text{black})=0.1\\] Représenter cette distribution de probabilité avec un diagramme en barres.\n\nLa difficulté ici vient du fait que les hauteurs de barre sont données : il ne faut pas les calculer à partir des données. On n’a donc pas à utiliser stat_count de geom_bar, if faut faire appel à stat_identity:\n\n\ndf &lt;- data.frame(var=c(\"red\",\"blue\",\"green\",\"black\"),prob=c(0.3,0.2,0.4,0.1))\nggplot(df)+aes(x=var,y=prob)+geom_bar(stat=\"identity\")+xlab(\"\")\n\n\n\n\n\nOn peut aussi utiliser l’aes weight :\n\n\nggplot(df)+aes(x=var,weight=prob)+geom_bar()+ylab(\"prob\")\n\n\n\n\n\n\nExercice 6.8 (Lissage) On étudie différentes façons de visualiser un lissage.\n\nReprésenter le lissage non linéaire de la variable price contre la variable carat à l’aide de geom_smooth puis de stat_smooth.\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_smooth(method=\"loess\")\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+stat_smooth(method=\"loess\")\n\n\n\n\nMême question mais avec une ligne en pointillés à la place d’un trait plein.\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_smooth(method=\"loess\",linetype=\"dotted\")\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+stat_smooth(method=\"loess\",geom=\"point\")\n\n\n\n\n\n\n\n\n6.2.5 Scales\nLes échelles (scales) controlent tout un tas d’options telles que des changements de couleurs, d’échelles ou de limites d’axes, de symboles, etc… L’utilisation n’est pas simple et nécessite de la pratique. On utilise généralement ce verbe à la dernière étape de construction du graphe. La syntaxe est définie comme suit :\n\ndébut : scale_.\najout de l’aesthetics que l’on souhaite modifier (color_, fill_, x_).\nfin : nom de l’échelle (manual, identity…)\n\nPar exemple,\n\nggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()+\n  scale_color_manual(values=c(\"Fair\"=\"black\",\"Good\"=\"yellow\",\n                              \"Very Good\"=\"blue\",\"Premium\"=\"red\",\"Ideal\"=\"green\"))\n\n\n\n\nVoici quelques exemples des principales échelles :\n\n\nTable 6.3: Exemples d’échelles\n\n\naes\nDiscret\nContinu\n\n\n\n\nCouleur (color et fill)\nbrewer\ngradient\n\n\n-\ngrey\ngradient2\n\n\n-\nhue\ngradientn\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nPosition (x et y)\ndiscrete\ncontinous\n\n\n-\n\ndate\n\n\nForme\nshape\n\n\n\n-\nidentity\n\n\n\n-\nmanual\n\n\n\nTaille\nidentity\nsize\n\n\n-\nmanual\n\n\n\n\n\nNous présentons quelques exemples d’utilisation des échelles :\n\nCouleur dans un diagramme en barres\n\np1 &lt;- ggplot(diamonds2)+aes(x=cut)+geom_bar(aes(fill=cut))\np1\n\n\n\n\nOn change la couleur en utilisant la palette Purples :\n\np1+scale_fill_brewer(palette=\"Purples\")\n\n\n\n\nGradient de couleurs pour un nuage de points :\n\np2 &lt;- ggplot(diamonds2)+aes(x=carat,y=price)+geom_point(aes(color=depth))\np2\n\n\n\n\nOn change le gradient de couleur\n\np2+scale_color_gradient(low=\"red\",high=\"yellow\")\n\n\n\n\nModifications sur les axes\n\np2+scale_x_continuous(breaks=seq(0.5,3,by=0.5))+\n  scale_y_continuous(name=\"prix\")+\n  scale_color_gradient(\"Profondeur\")\n\n\n\n\n\n\n\n6.2.6 Group et facets\nggplot permet de faire des représentations pour des groupes d’individus. On procède généralement de deux façons différentes :\n\nvisualisation de sous groupes sur le même graphe, on utilise l’option group dans le verbe aes ;\nvisualisation de sous groupes sur des graphes différents, on utilise le verbe facet_wrap ou facet_grid.\n\nReprésentons ici (sur le même graphe) le lisseur price vs carat pour chaque modalité de cut\n\nggplot(diamonds2)+aes(x=carat,y=price,group=cut)+\n  geom_smooth(method=\"loess\")\n\n\n\n\nPour obtenir cette représentation sur plusieurs fenêtres, on utilise\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+\n  geom_smooth(method=\"loess\")+facet_wrap(~cut,nrow=1)\n\n\n\n\nfacet_grid et facet_wrap font des choses proches mais divisent la fenêtre d’une façon différente :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_grid(color~cut)\n\n\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()+\n  geom_smooth(method=\"lm\")+facet_wrap(color~cut)"
  },
  {
    "objectID": "04-ggplot.html#compléments",
    "href": "04-ggplot.html#compléments",
    "title": "6  Visualisation avec ggplot2",
    "section": "6.3 Compléments",
    "text": "6.3 Compléments\nLa syntaxe ggplot est définie selon le schéma :\n\nggplot()+aes()+geom_()+scale_()\n\nElle est très flexible, on peut par exemple spécifier les variables de aes dans les verbes ggplot ou geom_ :\n\nggplot(diamonds2)+aes(x=carat,y=price)+geom_point()\n\n\n\nggplot(diamonds2,aes(x=carat,y=price))+geom_point()\n\n\n\nggplot(diamonds2)+geom_point(aes(x=carat,y=price))\n\n\n\n\nCeci peut se révéler très utile lorsqu’on utilise des aes différents dans les geom_.\nOn peut aussi construire un graphe à l’aide de différents jeux de données :\n\nX &lt;- seq(-2*pi,2*pi,by=0.001)\nY1 &lt;- cos(X)\nY2 &lt;- sin(X)\ndonnees1 &lt;- data.frame(X,Y1)\ndonnees2 &lt;- data.frame(X,Y2)\nggplot(donnees1)+geom_line(aes(x=X,y=Y1))+\n  geom_line(data=donnees2,aes(x=X,y=Y2),color=\"red\")\n\n\n\n\nIl existe d’autres fonctions ggplot :\n\nggtitle pour ajouter un titre.\nggsave pour sauver un graphe.\ntheme_ pour changer le theme du graphe.\n\n\np &lt;- ggplot(diamonds2)+aes(x=carat,y=price,color=cut)+geom_point()\np+theme_bw()\n\n\n\np+theme_classic()\n\n\n\np+theme_grey()\n\n\n\np+theme_bw()\n\n\n\n\nD’autres thèmes sont disponibles dans le package ggtheme. On pourra également parler de la fonction set_theme qui permet de modifier le thème par défaut pour un document quarto."
  },
  {
    "objectID": "04-ggplot.html#quelques-exercices-supplémentaires",
    "href": "04-ggplot.html#quelques-exercices-supplémentaires",
    "title": "6  Visualisation avec ggplot2",
    "section": "6.4 Quelques exercices supplémentaires",
    "text": "6.4 Quelques exercices supplémentaires\n\nExercice 6.9 (Fonctions cosinus et sinus) L’objectif est de visualiser les fonctions sinus et cosinus de plusieurs façons.\n\nTracer les fonctions sinus et cosinus. On utilisera tout d’abord les deux jeux de données suivants (un pour le sinus, l’autre pour le cosinus) :\n\ndonnees1 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X))\ndonnees2 &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   sin=sin(X))\n\n\nggplot(donnees1)+geom_line(aes(x=X,y=cos))+\n  geom_line(data=donnees2,aes(x=X,y=sin),color=\"red\")\n\n\n\n\nFaire la même chose avec le jeu de données suivent qui regroupe les informations du cosinus et du sinus (on pourra ajouter une légende) :\n\ndonnees &lt;- tibble(X=seq(-2*pi,2*pi,by=0.001),\n                   cos=cos(X),sin=sin(X))\n\n\nggplot(donnees)+aes(x=X,y=cos)+geom_line()+\n  geom_line(aes(y=sin),color=\"red\")\n\n\n\n#ou pour la légende\nggplot(donnees)+aes(x=X,y=cos)+geom_line(aes(color=\"cos\"))+\n  geom_line(aes(y=sin,color=\"sin\"))+labs(color=\"Fonction\")\n\n\n\n\nFaire la même chose avec un jeu de données et un seul appel à geom_line. On pourra utiliser la fonction pivot_longer du tidyverse.\n\ndf1 &lt;- donnees |&gt; \n  pivot_longer(cols=c(cos,sin),\n               names_to = \"Fonction\",\n               values_to = \"value\")\n#ou\ndf1 &lt;- donnees |&gt; \n  pivot_longer(cols=-X,\n               names_to = \"Fonction\",\n               values_to = \"value\")\nggplot(df1)+aes(x=X,y=value,color=Fonction)+geom_line()\n\n\n\n# on peut aussi ne pas créer de tibble intermédiaire\ndonnees |&gt; \n  pivot_longer(cols=-X,\n               names_to = \"Fonction\",\n               values_to = \"value\") |&gt; \n  ggplot()+aes(x=X,y=value,color=Fonction)+geom_line()\n\n\n\n\nTracer les deux fonctions sur deux fenêtres graphiques (utiliser facet_wrap).\n\nggplot(df1)+aes(x=X,y=value)+geom_line()+facet_wrap(~Fonction)\n\n\n\n\nFaire la même chose avec la fonction grid.arrange du package gridExtra.\n\nlibrary(gridExtra)\np1 &lt;- ggplot(donnees1)+aes(x=X,y=cos)+geom_line()\np2 &lt;- ggplot(donnees2)+aes(x=X,y=sin)+geom_line()\ngrid.arrange(p1,p2,nrow=1)\n\n\n\n\n\n\n\nExercice 6.10 (Différents graphes) On considère les données mtcars\n\ndata(mtcars)\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\nTracer l’histogramme de mpg (on fera varier le nombre de classes).\n\nggplot(mtcars)+aes(x=mpg)+geom_histogram()\n\n\n\nggplot(mtcars)+aes(x=mpg)+geom_histogram(bins=10)\n\n\n\n\nTracer l’histogramme de la densité.\n\nggplot(mtcars)+aes(x=mpg,y=..density..)+geom_histogram(bins=10)\n\n\n\n\nTracer le diagramme en barres de cyl.\n\nggplot(mtcars)+aes(x=cyl)+geom_bar()\n\n\n\n\nTracer le nuage de points disp vs mpg en utilisant une couleur différente pour chaque valeur de cyl.\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=cyl)+geom_point()\n\n\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=as.factor(cyl))+\n  geom_point()+labs(color=\"cyl\")\n\n\n\n\nAjouter le lisseur linéaire sur le graphe (un lisseur par modalité de cyl).\n\nggplot(mtcars)+aes(x=disp,y=mpg,color=as.factor(cyl))+geom_point()+\n  geom_smooth(method=\"lm\")+labs(color=\"cyl\")\n\n\n\n\n\n\n\nExercice 6.11 (Résidus pour régression simple) On souhaite visualiser les résidus dans un modèle de régression simple.\n\nGénérer un échantillon \\((x_i,y_i),i=1,\\dots,100\\) selon le modèle linéaire \\[y_i=3+x_i+\\varepsilon_i\\] où les \\(x_i\\) sont i.i.d. de loi uniforme sur \\([0,1]\\) et les \\(\\varepsilon_i\\) sont i.i.d. de loi gaussienne \\(N(0,0.2^2)\\) (utiliser runif et rnorm).\n\nn &lt;- 100\nX &lt;- runif(n)\neps &lt;- rnorm(n,sd=0.2)\nY &lt;- 3+X+eps\nD &lt;- data.frame(X,Y)\n\nTracer le nuage de points Y vs X et ajouter le lisseur linéaire.\n\nOn le fait d’abord “à la main” en calculant l’équation de la droite de régression.\n\n\nmodel &lt;- lm(Y~.,data=D)\nco &lt;- coef(model)\nD$fit &lt;- predict(model)\nco &lt;- coef(lm(Y~.,data=D))\nggplot(D)+aes(x=X,y=Y)+geom_point()+\n  geom_abline(slope=co[2],intercept=co[1],color=\"blue\")\n\n\n\n\n\nOn peut avoir le tracé directement avec geom_smooth.\n\n\nggplot(D)+aes(x=X,y=Y)+geom_point()+geom_smooth(method=\"lm\")\n\n\n\n\nReprésenter les résidus : on ajoutera une ligne verticale entre chaque point et la droite de lissage (utiliser geom_segment).\n\nggplot(D)+aes(x=X,y=Y)+geom_point()+geom_smooth(method=\"lm\")+\n  geom_segment(aes(xend=X,yend=fit))\n\n\n\n\n\n\n\nExercice 6.12 (Challenge) On considère les données diamonds.\n\nTracer les graphes suivants.\n\n\n\n\n\n\n\n\n\n\n\n\nOn obtient les graphes demandés avec :\n\n\nggplot(data=diamonds) + geom_boxplot(aes(x=cut,y=carat,fill=cut)) \nggplot(data=diamonds) + geom_boxplot(aes(x=carat,y=cut,fill=cut))\nggplot(data=diamonds) + geom_density(aes(x=carat,y=..density..)) +\n  facet_grid(cut~.)\n\nAjouter sur le troisième graphe les quartiles de la variable carat pour chaque valeur de cut. On utilisera une ligne verticale.\n\nQ1 &lt;- diamonds |&gt; group_by(cut) |&gt; \n  summarize(q1=quantile(carat,c(0.25)),q2=quantile(carat,c(0.5)),\n        q3=quantile(carat,c(0.75)))\nquantildf &lt;- Q1 |&gt; pivot_longer(-cut,names_to=\"alpha\",values_to=\"quantiles\")\nggplot(data=diamonds) + geom_density(aes(x=carat,y=..density..)) +\n  facet_grid(cut~.) +\n  geom_vline(data=quantildf,aes(xintercept=quantiles),col=alpha(\"black\",1/2))\n\n\n\n\n\nOn peut aussi l’obtenir avec stat_boxplot sans calculer explicitement les quartiles :\n\n\nggplot(data=diamonds) + aes(x=carat)+ \n  geom_density() +\n  stat_boxplot(aes(xintercept=c(..xlower..,..xmiddle..,\n                                ..xupper..)),geom=\"vline\") + \n  facet_grid(cut~.) \n\n\n\n\n\nou encore avec stat_summary :\n\n\ndiamonds |&gt; ggplot(aes(x=carat)) +\n  geom_density() +\n  stat_summary(mapping=aes(y=1,xintercept=after_stat(x)),fun=\"quantile\",\n               fun.args = list(prob=c(0.25,0.5,0.75)),\n               geom=\"vline\",orientation=\"y\") + \n  facet_grid(cut~.) \n\n\n\n\nEn déduire le graphe suivant.\n\n\n\n\n\n\nOn l’obtient avec\n\n\nggplot(data=diamonds) +\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density(aes(x=carat,y=..density..)) +  facet_grid(cut~.) +\n  geom_vline(data=quantildf,aes(xintercept=quantiles),col=alpha(\"black\",1/2)) +\n  ylab(\"\")\n\n\nou encore\n\n\nggplot(data=diamonds) + aes(x=carat)+\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density() +\n  stat_boxplot(aes(xintercept=c(..xlower..,..xmiddle..,\n                            ..xupper..)),geom=\"vline\") + \n  facet_grid(cut~.)+ylab(\"\")\n\n\n\n\n\nou encore avec stat_summary :\n\n\ndiamonds |&gt; ggplot(aes(x=carat)) +\n  geom_boxplot(data=diamonds,aes(y=-0.5,x=carat,fill=cut)) +\n  geom_density() +\n  stat_summary(mapping=aes(y=1,xintercept=after_stat(x)),fun=\"quantile\",\n               fun.args = list(prob=c(0.25,0.5,0.75)),\n               geom=\"vline\",orientation=\"y\") + \n  facet_grid(cut~.) + ylab(\"\")"
  },
  {
    "objectID": "05-carto.html#cartes-avec-ggplot2",
    "href": "05-carto.html#cartes-avec-ggplot2",
    "title": "7  Faire des cartes avec R",
    "section": "7.1 Cartes avec ggplot2",
    "text": "7.1 Cartes avec ggplot2\nNous montrons dans cette section comment récupérer des fonds de carte et ajouter quelques informations à l’aide de ggmap. Pour plus de détails sur ce package, on pourra consulter cet article pour plus de détails.\nLa fonction map_data permet de récupérer les géolocalisations pour des fonds de carte à partir de ceux présent dans le package maps. Par exemple :\n\nlibrary(tidyverse)\nus &lt;- map_data(\"state\")\nhead(us)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nOn peut alors visualiser le fond avec geom_polygon :\n\nggplot(us)+aes(x=long,y=lat,group=group)+\n  geom_polygon(fill=\"white\",color=\"black\")+coord_quickmap()\n\n\n\n\nPour le monde on peut procéder ainsi\n\nworld &lt;- map_data(\"world\")\nggplot(world)+aes(x=long,y=lat,group=group)+\n  geom_polygon(fill=\"white\",color=\"black\")+coord_quickmap()\n\n\n\n\nPour la France :\n\nfrance &lt;- map_data(\"france\")\nggplot(france)+aes(x=long,y=lat,group=group)+\n  geom_polygon(fill=\"white\",color=\"black\")+coord_quickmap()\n\n\n\n\nLa fonction geocode de tiygecoder permet de récupérer des latitudes et longitudes à partir d’adresses :\n\ntbl &lt;- tibble(address=c(\"the white house\",\"Paris\",\"Rennes\"))\nlibrary(tidygeocoder)\ntbl |&gt; geocode(address)\n\n# A tibble: 3 × 3\n  address           lat   long\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;\n1 the white house  38.9 -77.0 \n2 Paris            48.9   2.35\n3 Rennes           48.1  -1.68\n\n\n\nExercice 7.1 (Populations des grandes villes de france) \n\n\nRécupérer les latitudes et longitudes de Paris, Lyon et Marseille et représenter ces 3 villes sur une carte de la France.\n\nV &lt;- tibble(ville=c(\"Paris\",\"Lyon\",\"Marseille\")) |&gt; \n  geocode(ville)\nggplot(france)+\n  geom_polygon(aes(x=long,y=lat,group=group),fill=\"white\",color=\"black\")+\n  geom_point(data=V,aes(x=long,y=lat),color=\"red\",size=3)+\n  coord_quickmap()\n\n\n\n\nLe fichier villes_fr.csv contient les populations des 30 plus grandes villes de France. Représenter à l’aide d’un point les 30 plus grandes villes de France. On fera varier la taille du point en fonction de la population en 2014.\n\ndf &lt;- read_csv(\"data/villes_fr.csv\")\n#df$Commune &lt;- as.character(df$Commune)\n\n\nAttention, la ville de Lille n’est pas bien écrite ! Il faut la renommer :\n\n\ndf$Commune[10]    \n\n[1] \"Lille15\"\n\ndf$Commune[10] &lt;- \"Lille\"\n\n\nOn calcule les coordonnées avec geocode et on représente les ville. Pour la taille des points, il suffit d’ajouter size=2014 dans l’aes du geom_point.\n\n\ncoord &lt;- df |&gt; tidygeocoder::geocode(Commune)\nggplot(france)+\n  geom_polygon(aes(x=long,y=lat,group=group),fill=\"white\",color=\"black\")+\n  geom_point(data=coord,aes(x=long,y=lat,size=`2014`),color=\"red\")+\n  coord_quickmap()"
  },
  {
    "objectID": "05-carto.html#cartes-avec-contours-le-format-shapefile",
    "href": "05-carto.html#cartes-avec-contours-le-format-shapefile",
    "title": "7  Faire des cartes avec R",
    "section": "7.2 Cartes avec contours, le format shapefile",
    "text": "7.2 Cartes avec contours, le format shapefile\nmap_data de ggplot2 permet de récupérer facilement des fonds de cartes et de placer des points dessus avec la syntaxe ggplot. Cette approche possède néanmoins plusieurs limites. En premier lieu, elle est dépendante d’une géolocalisation avec des longitudes-latitudes qui n’est pas forcément la plus utilisée dans le monde de la cartographie. De plus, les fonds de carte disponibles dans maps sont limités.\nLes données vectorielles pour les cartes sont souvent encodées avec la norme simple feature. Le package sf développé par (Pebesma 2018) permet de créer des cartes “avancées”, en gérant les contours, les points et les lignes (pour des routes par exemple) à l’aide d’objets particuliers mais aussi en prenant en compte différents systèmes de coordonnées. On pourra trouver de la documentation sur ce package aux url suivantes :\n\nhttps://statnmap.com/fr/2018-07-14-initiation-a-la-cartographie-avec-sf-et-compagnie/\ndans les vignettes sur la page du cran de ce package : https://cran.r-project.org/web/packages/sf/index.html\nou encore ici : https://ggplot2-book.org/maps#sec-sf\n\nCe package propose de définir un nouveau format sf adapté à la cartographie. Regardons par exemple l’objet nc\n\nlibrary(sf)\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"), quiet = TRUE)\nclass(nc)\n\n[1] \"sf\"         \"data.frame\"\n\nnc\n\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\nFirst 10 features:\n    AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n   NWBIR74 BIR79 SID79 NWBIR79                       geometry\n1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\n\nCes données contiennent des informations sur les morts subites de nourissons dans des villes de Caroline du Nord. On remarque que l’objet nc est au format sf et data.frame. On peut donc l’utiliser comme un data.frame classique. Le format sf permet l’ajout d’une colonne particulière (geometry) qui délimitera les villes à l’aide de polygones. Une fois l’objet obtenu au format sf, il est facile de visualiser la carte avec un plot classique\n\nplot(st_geometry(nc))\n\n\n\n\nou en utilisant le verbe geom_sf si on veut faire du ggplot\n\nggplot(nc)+geom_sf()\n\n\n\n\nIl devient dès lors facile de colorier des villes et d’ajouter leurs noms :\n\nggplot(nc[1:3,]) +\n   geom_sf(aes(fill = AREA)) + \n   geom_sf_label(aes(label = NAME))\n\n\n\n\nLa colonne geometry de nc est au format MULTIPOLYGON, elle permettra donc de délimiter les frontières des villes. Si maintenant on souhaite représenter une ville à l’aide d’un point défini par sa latitude et longitude, il va falloir modifier le format de cette colonne geometry. On peut le faire de la manière suivante :\n\nOn récupère les latitudes et longitudes de chaque ville :\n\ncoord.ville.nc &lt;- nc |&gt; tidygeocoder::geocode(NAME)\n\nOn met ces coordonnées au format MULTIPOINT\n\ncoord.ville1.nc &lt;- coord.ville.nc |&gt; select(long,lat) |&gt; \n  filter(long&lt;=-77 & long&gt;=-85 & lat&gt;=33 & lat&lt;=37) |&gt; \n  as.matrix() |&gt; st_multipoint()  |&gt; st_geometry() |&gt; st_cast(to=\"POINT\")\ncoord.ville1.nc\n\nGeometry set for 50 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -83.83378 ymin: 34.27511 xmax: -77.01151 ymax: 36.503\nCRS:           NA\nFirst 5 geometries:\n\n\nPOINT (-81.50766 36.43936)\n\n\nPOINT (-81.13408 36.503)\n\n\nPOINT (-80.70138 36.41356)\n\n\nPOINT (-77.01151 36.35605)\n\n\nPOINT (-80.22881 36.4121)\n\n\nOn indique que ces coordonnées sont des latitudes et longitude et on ajoute la colonne aux données initiales\n\nst_crs(coord.ville1.nc) &lt;- 4326 \n\nOn peut enfin représenter la carte avec les frontières et les points :\n\nggplot(nc)+geom_sf()+geom_sf(data=coord.ville1.nc)\n\n\n\n\n\nLe package sf possède également des fonctions très utiles pour traiter des données cartographiques, on peut citer par exemple :\n\nst_distance qui permet de calculer des distances entre coordonnées ;\nst_centroid pour calculer le centre d’une région ;\n…\n\nOn peut ainsi représenter les centres des villes délimitées par les polygones des données nc avec\n\nnc2 &lt;- nc |&gt; mutate(centre=st_centroid(nc)$geometry)\nggplot(nc2)+geom_sf()+geom_sf(aes(geometry=centre))\n\n\n\n\n\nExercice 7.2 (Première carte avec sf) Nous nous servons de la carte GEOFLAR proposée par l’Institut Géographique National pour récupérer un fond de carte contenant les frontières des départements français. Cette carte est disponible sur le site http: //professionnels.ign.fr/ au format shapefile, elle se trouve dans l’archive dpt.zip. Il faut décompresser pour reproduire la carte. Grâce au package sf, cette carte, contenue dans la série de fichiers département du répertoire dpt, peut être importée dans un objet R :\n\ndpt &lt;- read_sf(\"data/dpt\")\nggplot(dpt) + geom_sf()\n\n\n\n\nRefaire la carte de l’Exercice 7.1 sur ce fond de carte.\n\nOn définit tout d’abord un geometry au format MULTIPOINT. On le transforme ensuite en un “vecteur” de longueur 30 au format POINT que l’on ajoute dans la dataframe qui contient les coordonnées des villes.\n\n\ncoord.ville1 &lt;- coord |&gt; select(long,lat) |&gt; \n  as.matrix() |&gt; st_multipoint() |&gt; st_geometry()\ncoord.ville2 &lt;- st_cast(coord.ville1, to = \"POINT\")\ncoord.ville1\n\nGeometry set for 1 feature \nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -4.486009 ymin: 42.69853 xmax: 7.750713 ymax: 50.63657\nCRS:           NA\n\n\nMULTIPOINT ((2.348391 48.8535), (5.369953 43.29...\n\ncoord.ville2\n\nGeometry set for 30 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -4.486009 ymin: 42.69853 xmax: 7.750713 ymax: 50.63657\nCRS:           NA\nFirst 5 geometries:\n\n\nPOINT (2.348391 48.8535)\n\n\nPOINT (5.369953 43.29617)\n\n\nPOINT (4.832011 45.75781)\n\n\nPOINT (1.444247 43.60446)\n\n\nPOINT (7.268391 43.70094)\n\n\n\nOn peut maintenant visualiser la carte demandée.\n\n\nst_geometry(coord) &lt;- coord.ville2\nst_crs(coord) &lt;- 4326\ncoord\n\nSimple feature collection with 30 features and 15 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -4.486009 ymin: 42.69853 xmax: 7.750713 ymax: 50.63657\nGeodetic CRS:  WGS 84\n# A tibble: 30 × 16\n    Rang Commune    Département Région `1968` `1975` `1982` `1990` `1999` `2006`\n * &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1     1 Paris      Paris       Île-d… 2.59e6 2.30e6 2.18e6 2.15e6 2.13e6 2.18e6\n 2     2 Marseille  Bouches-du… Prove… 8.89e5 9.09e5 8.74e5 8.01e5 7.96e5 8.39e5\n 3     3 Lyon       Métropole … Auver… 5.28e5 4.57e5 4.13e5 4.15e5 4.45e5 4.72e5\n 4     4 Toulouse   Haute-Garo… Occit… 3.71e5 3.74e5 3.48e5 3.59e5 3.90e5 4.38e5\n 5     5 Nice       Alpes-Mari… Prove… 3.22e5 3.44e5 3.37e5 3.42e5 3.43e5 3.47e5\n 6     6 Nantes     Loire-Atla… Pays … 2.60e5 2.57e5 2.41e5 2.45e5 2.70e5 2.83e5\n 7     7 Strasbourg Bas-Rhin    Grand… 2.49e5 2.53e5 2.49e5 2.52e5 2.64e5 2.73e5\n 8     8 Montpelli… Hérault     Occit… 1.62e5 1.91e5 1.97e5 2.08e5 2.25e5 2.52e5\n 9     9 Bordeaux   Gironde     Nouve… 2.67e5 2.23e5 2.08e5 2.10e5 2.15e5 2.32e5\n10    10 Lille      Nord        Hauts… 2.39e5 2.19e5 1.97e5 1.99e5 2.13e5 2.26e5\n# ℹ 20 more rows\n# ℹ 6 more variables: `2011` &lt;dbl&gt;, `2013` &lt;dbl&gt;, `2014` &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   long &lt;dbl&gt;, geometry &lt;POINT [°]&gt;\n\nggplot(dpt)+geom_sf(fill=\"white\")+\n  geom_sf(data=coord,aes(size=`2014`),color=\"red\")+theme_void()\n\n\n\n\n\n\nExercice 7.3 (Visualisation de taux de chômage avec sf) Nous souhaitons visualiser graphiquement les différences de taux de chômage par département entre deux années. Pour cela, nous disposons de chaque taux mesuré aux premiers trimestres des années 2006 et 2011 (variables TCHOMB1T06, TCHOMB1T11) qui se trouvent dans le jeu de données tauxchomage.csv.\n\nImporter le jeu de données.\n\nchomage &lt;- read_delim(\"data/tauxchomage.csv\",delim=\";\")\n\nFaire la jointure de cette table avec celle des frontières des départements. On pourra utiliser inner_join.\n\ndpt &lt;- read_sf(\"data/dpt\")\ndpt2 &lt;- inner_join(dpt,chomage,by=\"CODE_DEPT\")\n\nComparer les taux de chômage en 2006 et 2011 (on le fera avec une carte pour les taux en 2006 et une autre pour les taux en 2011).\n\ndpt3 &lt;- dpt2 |&gt; select(A2006=TCHOMB1T06,A2011=TCHOMB1T11,geometry) |&gt;\n  as_tibble() |&gt; \n  pivot_longer(-geometry,names_to=\"Annee\",values_to=\"TxChomage\") |&gt;\n  st_as_sf()\n\n\nggplot(dpt3) + aes(fill = TxChomage)+geom_sf() +\n  facet_wrap(~Annee, nrow = 1)+\n  scale_fill_gradient(low=\"white\",high=\"brown\")+theme_bw()\n\n\n\n\n\n\n\n7.2.1 Challenge 1 : carte des températures avec sf\nOn souhaite ici faire une carte permettant de visualiser les température en France à un moment donné. Les données se trouvent sur le site des données publiques de meteo france. On peut notamment récupérer\n\nles températures observées dans certaines stations en France les 15 derniers jours dans le lien téléchargement. On utilisera uniquement les identifiants de la station ainsi que la température observée (colonne t).\nla géolocalisation de ces stations dans le lien documentation\n\n\nImporter les 2 bases nécessaires. On pourra les lire directement sur le site. Convertir les degrés Kelvin en degrés Celsius et faire la jointure de ces bases.\n\nOn commence par importer les 2 bases :\n\n\nlien_temp &lt;- str_c(\"https://donneespubliques.meteofrance.fr/donnees_libres/Txt/Synop/synop.\",\n                   str_remove_all(today()-1,\"-\"),\n                   \"15\",\n                   \".csv\")\ndonnees_temp &lt;- read_delim(lien_temp,delim=\";\",\n                           col_select = c(\"numer_sta\",\"t\"),\n                           col_types = cols(t=col_double())) |&gt; \n  rename(temp=t) |&gt; \n  mutate(temp=temp-273.15)\n\ndonnees_sta &lt;- read_delim(\"https://donneespubliques.meteofrance.fr/donnees_libres/Txt/Synop/postesSynop.csv\",\n                          delim=\";\",\n                          col_select = c(\"ID\",\"Latitude\",\"Longitude\"))\ndonnees_temp\ndonnees_sta\n\n\nPuis on fait la jointure :\n\n\nD &lt;- inner_join(donnees_temp,donnees_sta,by=join_by(numer_sta==ID))\n\nÉliminer les station d’outre mer (on pourra conserver uniquement les stations qui ont une longitude entre -20 et 25). On appellera le tableau résultant de cette étape station1. Visualiser les stations sur la carte contenant les frontières des départements français.\n\nstation1 &lt;- D |&gt; filter(Longitude&lt;25 & Longitude&gt;-20) |&gt; drop_na()\nstation4326 &lt;- station1 |&gt; select(Longitude,Latitude) |&gt; \n  as.matrix() |&gt; \n  st_multipoint() |&gt; \n  st_sfc() |&gt; \n  st_set_crs(4326)\nggplot(dpt) + geom_sf()+geom_sf(data=station4326)\n\n\n\n\nCréer un objet de classes tbl et sf qui contient les températures des stations ainsi que leurs coordonnées dans la colonne geometry. On pourra s’inspirer de\n\nstation2 &lt;- station1\nst_geometry(station2) &lt;- ...\n\n\nstation2 &lt;- station1\nst_geometry(station2) &lt;- st_cast(station4326,to=\"POINT\")\n\nReprésenter les stations sur une carte de France en utilisant une couleur différente en fonction de la température.\n\nggplot(dpt) + geom_sf(fill=\"white\")+\n  geom_sf(data=station2,aes(color=temp),size=2)+\n  scale_color_continuous(low=\"blue\",high=\"red\")\n\n\n\n\nOn obtient les coordonnées des centroïdes des départements à l’aide de\n\ncentro &lt;- st_centroid(dpt$geometry) \ncentro &lt;- st_transform(centro,crs=4326)\n\nOn déduit les distances entre ces centroïdes et les stations avec (station2 étant la table sf obtenue à la question 3).\n\nDD &lt;- st_distance(station2,centro)\n\nPrédire la température de chaque département à l’aide de la règle du 1 plus proche voisin (la température du département \\(i\\) sera celle de la station la plus proche du centroïde de \\(i\\)).\n\nNN &lt;- apply(DD,2,order)[1,]\nt_prev &lt;- station1[NN,2]$temp\n\nColorier les départements en fonction de la température prédite dans le département. On pourra faire varier le dégradé de couleur du jaune (pour les faibles températures) au rouge (pour les fortes).\n\ndpt1 &lt;- dpt |&gt; mutate(t_prev=t_prev) |&gt; \n  select(NOM_DEPT,geometry,t_prev)\ndpt1\n\nSimple feature collection with 96 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 99226 ymin: 6049647 xmax: 1242375 ymax: 7110524\nProjected CRS: RGF93 v1 / Lambert-93\n# A tibble: 96 × 3\n   NOM_DEPT                                                      geometry t_prev\n   &lt;chr&gt;                                               &lt;MULTIPOLYGON [m]&gt;  &lt;dbl&gt;\n 1 AIN                     (((919195 6541470, 918932 6541203, 918628 654…   19.7\n 2 AISNE                   (((735603 6861428, 735234 6861392, 734504 686…   15  \n 3 ALLIER                  (((753769 6537043, 753554 6537318, 752879 653…   20.5\n 4 ALPES-DE-HAUTE-PROVENCE (((992638 6305621, 992263 6305688, 991610 630…   14.7\n 5 HAUTES-ALPES            (((1012913 6402904, 1012577 6402759, 1010853 …   14.7\n 6 ALPES-MARITIMES         (((1018256 6272482, 1017888 6272559, 1016779 …   20.6\n 7 ARDECHE                 (((831641 6353746, 831034 6354160, 830637 635…   20.3\n 8 ARDENNES                (((842092 6905887, 842050 6906262, 840080 690…   15  \n 9 ARIEGE                  (((631545 6174170, 631157 6174210, 630414 617…   19.4\n10 AUBE                    (((796594 6759156, 796236 6759281, 795171 675…   13.3\n# ℹ 86 more rows\n\nggplot(dpt1) + geom_sf(aes(fill=t_prev)) +\n  scale_fill_continuous(low=\"blue\",high=\"red\")+theme_void()\n\n\n\n\n\nOn peut supprimer les lignes de frontières avec\n\n\nggplot(dpt1) + geom_sf(aes(fill=t_prev,color=t_prev)) + \n  scale_fill_continuous(low=\"blue\",high=\"red\") + \n  scale_color_continuous(low=\"blue\",high=\"red\")+theme_void()\n\n\n\n\n\n\n\n7.2.2 Trouver des cartes au format shapefile\nLe plus souvent on ne va pas construire les fonds de carte au format shapefile “à la main” et il est bien entendu important de récupérer ces fonds de carte au préalable. La méthode la plus courante consiste à taper les bons mots clefs sur un moteur de recherche… On pourra par exemple utiliser :\n\ndes packages R, par exemple rnaturalearth:\n\nworld &lt;- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\nclass(world)\n\n[1] \"sf\"         \"data.frame\"\n\nggplot(data = world) +\ngeom_sf(aes(fill = pop_est)) +\nscale_fill_viridis_c(option = \"plasma\", trans = \"sqrt\")+theme_void()\n\n\n\n\nOn peut aussi visualiser la térre comme une sphère :\n\nggplot(data = world) +\ngeom_sf() +\ncoord_sf(crs = \"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs \")\n\n\n\n\nVoir https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html pour plus de détails.\nle web, par exemple le site data gouv:\n\nregions &lt;- read_sf(\"data/regions-20180101-shp/\")\n\nAttention, la taille des objets peut être très (trop) grande\n\n\nformat(object.size(regions),units=\"Mb\")\n\n[1] \"15.4 Mb\"\n\n\net la construction de la carte peut dans ce cas prendre beaucoup de temps… On peut réduire la taille avec ce type d’outils\n\n\nlibrary(rmapshaper)\nregions1 &lt;- ms_simplify(regions)\nformat(object.size(regions1),units=\"Mb\")\n\n[1] \"0.9 Mb\"\n\nggplot(regions1)+geom_sf()+\n  coord_sf(xlim = c(-5.5,10),ylim=c(41,51))+theme_void()"
  },
  {
    "objectID": "05-carto.html#cartes-interactives-avec-leaflet",
    "href": "05-carto.html#cartes-interactives-avec-leaflet",
    "title": "7  Faire des cartes avec R",
    "section": "7.3 Cartes interactives avec leaflet",
    "text": "7.3 Cartes interactives avec leaflet\nLeaflet est un package permettant de faire de la cartographie interactive. On pourra consulter un descriptif synthétique ici. Le principe est similaire à ce qui a été présenté précédemment : les cartes sont construites à partir de couches qui se superposent. Un fond de carte s’obtient avec les fonctions leaflet et addTiles\n\nlibrary(leaflet)\nleaflet() |&gt; addTiles()\n\n\n\n\n\nOn dispose de plusieurs styles de fonds de cartes (quelques exemples ici) :\n\nParis &lt;- tibble(V=\"Paris\") |&gt; tidygeocoder::geocode(V)\nm2 &lt;- leaflet() |&gt; setView(lng = as.numeric(Paris[1,3]), \n                           lat = as.numeric(Paris[1,2]), zoom = 12) |&gt; \n  addTiles()\nm2 |&gt; addProviderTiles(\"Stamen.Toner\")\n\n\n\n\n\nm2 |&gt; addProviderTiles(\"Esri.NatGeoWorldMap\")\n\n\n\n\n\nm2 |&gt;\n  addProviderTiles(\"Stamen.Watercolor\") |&gt;\n  addProviderTiles(\"Stamen.TonerHybrid\")\n\n\n\n\nIl est souvent utile de repérer des lieux sur une carte à l’aide de symboles. On pourra effectuer cela à l’aide des fonctions addMarkers et addCircles, par exemple :\n\ndata(quakes)\nleaflet(data = quakes[1:20,]) |&gt; addTiles() |&gt;\n  addMarkers(~long, ~lat, popup = ~as.character(mag))\n\n\n\n\n\nOn remarque que l’on utilise ici un tilde pour spécifier qu’on utilise des variables dans un dataframe.\nLe caractère interactif de la carte permet d’ajouter de l’information lorsqu’on clique sur un marker (grâce à l’option popup). On peut également ajouter des popups qui contiennent plus d’information, voire des liens vers des sites web :\n\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='http://www.samurainoodle.com'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() |&gt; addTiles() |&gt;\n  addPopups(-122.327298, 47.597131, content,\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\nExercice 7.4 (Popup avec leaflet) Placer un popup localisant l’Université Rennes 2 (Campus Villejean). On ajoutera un lien renvoyant sur le site de l’Université.\n\nR2 &lt;- tibble(V=\"Universite Rennes Villejean\") |&gt; tidygeocoder::geocode(V)\ninfo &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.univ-rennes2.fr'&gt;Universite Rennes 2&lt;/a&gt;&lt;/b&gt;\",\n  \"Campus Villejean\")\n\n\nleaflet() |&gt; addTiles() |&gt;  \n  addPopups(as.numeric(R2[1,3]$long), as.numeric(R2[1,2]$lat), info,\n            options = popupOptions(closeButton = FALSE))\n\n\n\n\n\n\n\n7.3.1 Challenge 2 : Visualisation des stations velib à Paris\nPlusieurs villes dans le monde ont accepté de mettre en ligne les données sur l’occupation des stations velib. Ces données sont facilement accessibles et mises à jour en temps réel. On dispose généralement de la taille et la localisation des stations, la proportion de vélos disponibles… Il est possible de requêter (entre autres) :\n\nsur les données Decaux\nsur Open data Paris\nsur vlstats pour des données mensuelles ou historiques ou encore sur Velib pour obtenir des fichiers qui sont rafraîchis régulièrement.\n\n\nRécupérer les données actuelles de velib disponibles pour la ville de Paris : https://opendata.paris.fr/explore/dataset/velib-disponibilite-en-temps-reel/information/. On pourra utiliser la fonction read_delim avec l’option delim=\";\".\n\nlien &lt;- \"https://opendata.paris.fr/explore/dataset/velib-disponibilite-en-temps-reel/download/?format=csv&timezone=Europe/Berlin&use_labels_for_header=true\"\nsta.Paris &lt;- read_delim(lien,delim=\";\")\n\nDécrire les variables du jeu de données.\n\nNous avons de l’information sur la disponibilité, le remplissage… de stations velib parisiennes.\n\nCréer une variable latitude et une variable longitude à partir de la variable Coordonnées géographiques. On pourra utiliser la fonction separate du package tidyr.\n\nsta.Paris1 &lt;- sta.Paris |&gt; separate(`Coordonnées géographiques`,\n                                 into=c(\"lat\",\"lon\"),sep=\",\") |&gt; \n  mutate(lat=as.numeric(lat),lon=as.numeric(lon))\n\nVisualiser les positions des stations sur une carte leaflet. On pourra utiliser l’option clusterOptions = markerClusterOptions() pour que la carte soit plus claire.\n\nmap.velib1 &lt;- leaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt;\n  addCircleMarkers(~ lon, ~ lat,radius=3,\nstroke = FALSE, fillOpacity = 0.5,color=\"red\"\n  )\n\nmap.velib1\n\n\n\n\n\n\nLa carte est peu lisible, il y a en effet beaucoup de stations et il est difficile de bien les visualiser. Les choses deviennent plus claires en visualisant es groupes de station :\n\n\nleaflet(sta.Paris1) |&gt; addTiles() |&gt; \n  addMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions())\n\n\n\n\n\nAjouter un popup qui permet de connaitre le nombre de vélos disponibles (électriques+mécanique) quand on clique sur la station (on pourra utiliser l’option popup dans la fonction addCircleMarkers).\n\nleaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt; \n  addMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions(),\n             popup = ~ sprintf(\"&lt;b&gt; Vélos dispos : %s&lt;/b&gt;\",\n                                 as.character(`Nombre total vélos disponibles`)))\n\n\n\n\n#ou sans sprintf\n\nleaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt; \n  addMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions(),\n             popup = ~ paste(\"&lt;b&gt; Vélos dispos &lt;/b&gt;:\",\n                               as.character(`Nombre total vélos disponibles`)))\n\n\n\n\n\nAjouter la nom de la station dans le popup.\n\nleaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt;\n  addMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions(),\n             popup = ~ paste(as.character(`Nom station`),\"&lt;br/&gt;&lt;b&gt; Vélos dispos &lt;/b&gt;:\",\n                             as.character(`Nombre total vélos disponibles`)))\n\n\n\n\n\nFaire de même en utilisant des couleurs différentes en fonction de la proportion de vélos disponibles dans la station. On pourra utiliser les palettes de couleur\n\nColorPal1 &lt;- colorNumeric(scales::seq_gradient_pal(low = \"#132B43\", high = \"#56B1F7\",\n                                               space = \"Lab\"), domain = c(0,1.2))\nColorPal2 &lt;- colorNumeric(scales::seq_gradient_pal(low = \"red\", high = \"black\", \n                                               space = \"Lab\"), domain = c(0,1.2))\n\n\nleaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt;\n  addCircleMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions(),\n                   stroke = FALSE, fillOpacity = 0.7,\n                   color=~ColorPal1(`Nombre total vélos disponibles`/\n                                      `Capacité de la station`), \n                   popup = ~ paste(as.character(`Nom station`),\"&lt;br/&gt;&lt;b&gt; Vélos dispos &lt;/b&gt;:\",\n                                   as.character(`Nombre total vélos disponibles`),\n                                   sep=\"\"))\n\n\n\n\n\n\nleaflet(data = sta.Paris1) |&gt; \n  addTiles() |&gt;\n  addCircleMarkers(~ lon, ~ lat,clusterOptions = markerClusterOptions(),\n                   stroke = FALSE, fillOpacity = 0.7,\n                   color=~ColorPal2(`Nombre total vélos disponibles`/\n                                      `Capacité de la station`),\n                   radius=~(`Nombre total vélos disponibles`/\n                          `Capacité de la station`)*40,\n                   popup = ~ paste(as.character(`Nom station`),\"&lt;br/&gt;&lt;b&gt; Vélos dispos &lt;/b&gt;:\",\n                               as.character(`Nombre total vélos disponibles`),\n                               sep=\"\"))\n\n\n\n\n\nCréer une fonction local.station qui permette de visualiser quelques stations autours d’une station choisie.\n\nnom.station &lt;- \"Jussieu - Fossés Saint-Bernard\"\nlocal.station &lt;- function(nom.station){\n  df &lt;- sta.Paris1 |&gt; filter(`Nom station`==nom.station)\n  leaflet(data = sta.Paris1) |&gt; setView(lng=df$lon,lat=df$lat,zoom=15) |&gt;\naddTiles() |&gt; \naddCircleMarkers(~ lon, ~ lat,stroke = FALSE, fillOpacity = 0.7,\n                popup = ~ paste(as.character(`Nom station`),\", Vélos dispos :\",\n                                as.character(`Nombre total vélos disponibles`),\n                                sep=\"\")) |&gt;\naddMarkers(lng=df$lon,lat=df$lat,\n           popup = ~ paste(nom.station,\", Vélos dispos :\",\n                           as.character(df$`Nombre total vélos disponibles`),\n                           sep=\"\"),\n           popupOptions = popupOptions(noHide = T))\n}\n\nLa fonction devra par exemple renvoyer\n\nlocal.station(\"Jussieu - Fossés Saint-Bernard\")\n\n\n\n\n\n\nlocal.station(\"Gare Montparnasse - Arrivée\")\n\n\n\n\n\n\n\n\n7.3.2 Carte des températures avec leaflet\n\nExercice 7.5 (Carte des températures avec leaflet) Refaire la carte des températures du premier challenge (voir Section 7.2.1) en utilisant leaflet. On utilisera la table construite dans le challenge 1 et la fonction addPolygons. On pourra également ajouter un popup qui permet de visualiser le nom du département ainsi que la température prévue lorsqu’on clique dessus.\n\ndpt2 &lt;- st_transform(dpt1, crs = 4326)\ndpt2$t_prev &lt;- round(dpt2$t_prev)\npal &lt;- colorNumeric(scales::seq_gradient_pal(low = \"blue\", high = \"red\",\n                                             space = \"Lab\"), domain = dpt2$t_prev)\nm &lt;- leaflet() |&gt; addTiles() |&gt; \n  addPolygons(data = dpt2,color=~pal(t_prev),fillOpacity = 0.6, \n              stroke = TRUE,weight=1,\n              popup=~paste(as.character(NOM_DEPT),as.character(t_prev),sep=\" : \"),\n              highlightOptions = highlightOptions(color = \"black\", weight = 3,bringToFront = TRUE)) |&gt; \n  addLayersControl(options=layersControlOptions(collapsed = FALSE))\nm\n\n\n\n\n\n\nou avec une autre palette de couleur\n\n\npal1 &lt;- colorNumeric(palette = c(\"inferno\"),domain = dpt2$t_prev)\nm1 &lt;- leaflet() |&gt; addTiles() |&gt; \n  addPolygons(data = dpt2,color=~pal1(t_prev),fillOpacity = 0.6, \n              stroke = TRUE,weight=1,\n              popup=~paste(as.character(NOM_DEPT),as.character(t_prev),sep=\" : \"),\n              highlightOptions = highlightOptions(color = \"black\", weight = 3,bringToFront = TRUE)) |&gt; \n  addLayersControl(options=layersControlOptions(collapsed = FALSE))\nm1"
  },
  {
    "objectID": "05-carto.html#autres-packages",
    "href": "05-carto.html#autres-packages",
    "title": "7  Faire des cartes avec R",
    "section": "7.4 Autres packages",
    "text": "7.4 Autres packages\nR propose de nombreux autres outils pour faire de la cartographie. On présente très brièvement les packages tmap, map_sf et mapview à travers l’exemple suivant\n\nus &lt;- spData::us_states\nggplot(us)+geom_sf(aes(fill=total_pop_15))\n\n\n\n\nOn pourra trouver de la documentation sur ces packages aux adresses suivantes :\n\nmapsf : https://cran.r-project.org/web/packages/mapsf/vignettes/mapsf.html\ntmap : https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html\nTutoriel thinkr :\n\nhttps://thinkr.fr/cartographie-interactive-comment-visualiser-mes-donnees-spatiales-de-maniere-dynamique-avec-leaflet/\nhttps://thinkr.fr/cartographie-interactive-avec-r-la-suite/\n\n\ntmap permet de visualiser des cartes statiques et interactives avec une sytaxe proche de ggplot2 :\n\nlibrary(tmap)\n#tmap_mode(\"view\") #pour une carte dynamique\ntm_shape(us)+tm_polygons(fill=\"total_pop_15\")\n\n\n\n\nTout comme pour ggplot2, on pourra utiliser des facet avec\n\nus |&gt; \n  pivot_longer(c(total_pop_10,total_pop_15),names_to=\"annee\",values_to = \"pop\") |&gt; \n  tm_shape() + tm_polygons(fill=\"pop\") + tm_facets(by=\"annee\")\n\n\n\n\nmapsf propose une syntaxe simple pour des cartes statiques définies à partir d’objets au format sf :\n\nmapsf::mf_map(us,var=\"total_pop_15\",type=\"choro\")\n\n\n\n\nEnfin, mapview propose des cartes synamiques pour visualiser des données spatiales présentées sous différents formats :\n\nmapview::mapview(us,zcol=\"total_pop_15\",\n                 popup=leafpop::popupTable(us, zcol = c(\"NAME\",\"total_pop_15\")))\n\n\n\n\n\n\n\nExercice 7.6 (Toujours les températures) Refaire la carte des températures du premier challenge (voir Section 7.2.1) en utilisant tmap, mapsf et mapview.\n\ntm_shape(dpt2)+tm_polygons(\"t_prev\",\n                           palette=\"viridis\")\n\n\n\n# c4a_palettes(\"seq\") pour lister les palettes\n\n\nmapsf::mf_map(dpt2,var=\"t_prev\",type=\"choro\",pal=\"Plasma\")\n\n\n\n# hcl.pals(type=\"sequential\") pour les palettes\n\n\nmapview::mapview(dpt2,zcol=\"t_prev\",\n                 popup=leafpop::popupTable(dpt2,zcol=c(\"NOM_DEPT\",\"t_prev\")),\n                 col.regions=colorRampPalette(c(\"blue\", \"red\")),\n                 color=\"white\")\n\n\n\n\n\n\n\n\n\n\n\nPebesma, E. 2018. « Simple Features for R: Standardized Support for Spatial Vector Data ». The R Journal 10: 439‑46. https://doi.org/10.32614/RJ-2018-009."
  },
  {
    "objectID": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "href": "06-interactif.html#représentations-classiques-avec-ramcharts-et-plotly",
    "title": "8  Quelques outils de visualisation dynamique/interactive",
    "section": "8.1 Représentations classiques avec rAmCharts et plotly",
    "text": "8.1 Représentations classiques avec rAmCharts et plotly\nLe package rAmCharts est très utile pour donner un caractère interactif à des représentations graphiques standards (nuages de points, séries temporelles, histogrammes…). Ce package a été fait dans l’esprit d’utiliser les fonctions graphiques de R en utilisant le préfixe am. La syntaxe est très proche de celle des fonctions graphiques standards. On a par exemple :\n\nlibrary(rAmCharts)\namHist(iris$Petal.Length)\n\n\n\n\n\n\namPlot(iris, col = colnames(iris)[1:2], type = c(\"l\", \"st\"), \n       zoom = TRUE, legend = TRUE)\n\n\n\n\n\n\namBoxplot(iris)\n\n\n\n\n\nplotly permet de faire des choses semblables avec avec une syntaxe spécifique. Les commandes plotly se décomposent essentiellement en 3 parties :\n\nle type de représentation graphique (plot_ly}) ;\nles ajouts que l’on souhaite effectuer (add_trace) ;\nla gestion de la fenêtre graphique (axes, titres…) (layout).\n\nOn trouvera un descriptif complet de ces 3 composantes ici. On propose de tracer un nuage de points en dimension 2 et d’y ajouter la droite de régression. On commence par générer le nuage et ajuster le modèle linéaire :\n\nlibrary(plotly)\nn &lt;- 100\nX &lt;- runif(n,-5,5)\nY &lt;- 2+3*X+rnorm(n,0,1)\nD &lt;- data.frame(X,Y)\nmodel &lt;- lm(Y~X,data=D)\n\nOn effectue maintenant le tracé\n\nD |&gt; plot_ly(x=~X,y=~Y) |&gt;\n  add_markers(type=\"scatter\",mode=\"markers\",\n              marker=list(color=\"red\"),name=\"Nuage\") |&gt;\n  add_trace(y=fitted(model),type=\"scatter\",mode='lines',\n            name=\"Régression\",line=list(color=\"blue\")) |&gt; \n  layout(title=\"Régression\",xaxis=list(title=\"abscisse\"),\n         yaxis=list(title=\"ordonnées\"))\n\n\n\n\n\nContrairement à ggplot, plotly permet de faire de la 3D. Par exemple\n\nplot_ly(z = volcano, type = \"surface\")\n\n\n\n\nplot_ly(z = volcano, type = \"contour\")\n\n\n\n\n\n\nIl est possible de convertir des graphes ggplot au format plotly avec la fonction ggplotly :\n\np &lt;- ggplot(iris)+aes(x=Species,y=Sepal.Length)+geom_boxplot()+theme_classic()\nggplotly(p)\n\n\n\n\n\n\nExercice 8.1 (Graphes standards avec rAmCharts et plotly) Pour le jeu de données iris on effectuera les graphes suivants en rAmCharts et plotly.\n\nNuage de points représentant les longueurs et largeurs de Sépales. On utilisera une couleur différente en fonction de l’espèce.\n\namPlot(Sepal.Length~Sepal.Width,data=iris,col=iris$Species) \n\n\n\n\n\n\niris |&gt; plot_ly(x=~Sepal.Width,y=~Sepal.Length,color=~Species) |&gt;\n  add_markers(type=\"scatter\",mode=\"markers\")\n\n\n\n\n\nBoxplot permettant de visualiser la distribution de la variable Petal.Length en fonction de l’espèce.\n\namBoxplot(Petal.Length~Species,data=iris)\n\n\n\n\n\n\niris |&gt; plot_ly(x=~Species,y=~Petal.Length) |&gt; add_boxplot()"
  },
  {
    "objectID": "06-interactif.html#dynamiser-ggplot2-avec-ggiraph",
    "href": "06-interactif.html#dynamiser-ggplot2-avec-ggiraph",
    "title": "8  Quelques outils de visualisation dynamique/interactive",
    "section": "8.2 Dynamiser ggplot2 avec ggiraph",
    "text": "8.2 Dynamiser ggplot2 avec ggiraph\nggiraph est une extension de ggplot2 qui produit des graphes dynamiques et interactifs. On pourra trouver une documentation complète à l’url https://www.ardata.fr/ggiraph-book/. D’une façon générale, les graphes s’obtiennent en utilisant la syntaxe de ggplot2 et en ajoutant le suffixe _interactive aux fonction geom. Par exemple\n\nlibrary(ggiraph)\np &lt;- ggplot(data=iris) +\n  aes(x=Sepal.Length,y=Sepal.Width,\n      tooltip=Petal.Width,data_id=Species) + \n  geom_point_interactive(size=3,hover_nearest=TRUE)\n\nOn visualise le graphe avec la fonction girafe :\n\ngirafe(ggobj = p)\n\n\n\n\n\nLe graphe est dynamique dans le sens où lorsque la souris approche un point\n\nles points de la même espèce que le point où se trouve la souris se colorie (option data_id) ;\nla largeur de pétale du point s’affiche (option tooltip).\n\nIl est bien entendu possible de personnaliser le caractère dynamique. On peut par exemple introduire du css pour changer la couleur (ou les autres attributs) des points qui se colorient lorsque la souris parcourt le graphe :\n\ngirafe(ggobj = p,\n       options=list(\n         opts_hover(css=\"fill:yellow;stroke:black;stroke-width:2px;\")\n       )\n)\n\n\n\n\n\nLe coté interactif peut s’obtenir en permettant à l’utilisateur de sélectionner des parties du graphe, par exemple des individus sur une nuage de points\n\npreselection &lt;- iris$Species[1]\ngirafe(ggobj = p,\n       options=list(\n         opts_selection(\n           selected = preselection,\n           css=\"fill:yellow;stroke:black;stroke-width:1px;\",\n           type=\"single\",only_shiny = FALSE\n         )\n       ))\n\n\n\n\n\n\nExercice 8.2 (Diagramme en barres dynamique) On considère le graphe diagramme en barres suivant\n\nggplot(diamonds)+aes(x=cut,fill=color)+geom_bar()\n\n\n\n\n\nCréer un graphe dynamique qui permet de visualiser la valeur de la variable color (la lettre) lorsque la souris parcourt sur le graphe.\n\np &lt;- ggplot(diamonds)+\n  aes(x=cut,fill=color,tooltip=color)+\n  geom_bar_interactive()\ngirafe(ggobj = p)\n\n\n\n\n\nFaire la même chose en affichant cette fois les effectifs de la classe à la place de la valeur de color. On pourra utiliser la fonction after_stat\n\np &lt;- ggplot(diamonds)+\n  aes(x=cut,fill=color,tooltip=after_stat(count))+\n  geom_bar_interactive()\ngirafe(ggobj = p)\n\n\n\n\n\nAjouter au graphe précédent une sélection qui identifie toutes les barres d’une même valeur de color (en les coloriant en rouge).\n\np1 &lt;- p+geom_bar_interactive(aes(data_id=color))\ngirafe(ggobj = p1,\n       options=list(\n         opts_hover(\n           css=\"fill:red;stroke:black;stroke-width:1px;\")\n       )\n)"
  },
  {
    "objectID": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "href": "06-interactif.html#graphes-pour-visualiser-des-réseaux-avec-visnetwork",
    "title": "8  Quelques outils de visualisation dynamique/interactive",
    "section": "8.3 Graphes pour visualiser des réseaux avec visNetwork",
    "text": "8.3 Graphes pour visualiser des réseaux avec visNetwork\nDe nombreuses données peuvent être visualisées à l’aide d’un graphe, notamment lorsqu’il s’agit de représenter des connexions entre individus. Un individu est alors représentés par un noeud et les individus connectés sont reliés par des arêtes. Le package igraph propose une visualisation statique d’un réseau. Pour donner un caractère dynamique à ce type de représentation, on pourra utiliser le package visNetwork. Une représentation standard visNetwork s’effectue en spécifiant les nœuds et connexions d’un graphe, par exemple :\n\nnodes &lt;- tibble(id = 1:15, label = paste(\"Id\", 1:15),\n                    group=sample(LETTERS[1:3], 15, replace = TRUE))\nedges &lt;- tibble(from = trunc(runif(15)*(15-1))+1,to = trunc(runif(15)*(15-1))+1)\nlibrary(visNetwork)\nvisNetwork(nodes,edges)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE)\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(highlightNearest = TRUE,\n                                        nodesIdSelection = TRUE)\n\n\n\n\n\n\n\n\nvisNetwork(nodes, edges) |&gt; visOptions(selectedBy = \"group\")\n\n\n\n\n\n\nExercice 8.3 (Interactions entre media) On considère un graphe qui représente des liens entre différents médias. Les données sont présentées ici et on peut les importer avec\n\nnodes &lt;- read_csv(\"data/Dataset1-Media-Example-NODES.csv\")\nlinks &lt;- read_csv(\"data/Dataset1-Media-Example-EDGES.csv\")\nhead(nodes)\n\n# A tibble: 6 × 5\n  id    media               media.type type.label audience.size\n  &lt;chr&gt; &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n1 s01   NY Times                     1 Newspaper             20\n2 s02   Washington Post              1 Newspaper             25\n3 s03   Wall Street Journal          1 Newspaper             30\n4 s04   USA Today                    1 Newspaper             32\n5 s05   LA Times                     1 Newspaper             20\n6 s06   New York Post                1 Newspaper             50\n\nhead(links)\n\n# A tibble: 6 × 4\n  from  to    weight type     \n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;    \n1 s01   s02       10 hyperlink\n2 s01   s02       12 hyperlink\n3 s01   s03       22 hyperlink\n4 s01   s04       21 hyperlink\n5 s04   s11       22 mention  \n6 s05   s15       21 mention  \n\n\nL’objet nodes représente les nœuds du graphe et l’objet links les arêtes. On définit l’objet graphe avec\n\nlibrary(igraph)\nmedia &lt;- graph_from_data_frame(d=links, vertices=nodes, directed=T) \nV(media)$name &lt;- nodes$media\n\net on peut le visualiser en faisant un plot de cet objet\n\nplot(media)\n\n\n\n\n\nVisualiser ce graphe avec VisNetwork. On pourra utiliser la fonction toVisNetworkData.\n\nmedia.VN &lt;- toVisNetworkData(media)\nvisNetwork(nodes=media.VN$nodes,edges=media.VN$edges)\n\n\n\n\n\nAjouter une option qui permette de sélectionner le type de media (Newspaper, TV ou Online).\n\nmedia.VN$nodes &lt;- media.VN$nodes |&gt; rename(labels=type.label)\nvisNetwork(nodes=media.VN$nodes,edges=media.VN$edges) |&gt; \n  visOptions(selectedBy = \"labels\")\n\n\n\n\n\n\n\nUtiliser une couleur différente pour chaque type de media.\n\nIl suffit de donner le nom group à la variable type.label.\n\n\nmedia.VN1 &lt;- media.VN\nmedia.VN1$nodes &lt;- media.VN1$nodes |&gt; rename(group=media.type)\nvisNetwork(nodes=media.VN1$nodes,edges=media.VN1$edges) |&gt; \n  visOptions(selectedBy = \"labels\")\n\n\n\n\n\n\n\nFaire des flèches d’épaisseur différente en fonction du poids (weight). On pourra également ajouter l’option visOptions(highlightNearest = TRUE).\n\nIl suffit de donner le nom width ou value à la variable weight.\n\n\nmedia.VN1$edges &lt;- media.VN1$edges |&gt; rename(width=weight)\nvisNetwork(nodes=media.VN1$nodes,edges=media.VN1$edges) |&gt; \n  visOptions(selectedBy = \"labels\",highlightNearest = TRUE)"
  },
  {
    "objectID": "06-interactif.html#dashboard",
    "href": "06-interactif.html#dashboard",
    "title": "8  Quelques outils de visualisation dynamique/interactive",
    "section": "8.4 Dashboard",
    "text": "8.4 Dashboard\nUn tableau de bord permet de visualiser “facilement” et “rapidement” divers graphes et/ou résumés statistiques en lien avec une problématique donnée. Sur R le package flexdashboard permet de construire de tels tableaux de bord. On trouvera un descriptif précis de ce package à cette url : https://rmarkdown.rstudio.com/flexdashboard/. On utilisera cette documentation pour faire l’exercice suivant.\n\nExercice 8.4 (Dashboard pour modèles linéaires) On considère le jeu de données ozone.txt. Le problème est d’expliquer la concentration maximale en ozone quotidienne (variable maxO3) par d’autres variables météorologiques (températures et indicateurs de nébulosité relevés à différents moments de la journée…). On souhaite faire un tableau de bord qui permettra de :\n\nvisualiser les données : la base de données ainsi qu’un ou deux graphes descriptifs sur la variable à expliquer ;\nvisualiser les modèles linéaires simples : on choisit une variable explicative et on visualise le graphe de la régression ainsi que le modèle ;\nvisualiser le modèle linéaire complet : on affiche le résultat de la régression avec toutes les variables et on représente le graphe des résidus ;\nchoisir les variables explicatives.\n\n\nAvant de réaliser le dashboard, on propose d’écrire quelques commandes pour calculer les différentes sorties :\n\nOn considère uniquement les variables quantitatives du jeu de données. Visualiser les corrélations entre ces variables à l’aide de la fonction corrplot du package corrplot.\n\ndf &lt;- read.table(\"data/ozone.txt\")\ncc &lt;- cor(df[,1:11])\nmat.cor &lt;- corrplot::corrplot(cc)\n\n\n\n\nReprésenter l’histogramme de la variable maxO3, on fera le graphe avec ggplot, rAmCharts, plotly (en utilisant ggplotly par exemple) et ggiraph.\n\ngg.H &lt;- ggplot(df)+aes(x=maxO3)+geom_histogram(bins = 10)\nam.H &lt;- amHist(df$maxO3)\npl.H &lt;- ggplotly(gg.H)\ngir.H &lt;- ggplot(df)+aes(x=maxO3,tooltip=after_stat(count),data_id=after_stat(count))+\n  geom_histogram_interactive(bins = 10) #%&gt;%  girafe(ggobj = .)\n\nConstruire le modèle linéaire permettant d’expliquer maxO3 par les autres variables. Calculer les résidus studentisés (rstudent) et visualiser ces résidus en fonction de la variable maxO3. Là encore on pourra ajouter un lisseur sur le graphe.\n\nmod &lt;- lm(maxO3~.,data=df)\nres &lt;- rstudent(mod)\ndf1 &lt;- data.frame(maxO3=df$maxO3,r.student=res)\nGgg &lt;- ggplot(df1)+aes(x=maxO3,y=res)+geom_point()+geom_smooth()\nGggp &lt;- ggplotly(Ggg)\n\n\nOn peut maintenant passer au tableau de bord. On utilise le menu File -&gt; Rmarkdown -&gt; From Template -&gt; Flex Dashboard.\n\nConstruire un premier dashboard permettant de visualiser :\n\nle jeu de données sur une colonne (on pourra utiliser la fonction datatable du package DT)\nl’histogramme de la variable maxO3 ainsi que la matrice des corrélations entre les variables quantitatives.\n\nAjouter un nouvel onglet qui permet de visualiser le summary du modèle linéaire complet. On pourra utiliser la fonction datatable du package DT. Indication : ce nouvel onglet peut se créer avec\n\nName of the tab\n=====================================  \n\nAjouter un nouvel onglet qui permet de visualiser un modèle linéaire simple avec la variable explicative de votre choix. On pourra afficher dans cet onglet le summary du modèle ainsi que le nuage de points et la droite de régression.\nPour aller plus loin : ajouter un dernier onglet qui permette à l’utilisateur de choisir la variable explicative du modèle simple. Indications : on pourra utiliser les commandes Shiny\n\nChoix de la variable\n\nradioButtons(\"variable1\",\n            label=\"Choisir la variable explicative\",\n            choices=names(df)[-1],\n            selected=list(\"T9\"))\n\nMise à jour du résumé\n\nmod1 &lt;- reactive({\n  XX &lt;- paste(input$variable1,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  lm(form,data=df)\n  })\n#Df correspond au jeu de données\nrenderDataTable({\n  mod.sum1 &lt;- summary(mod1())$coefficients |&gt; round(3) |&gt; as.data.frame()\n  DT::datatable(mod.sum1,options = list(dom = 't'))\n})\n\nMise à jour du graph interactif\n\nrenderPlotly({\n  (ggplot(df)+aes(x=!!as.name(input$variable1),y=maxO3)+\n     geom_point()+geom_smooth(method=\"lm\")) |&gt; ggplotly()\n})\n\nEnfin il ne faudra pas oublier d’ajouter\n\nruntime: shiny\n\n\nAjouter un dernier onglet permettant de choisir les variables explicatives dans le modèle linéaire. Là encore on pourra utiliser des commandes Shiny, par exemple\n\ncheckboxGroupInput(\"variable\",\n                   label=\"Choisir la variable\",\n                   choices=names(df)[-1],\n                   selected=list(\"T9\"))\n\nPour les variables choisies, on affichera dans ce nouvel onglet les coefficients du modèle linéaire ainsi que le graphe des résidus studentisés.\n\n\nLe tableau de bord finalisé pourra ressembler à\n\n\n\n\nIl est disponible à l’url https://lrouviere.shinyapps.io/dashboard/"
  },
  {
    "objectID": "07-shiny.html#une-première-application",
    "href": "07-shiny.html#une-première-application",
    "title": "9  Applications web avec Shiny",
    "section": "9.1 Une première application",
    "text": "9.1 Une première application\nCréer un répertoire pour l’application avec RStudio\nFile -&gt; New Project -&gt; New Directory -&gt; Shiny Web Application\nChoisir une application Multiple File.\nSi cette option n’est pas disponible (ça peut dépendre des versions de Rstudio), on pourra utiliser\nFile -&gt; New File -&gt; Shiny Web App -&gt; Multiple File\nDeux fichier sont automatiquement générés : ui.R et server.R. Lancer l’application en cliquant sur le bouton Run App.\n\nChanger le titre de l’application. On pourra l’appeler My first application.\nMettre à jour et vérifier que le titre a bien été changé."
  },
  {
    "objectID": "07-shiny.html#input---output",
    "href": "07-shiny.html#input---output",
    "title": "9  Applications web avec Shiny",
    "section": "9.2 Input - output",
    "text": "9.2 Input - output\nOn garde la même application. On ne s’intéressera pas à la structure dans cette partie, on veut simplement ajouter\n\ndes nouveaux inputs dans le sidebarPanel, après le sliderInput. On n’oubliera pas de séparer les inputs par des virgules ;\ndes nouveaux outputs dans le mainPanel, après le plotOutput. Là encore, on n’oubliera pas de séparer les outputs par des virgules.\n\nPour résumer on souhaite une colonne avec tous les inputs et une autre avec tous les outputs.\n\nAjouter dans ui.R une entrée qui permette de changer la couleur de l’histogramme. On pourra utiliser\n\nselectInput(inputId = \"color\", label = \"Couleur :\",\n            choices = c(\"Rouge\" = \"red\", \"Vert\" = \"green\", \"Bleu\" = \"blue\"))\n\nAjouter une sortie qui permette de visualiser le summary du jeu de données faithful. On pourra utiliser\n\n# ui.R\nverbatimTextOutput(\"...\")\n\n# server.R\noutput$... &lt;- renderPrint({\n  summary(...)\n})\n\n\n\nExercice 9.1 (Ajouter des inputs/outputs) Ajouter des entrées/sorties à votre application pour\n\nproposer à l’utilisateur de choisir un titre pour l’histogramme (utiliser textInput dans l’ui et l’option main dans hist);\nchoisir la variable de faithful à représenter dans l’histogramme avec un radioButtons ayant pour choix colnames(faithful);\nvisualiser le jeu de données entier (renderDataTable & dataTableOutput);\najouter un text sous l’histogramme qui indique le nombre de classes (renderText et paste dans server, textOutput dans ui);\nremplacer le selectInput du choix de la couleur par un colourInput (utiliser la package colourpicker);\nexporter le graphe (downloadButton & jpeg).\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://input-output-rouviere-shiny.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#structurer-lapplication",
    "href": "07-shiny.html#structurer-lapplication",
    "title": "9  Applications web avec Shiny",
    "section": "9.3 Structurer l’application",
    "text": "9.3 Structurer l’application\nOn considère l’application app_structure disponible ici. C’est quasiment la même que précédemment avec un navbarPage qui définit\n\nun onglet Data pour visualiser les données (table + summary)\nun onglet Visualisation : inputs + histogramme.\n\n\nExercice 9.2 (Structurer son application) On conserve l’application précédente.\n\nDans l’onglet Data utiliser navlistPanel pour séparer le summary et la table table en deux onglets :\n\n# rappel de la structure (ui.R)\nnavlistPanel(\"Title of the structure\",\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\"),\n             tabPanel(\"Title of the tab\", ..., \"(content of the tab)\")\n)\n\nDans l’onglet Visualization changer sidebarLayout - sidebarPanel - mainPanel par un fluidRow à 2 colonnes :\n\n1/4 : pour le sidebarPanel\n3/4 : pour le mainPanel.\n\n\nfluidRow(\n  column(width = 3, ...), # column 1/4 (3/12)\n  column(width = 9, ...)  # column 3/4 (9/12)\n)\n\nIndication : utiliser wellPanel pour la colonne de gauche.\nAjouter un bloxplot dans l’onglet visualisation (même variable et même couleur). On pourra également utiliser tabsetPanel pour avoir deux onglets pour l’histogramme et le boxplot.\n\n# rappel de la structure (ui.R)\ntabsetPanel(\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\"),\n  tabPanel(\"Title of the tab\", ... ,\"(content of the tab)\")\n)\n\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://structure-rouviere-shiny.apps.math.cnrs.fr/.\nPour aller plus loin : faire la même application avec shinydashboard."
  },
  {
    "objectID": "07-shiny.html#ajout-de-graphes-interactifs",
    "href": "07-shiny.html#ajout-de-graphes-interactifs",
    "title": "9  Applications web avec Shiny",
    "section": "9.4 Ajout de graphes interactifs",
    "text": "9.4 Ajout de graphes interactifs\nDans l’application précédente, remplacer l’histogramme et la boxplot par des graphes javascript réalisés avec rAmCharts. On pourra utiliser\n\n# server.R\noutput$distPlot &lt;- renderAmCharts({...})\n\n# ui.R\namChartsOutput(\"...\")\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici https://interactifs-rouviere-shiny-2.apps.math.cnrs.fr/.\n\nExercice 9.3 (Modèles linéaires pour l’ozone) On considère les données ozone.txt où le problème est d’expliquer la variable continue maxO3 par les autres variables du jeu de données. On propose de construire une application avec 3 onglets en utilisant (dans le ui.R) la structure suivante :\n\nnavbarPage(\n  title=\"Titre de l'appli\",\n  tabPanel(\n    title=\"Titre de l'onglet\",\n    ...\n  )\n)\n\n\nCréer le fichier global.R où on chargera les packages nécessaires et où on lira le jeu de données.\nConstruire le premier onglet où on visualisera :\n\nsur une ligne le jeu de données de façon dynamique : on pourra utiliser la fonction dataTableOutput dans le ui.R et la fonction renderDataTable dans le server.R.\nsur une autre ligne l’histogramme de la variable à expliquer et la matrice des corrélations des variables explicatives quatitatives. On pourra utiliser les commandes suivantes pour la matrice des corrélations :\n\ncorrplot::corrplot(cor(ozone[,2:11]))\n\nD’un point de vue structure on pourra utiliser la fonction fluidrow pour intégrer les deux graphes.\n\nAjouter un second onglet qui permettra de visualiser un modèle à une variable explicative que l’utilisateur choisira. On pourra utiliser radioButtons dans le ui.R pour choisir la variable et les commandes suivantes dans le server.R\n\nrenderDataTable({\n  XX &lt;- paste(input$...,collapse=\"+\")\n  form &lt;- paste(\"maxO3~\",XX,sep=\"\") |&gt; formula()\n  mod &lt;- lm(form,data=ozone)\n  mod_sum1 &lt;- summary(mod)$coefficients |&gt; round(3) |&gt; as_tibble()\n  mod_sum1\n})\n\nOn pourra également visualiser le nuage de points et la droite de régression pour le modèle choisi par l’utilisateur.\nAjouter un troisième onglet où l’utilisateur pourra visualiser les estimateurs d’un modèle de régression multiple où il choisira les variables explicatives (avec checkboxGroupInput par exemple). On pourra éventuellement ajouter un graphe pour visualiser les résidus.\nChoisir un thème pour votre application en vous référant à la page suivante : https://rstudio.github.io/shinythemes/.\n\nL’application demandée pourra ressembler à\n\n\n\n\nElle est également disponible ici : https://ozone-rouviere-shiny-4.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#reactive-isolation-observe-html",
    "href": "07-shiny.html#reactive-isolation-observe-html",
    "title": "9  Applications web avec Shiny",
    "section": "9.5 Reactive, isolation, observe, html, …",
    "text": "9.5 Reactive, isolation, observe, html, …\nGarder la même application et\n\najouter un actionButton combiné à un isolate pour mettre à jour l’application uniquement lorsque l’utilisateur clique sur le bouton.\nUtiliser observeEvent pour forcer l’apparition de l’histogramme lorsqu’on met à jour l’application. On pourra utiliser\n\n# think to add  \"session\" \nshinyServer(function(input, output, session))\n\n# an id \ntabsetPanel(id = \"viz\",\n            tabPanel(\"Histogram\",...,))\n\n# and finaly\nobserveEvent(input$go, {\n  updateTabsetPanel(session, inputId = \"viz\",\n                    selected = \"Histogram\")})\n\nUtiliser reactive pour stocker la variable sélectionnée\n\n# Example of reactive\ndata &lt;- reactive({\n  ...\n})\n\noutput$plot &lt;- renderPlot({\n  x &lt;- data()\n  ...\n})\n\nAjouter un titre en bleu sur le jeu de données. On pourra utiliser h1\n\nh1(\"Dataset\", style = \"color : #0099ff;text-align:center\")\n\nAjouter un troisième onglet pour présenter un résumé de votre Université, avec un logo de l’institution et un lien vers son site web.\nPour aller plus loin : changer le thème de l’application avec un fichier de style .css. On pourra par exemple utiliser bootswatch http://bootswatch.com/3.\n\nL’application finale pourra ressembler à\n\n\n\n\nElle est également disponible ici https://plus-loin-rouviere-shiny-2.apps.math.cnrs.fr/."
  },
  {
    "objectID": "07-shiny.html#exercices-complémentaires",
    "href": "07-shiny.html#exercices-complémentaires",
    "title": "9  Applications web avec Shiny",
    "section": "9.6 Exercices complémentaires",
    "text": "9.6 Exercices complémentaires\n\nExercice 9.4 (Une application simple descriptive) On considère le jeu de données SAheart du package bestglm.\n\nA l’aide du package rAmCharts, représenter les histogrammes des variables quantitatives du jeu de données ainsi que les boxplots de ces variables en fonction de la variable chd.\n\nlibrary(bestglm)\nlibrary(rAmCharts)\namHist(SAheart$adiposity,freq=FALSE,xlab=\"adiposity\")\n\n\n\n\n\n\namBoxplot(adiposity~chd,data=SAheart)\n\n\n\n\n\nCréer une application shiny avec shinydashboard qui permette de\n\nchoisir une variable parmi les variables quantitatives du jeu de données. On pourra utiliser radioButtons avec l’argument\n\nchoices=names(SAheart)[sapply(SAheart,class)==\"numeric\"]\n\nvisualiser l’histogramme, puis le boxplot en fonction de chd de la variable sélectionnée. Ces graphiques devront être faits avec rAmCharts. On pourra utiliser amChartsOutput. L’application demandée pourra ressembler à\n\n\n\n\nElle est disponible ici https://lrouviere.shinyapps.io/DESC_APP.\n\n\n\n\nExercice 9.5 (Stations velib à Rennes) Réaliser une application qui permette de visualiser les stations velib à Rennes. Elle pourra être du même genre que celle-ci :\n\n\n\n\nOn peut avoir une meilleure vision ici : https://lrouviere.shinyapps.io/velib/. On récupérera les données sur le site de Rennes métropole : https://data.rennesmetropole.fr/explore/dataset/etat-des-stations-le-velo-star-en-temps-reel/export/"
  },
  {
    "objectID": "08-estimation.html",
    "href": "08-estimation.html",
    "title": "10  Estimation et intervalles de confiance",
    "section": "",
    "text": "11 Vers des modèles plus complexes\nOn présente un cas d’étude dans cette partie. On se pose le problème d’étudier l’impact de l’activité sportive combiné à un régime sur le cancer. Pour se faire, on étudie l’évolution de tumeurs cancéreuses chez des souris réparties en 4 groupes :\nOn importe les données\n(data1 &lt;- readxl::read_excel(\"data/donnees_tum.xlsx\", sheet = \"Tumeur\",skip=1))\n\n# A tibble: 53 × 20\n   Id        J5    J8   J12   J14   J16   J20   J22    J26    J28    J30    J34\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 CTL 1  11.3  10.5  11.1  10.4  11.9  19.8  21.8   30.1   33.1   43.3   85.5 \n 2 CTL 2   0     5.29  5.83  5.22  5.77  4.47  4.79   5.06   5.13   5.00   6.21\n 3 CTL 3  10.3  16.8  11.4  13.1  13.4  22.9  25.1   24.3   42.1   57.2  104.  \n 4 CTL 4   6.00 11.4  25.5  32.0  34.3  69.2  85.2  137.   187.   212.   278.  \n 5 CTL 5  15.9  11.6  14.1  11.0  18.0  19.5  21.0   47.4   82.1   81.7  156.  \n 6 CTL 6   0     0     3.86  3.65 10.1  14.1  18.8   27.0   46.2   54.2   75.0 \n 7 CTL 7  10.8  10.9  19.0  16.9  22.2  31.1  33.9   34.4   62.4   79.3  152.  \n 8 CTL 8   9.00 13.3  16.2  15.4  16.4  22.6  22.0   16.9   15.5   17.8   29.4 \n 9 CTL 9   3.75 11.2  10.5  11.3  30.3  52.5  59.4   82.1   97.7  126.   218.  \n10 CTL 10 14.1  16.3  19.4  23.1  26.7  25.3  38.8   38.2   44.5   54.5   89.5 \n# ℹ 43 more rows\n# ℹ 8 more variables: J36 &lt;dbl&gt;, J40 &lt;dbl&gt;, J42 &lt;dbl&gt;, J44 &lt;dbl&gt;, J48 &lt;dbl&gt;,\n#   J50 &lt;dbl&gt;, J54 &lt;dbl&gt;, J56 &lt;dbl&gt;\n\ndim(data1)\n\n[1] 53 20\net on les met sous un format long :\ndata2 &lt;- data1 |&gt; pivot_longer(-c(Id),names_to=\"Day\",values_to = \"Volume\") |&gt;\n  mutate(day_num=as.numeric(str_remove(Day,'[J]')),\n         groupe=fct(str_remove(Id,'[0-9]+')),\n         Day=fct(Day))\ndata2\n\n# A tibble: 1,007 × 5\n   Id    Day   Volume day_num groupe\n   &lt;chr&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; \n 1 CTL 1 J5      11.3       5 \"CTL \"\n 2 CTL 1 J8      10.5       8 \"CTL \"\n 3 CTL 1 J12     11.1      12 \"CTL \"\n 4 CTL 1 J14     10.4      14 \"CTL \"\n 5 CTL 1 J16     11.9      16 \"CTL \"\n 6 CTL 1 J20     19.8      20 \"CTL \"\n 7 CTL 1 J22     21.8      22 \"CTL \"\n 8 CTL 1 J26     30.1      26 \"CTL \"\n 9 CTL 1 J28     33.1      28 \"CTL \"\n10 CTL 1 J30     43.3      30 \"CTL \"\n# ℹ 997 more rows"
  },
  {
    "objectID": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "href": "08-estimation.html#générer-des-observations-selon-des-lois-de-probabilités",
    "title": "10  Estimation et intervalles de confiance",
    "section": "10.1 Générer des observations selon des lois de probabilités",
    "text": "10.1 Générer des observations selon des lois de probabilités\nR étant un logiciel de statistique, il est bien entendu possible de\n\nvisualiser\ncalculer des indicateurs (quantiles, probabilités…)\ngénérer des observations\n\npour toutes les lois classiques de probabilités. Chaque loi va être identifiée par une chaîne de caractères :\n\n\n\nLoi\nChaîne\n\n\n\n\nBinomiale\nbinom\n\n\nPoisson\npois\n\n\nUniforme\nunif\n\n\nExponentielle\nexp\n\n\nNormale\nnorm\n\n\n\nUn préfixe permettra de spécifier l’action que l’on souhaite effectuer sur la loi :\n\nd : calculer la densité pour une loi continue ou la fonction de masse pour une loi discrète\nq : calculer les quantiles\nr : générer des observations.\n\nOn pourra par exemple :\n\nCalculer la densité de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\ndnorm(c(-1,0,1),mean=0,sd=1)\n\n[1] 0.2419707 0.3989423 0.2419707\n\n\nCalculer les quantiles d’ordre 0.05, 0.5 et 0.95 de la loi \\(\\mathcal N(0,1)\\) en -1,0,1 avec\n\nqnorm(c(0.05,0.5,0.95),mean=0,sd=1)\n\n[1] -1.644854  0.000000  1.644854\n\n\nGénérer 10 observations selon une loi \\(\\mathcal N(0,1)\\) avec\n\nrnorm(10,mean=0,sd=1)\n\n [1]  1.51531352  1.00777559 -0.13460092  0.25474220  0.07091221  1.98237820\n [7]  1.00292268  1.92731321  0.82480344 -0.72255034\n\n\n\n\nExercice 10.1 (Loi binomiale) On étudie les fonctions R associées à la loi binomiale.\n\nSoit \\(X\\) un variable de loi binomiale \\(B(20,0.6)\\). Calculer la probabilité que \\(X\\) soit égale à 1,5,10,15.\n\ndbinom(c(1,5,10,15),size=20,prob=0.6)\n\n[1] 3.298535e-07 1.294494e-03 1.171416e-01 7.464702e-02\n\n\nPour la même loi calculer la probabilités : \\[\\mathbf P(X\\leq 13),\\quad\\mathbf P(X&gt;13),\\quad \\mathbf P(X\\geq 13)\\quad\\text{et}\\quad \\mathbf P(X\\in[8,15]).\\]\n\nPour la première il suffit d’utiliser pbinom :\n\npbinom(13,size=20,prob=0.6)\n\n[1] 0.7499893\n\n\nOn remarque ensuite que \\[\\mathbf P(X&gt;13)=1-\\mathbf P(X\\leq 13)\\quad\\text{et}\\quad\\mathbf P(X\\geq 13)=\\mathbf P(X&gt;13)+\\mathbf P(X=13)\\]\ndonc\n\n1-pbinom(13,size=20,prob=0.6)\n\n[1] 0.2500107\n\n1-pbinom(13,size=20,prob=0.6)+dbinom(13,size=20,prob=0.6)\n\n[1] 0.4158929\n\n\nPour la dernière, on utilise \\[\\mathbf P(X\\in[8,15]=\\mathbf P(X\\leq 15)-\\mathbf P(X\\leq 8)+\\mathbf P(X=8)\\]\n\npbinom(15,size=20,prob=0.6)-pbinom(8,size=20,prob=0.6)+dbinom(8,size=20,prob=0.6)\n\n[1] 0.9280191\n\n\nOn aurait aussi pu faire\n\nsum(dbinom(8:15,size=20,prob=0.6))\n\n[1] 0.9280191\n\n\n\nReprésenter le diagramme en barre associé à la loi \\(B(20,0.6)\\). On pourra utiliser l’argument stat=“identity” dans la fonction geom_bar.\n\nprob &lt;- dbinom(0:20,size=20,prob=0.6)\ndf &lt;- data.frame(x=0:20,prob=prob)\nggplot(df)+aes(x=x,y=prob)+geom_bar(stat=\"identity\",width=0.15)+theme_classic()\n\n\n\n\nGénérer un échantillon de taille 5000 selon la loi \\(B(20,0.6)\\). Tracer le diagramme en barres associé à cet échantillon et comparer le à celui de la question précédente.\n\nX &lt;- rbinom(5000,size=20,prob=0.6)\ndf1 &lt;- data.frame(X=X)\nggplot(df1)+aes(x=X,y=..prop..)+geom_bar(width=0.15)+theme_classic()+xlim(c(0,20))\n\n\n\n\n\nOn peut visualiser les digrammes en barres cote à cote avec\n\n\nprop &lt;- table(X)/5000\nprop1 &lt;- data.frame(X=as.numeric(names(prop)),Freq=as.numeric(prop))\ndf2 &lt;- full_join(df,prop1,by=c(\"x\"=\"X\"))\nnames(df2)[2:3] &lt;- c(\"Theo\",\"Emp\")\ndf2[is.na(df2)] &lt;- 0\ndf3 &lt;- df2 |&gt; pivot_longer(-x,names_to=\"type\",values_to=\"valeur\")\nggplot(df3)+aes(x=x,y=valeur,fill=type)+geom_bar(stat=\"identity\",position='dodge',width=0.25)\n\n\n\n\n\n\n\nExercice 10.2 (Loi normale) On considère ici la loi normale \\(\\mathcal N(\\mu,\\sigma^2)\\).\n\nTracer la densité de la loi \\(\\mathcal N(0,1)\\).\n\ndf &lt;- tibble(x=seq(-3,3,by=0.01),y=dnorm(x))\nggplot(df)+aes(x=x,y=y)+geom_line()\n\n\n\n\nSoit \\(X\\) une variable aléatoire de loi \\(\\mathcal N(2,2^2)\\) (variance 4, écart-type 2). Calculer les probabilités suivantes : \\[\\mathbf P(X=2),\\quad \\mathbf P(X\\leq 2),\\quad \\mathbf P(X&lt;2),\\quad \\mathbf P(X&gt;3).\\]\n\nLa première probabilité est nulle. Les deux suivantes sont égales et valent\n\n\npnorm(2,2,2)\n\n[1] 0.5\n\n\n\nOn obtient la dernière avec\n\n\n1-pnorm(3,2,2)\n\n[1] 0.3085375\n\n\nGénérer un échantillon de taille 5000 selon la loi \\(\\mathcal N(0,1)\\). Tracer l’histogramme associé à cet échantillon et comparer le à la densité tracée à la question précédente (on pourra superposer les 2 représentations).\n\ndf1 &lt;- data.frame(X=rnorm(5000))\nggplot(df1)+aes(x=X,y=..density..)+geom_histogram()+theme_classic()+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=1)"
  },
  {
    "objectID": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "href": "08-estimation.html#une-étude-numérique-de-la-moyenne-empirique.",
    "title": "10  Estimation et intervalles de confiance",
    "section": "10.2 Une étude numérique de la moyenne empirique.",
    "text": "10.2 Une étude numérique de la moyenne empirique.\nOn considère un échantillon de \\(x_1,\\dots,x_n\\) i.i.d de loi uniforme sur \\([a,b]\\) avec \\(a\\) et \\(b\\) supposés inconnus. Le problème est d’estimer l’espérance de cette loi uniforme \\[\\mathbf E[X]=\\frac{a+b}{2}.\\]\nUn estimateur naturel est la moyenne empirique \\[\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i\\] Remarquons déjà que la moyenne empirique dépend des observations \\(x_1,\\dots,x_n\\) : la moyenne va donc changer lorsque les observations changent.\n\n10.2.1 Exemple\nPour fixer les idées, on suppose dans cette partie que \\(a=0\\) et \\(b=1\\). L’espérance à estimer vaut donc 0.5 (on peut faire comme si on le la connaissait pas.)\nOn considère deux échantillons de taille 20 générées selon une loi uniforme entre 0 et 1 :\n\nech1 &lt;- runif(20)\nech2 &lt;- runif(20)\ndf &lt;- data.frame(ech1,ech2)\n\nLes moyennes empiriques pour ces deux échantillons sont différentes :\n\ndf |&gt; summarise_all(mean)\n\n       ech1      ech2\n1 0.5020276 0.5039101\n\n\nLa moyenne empirique peut-être considérée comme une variable aléatoire : elle va donc posséder une loi de probabilité, une espérance… Si on considère l’exemple précédent, on sent bien que la distribution de la moyenne empirique doit\n\nse répartir autours de 0.5 (qui est la valeur à estimer).\nêtre de plus en plus concentrée autours de 0.5 lorsque le nombre d’observations \\(n\\) augmente.\n\nOn peut visualiser ce fait en considérant un grand nombre d’échantillon et en regardant comment se comporte les valeurs moyennes de chaque échantillon. Pour cela on\n\ngénère un nombre \\(B\\) (grand) d’échantillons de taille \\(n=20\\) selon une loi uniforme entre 0 et 1.\n\nset.seed(1234)\ndf &lt;- matrix(runif(20*5000),nrow=20) |&gt; as.data.frame()\n\ncalcule les moyennes obtenues pour chaque échantillon\n\nmoy &lt;- df |&gt; summarize_all(mean)\nhead(t(moy))\n\n        [,1]\nV1 0.4719301\nV2 0.4449401\nV3 0.4833523\nV4 0.3740339\nV5 0.4132300\nV6 0.3734092\n\n\nvisualise la distribution de la moyenne de chaque échantillon (en traçant l’histogramme de ces valeurs par exemple).\n\nmoy &lt;- data.frame(M=t(moy))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+theme_classic()\n\n\n\n\n\nOn voit que cette distribution semble se comporter comme une distribution gaussienne autours de la vraie valeur (0.5). Le théorème central limite confirme (et surtout prouve) ce constat. En effet, le théorème central limite nous dit que cette moyenne \\(\\bar x_n\\) vérifie \\[\\sqrt{n}\\frac{\\bar x_n-\\mu}{\\sigma}\\to \\mathcal N(0,1)\\] avec \\(\\mu=0.5\\) et \\(\\sigma=1/\\sqrt{12}\\) ici. On a donc \\[\\sqrt{n}\\frac{\\bar X_n-0.5}{1/\\sqrt{12}}\\to \\mathcal N(0,1)\\] Ce qui signifie qu’on peut approcher la loi de \\(\\bar X_n\\) par la loi \\(\\mathcal N(0.5,1/(12n))\\) avec \\(n=20\\). On le retrouve sur notre exemple en supperposant cette distribution gaussienne sur l’histogramme\n\nx &lt;- seq(0.25,0.75,by=0.001)\ndf &lt;- data.frame(x=x,y=dnorm(x,0.5,1/(sqrt(12*20))))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=2)+xlab(\"x\")\n\n\n\n\n\nExercice 10.3 (Théorème central limite) Faire le même travail pour des tailles d’échantillon de 50, 100 et 500. Interpréter.\n\ndf1 &lt;- matrix(runif(20*5000),nrow=20) \ndf2 &lt;- matrix(runif(50*5000),nrow=50) \ndf3 &lt;- matrix(runif(100*5000),nrow=100) \ndf4 &lt;- matrix(runif(500*5000),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n                  n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"))+theme_classic()\n\n\n\n\n\nOn remarque que :\n\ndans tous les cas, la distribution de la moyenne empirique semble être gaussienne et centrée en 0.5 (qui est la valeur à estimer).\nla dispersion augmente lorsque le nombre d’observations \\(n\\) diminue (moins précis).\n\n\n\n\nExercice 10.4 (Théorème central limite (toujours)) Faire le même exercice pour une loi gaussienne \\(\\mathcal N(1,2)\\) et une loi de Bernoulli \\(\\mathcal B(0.6)\\).\n\nPour la loi \\(\\mathcal N(1,2)\\)\n\ndf1 &lt;- matrix(rnorm(20*5000,1,2),nrow=20) \ndf2 &lt;- matrix(rnorm(50*5000,1,2),nrow=50) \ndf3 &lt;- matrix(rnorm(100*5000,1,2),nrow=100) \ndf4 &lt;- matrix(rnorm(500*5000,1,2),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n\n\n\n\nPour la \\(\\mathcal B(0.6)\\)\n\ndf1 &lt;- matrix(rbinom(20*50000,1,0.6),nrow=20) \ndf2 &lt;- matrix(rbinom(50*50000,1,0.6),nrow=50) \ndf3 &lt;- matrix(rbinom(100*50000,1,0.6),nrow=100) \ndf4 &lt;- matrix(rbinom(500*50000,1,0.6),nrow=500)\ndf &lt;- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 &lt;- df |&gt; gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=30)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n\n\n\n\nDans tous ces cas, on retrouve bien que la moyenne empirique a une distribution gaussienne autours de la valeur à estimer (l’espérance). La dispersion dépend de :\n\nla dispersion des observations (de la loi de \\(x_i\\)) ;\ndu nombre d’observations.\n\nLa moyenne empirique est donc d’autant plus précise que la variance des observations est petite et que le nombre d’observations est grand. Le théorème central limite permet de quantifier tout ça et donc de déduire des intervalles de confiance et de faire des tests…"
  },
  {
    "objectID": "08-estimation.html#intervalles-de-confiance",
    "href": "08-estimation.html#intervalles-de-confiance",
    "title": "10  Estimation et intervalles de confiance",
    "section": "10.3 Intervalles de confiance",
    "text": "10.3 Intervalles de confiance\nOn cherche ici à illustrer numériquement le niveau d’un intervalle de confiance. On rappelle que \\([A,B]\\) est un IC de niveau \\(1-\\alpha\\) pour un paramètre \\(\\theta\\) si \\[P(\\theta\\in[A,B])=1-\\alpha.\\]\n\nExercice 10.5 (IC pour l’espérance d’une gaussienne) On fixe ici le niveau à 0.95 (\\(\\alpha=0.05\\)). On considère \\(n\\) observations \\(x_1,\\dots,x_n\\) i.i.d de loi \\(\\mathcal N(\\mu,1)\\) et on cherche un intervalle de confiance pour \\(\\mu\\).\n\nGénérer \\(n=100\\) observations i.i.d. selon la loi \\(\\mathcal N(\\mu,1)\\) avec \\(\\mu=1\\).\n\nech &lt;- rnorm(100,1,1)\n\nCalculer un intervalle de confiance pour \\(\\mu\\) de niveau 0.95.\n\nt.test(ech)$conf.int\n\n[1] 0.8038101 1.2314117\nattr(,\"conf.level\")\n[1] 0.95\n\n\nSelon-vous, peut-on dire que la probabilité que \\(\\mu\\) appartienne à l’intervalle trouvé est de 0.95 ? Si non, comment peut-on interpréter cette formule.\n\nNon. Dans notre cas, \\(\\mu\\) (qui vaut 1) appartient à l’intervalle trouvé. Dans la vraie vie, \\(\\mu\\) est inconnu. Ce que la formule nous dit, c’est que si nos données sont issues d’un loi \\(\\mathcal N(\\mu,\\sigma^2)\\), on a une probabilité de 0.95 que \\(\\mu\\) appartienne à l’intervalle trouvé. Donc si on génère un très grand nombre d’échantillon i.i.d selon la loi \\(\\mathcal N(\\mu,\\sigma^2)\\), alors dans 95% des cas, la vraie valeur de \\(\\mu\\) appartiendra à l’intervalle trouvé. C’est ce qu’on propose de vérifier dans les questions suivantes.\n\nGénérer 5000 échantillons i.i.d. de loi \\(\\mathcal N(1,1)\\) de tailles 100. On pourra mettre le tout dans une matrice de dimension \\(5000\\times 100\\).\n\nmu &lt;- 1\nn &lt;- 100\nB &lt;- 5000\nX &lt;- matrix(rnorm(n*B,mean=mu),nrow=B)\n\nCalculer un intervalle de confiance de niveau 0.95 pour chacun des 5000 échantillons. On pourra utiliser une boucle for ou la fonction apply.\n\nb1 &lt;- apply(X,1, function(x) t.test(x)$conf.int[1:2])\n\nSur les 5000 intervalles obtenus, calculer le nombre de fois où la vraie valeur de \\(\\mu\\) (en l’occcurence ici 1) se trouve à l’intérieur de l’intervalle.\n\nb2 &lt;- as.data.frame(t(b1))\nb2 |&gt; mutate(test=mu&gt;V1 & mu&lt;V2) |&gt; summarize(mean(test))\n\n  mean(test)\n1     0.9494\n\n\nRefaire les questions 5-6-7 avec des IC de niveau 0.90.\n\nc1 &lt;- apply(X,1, function(x) t.test(x,conf.level=0.90)$conf.int[1:2])\nc2 &lt;- as.data.frame(t(c1))\nc2 |&gt; mutate(test=mu&gt;V1 & mu&lt;V2) |&gt; summarize(mean(test))\n\n  mean(test)\n1      0.898\n\n\n\n\n\nExercice 10.6 (IC pour les iris de Fisher) On considère les données sur les iris de Fisher. Construire un intervalle de confiance de niveau 90% pour les paramètres suivants :\n\nLa longueur de Pétales moyenne\n\nt.test(iris$Petal.Length,conf.level=0.90)$conf.int\n\n[1] 3.519434 3.996566\nattr(,\"conf.level\")\n[1] 0.9\n\n\nLa largeur de Sépales moyenne de l’espèce Setosa\n\nsep_set &lt;- iris |&gt; filter(Species==\"setosa\") |&gt; select(Sepal.Width) \nt.test(sep_set,conf.level=0.90)$conf.int\n\n[1] 3.338124 3.517876\nattr(,\"conf.level\")\n[1] 0.9\n\n#ou\niris |&gt; filter(Species==\"setosa\") |&gt; \n  select(Sepal.Width) |&gt; t.test(conf.level=0.9)\n\n\n    One Sample t-test\n\ndata:  select(filter(iris, Species == \"setosa\"), Sepal.Width)\nt = 63.946, df = 49, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n90 percent confidence interval:\n 3.338124 3.517876\nsample estimates:\nmean of x \n    3.428 \n\n\nLa largeur de Sépales moyenne des espèces Versicolor et Virginica\n\nsep_vervin &lt;- iris |&gt; filter(Species==\"versicolor\" | Species ==\"virginica\") |&gt; select(Sepal.Width) \nt.test(sep_vervin,conf.level=0.90)$conf.int\n\n[1] 2.81675 2.92725\nattr(,\"conf.level\")\n[1] 0.9\n\n\n\n\n\nExercice 10.7 (IC pour une proportion) On considère \\(x_1,\\dots,x_n\\) un échantillon i.i.d issu d’une loi de Bernoulli de paramètre \\(p\\in[0,1]\\) inconnu.\n\nProposer un estimateur \\(\\widehat p\\) pour \\(p\\).\n\nOn peut prendre \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\]\n\nA l’aide du TCL, obtenir la loi asymptotique de \\(\\hat p\\).\n\nOn a d’après la TCL\n\\[\\sqrt{n}\\frac{\\widehat{p}-p}{\\sqrt{p(1-p)}}\\stackrel{\\mathcal L}{\\to}\\mathcal N(0,1)\\]\n\nEn déduire un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(p\\).\n\nOn déduit que \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right].\\]\nest un IC de niveau \\(1-\\alpha\\).\n\nQue pouvez-vous reprocher à l’intervalle proposé à la question précédente ?\n\nL’IC proposé dépend de \\(p\\) qui est inconnu ! Il ne sera donc pas calculable en pratique !\n\nProposer une solution.\n\nUn solution classique consiste à remplacer le paramètre \\(p\\) inconnu par son estimateur \\(\\widehat p\\). On obtient ainsi l’IC \\[\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}\\right].\\]\n\n\n\n\nExercice 10.8 (IC pour une proportion (suite)) Afin de tenter de deviner qui va gagner une élection entre deux candidats \\(A\\) et \\(B\\) on effectue un sondage. On demande à 100 personnes pour qui elles vont voter. Les résultats sont reportés dans le vecteur suivant.\n\nset.seed(12345)\nres &lt;- rbinom(100,1,0.52)\n\nOn désigne par \\(p\\) la propotion (inconnue) d’électeurs qui vont voter pour \\(A\\).\n\nProposer et calculer un estimateur de \\(p\\).\n\nOn peut prendre la moyenne empirique \\[\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.\\] On la calcule avec\n\n\nphat &lt;- mean(res)\nphat\n\n[1] 0.54\n\n\nQue pouvez-vous conclure a priori.\n\nIl semble que \\(A\\) va remporter l’élection.\n\nEn vous basant sur l’exercice précédent, calculer un intervalle de confiance de niveau 95% pour \\(p\\).\n\nOn le calcule avec\n\n\nn &lt;- length(res)\nbinf &lt;- phat-qnorm(0.975)*sqrt(phat*(1-phat)/n)\nbsup &lt;- phat+qnorm(0.975)*sqrt(phat*(1-phat)/n)\nc(binf,bsup)\n\n[1] 0.4423159 0.6376841\n\n\nEst-ce que l’intervalle obtenu conforte votre conclusion de la question 2 ?\n\nNon, en effet 0.5 se trouve dans l’intervalle de confiance !\n\nCalculer un intervalle de confiance pour \\(p\\) à l’aide de la fonction prop.test.\n\nprop.test(sum(res),n)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  sum(res) out of n, null probability 0.5\nX-squared = 0.49, df = 1, p-value = 0.4839\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4377639 0.6391280\nsample estimates:\n   p \n0.54 \n\n\n\nOn remarque que l’IC obtenu ne correspond pas exactement à celui que nous avons calculé à la question 3. La fonction prop.test utilise une solution plus pertinente que de remplacer \\(p\\) par son estimateur. La correction utilisée dans prop.test est plus préciser, il est recommandé d’utiliser celle là.\n\n\n\n\nExercice 10.9 (Comparaison de moyennes) Pour le jeu de données decathlon disponible ici\n\nlibrary(FactoMineR)\ndata(decathlon)\n\non souhaite comparer les performances au 100m en fonction de la compétition (Decastar vs JO).\n\nCalculer un intervalle de confiance de niveau 95% pour la vitesse moyenne au 100m au Decastar.\n\nperf.D &lt;- decathlon |&gt; filter(Competition==\"Decastar\") |&gt; select(`100m`)\nt.test(perf.D)\n\n\n    One Sample t-test\n\ndata:  perf.D\nt = 163.64, df = 12, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 11.02659 11.32418\nsample estimates:\nmean of x \n 11.17538 \n\n\nMême question pour les jeux olympiques.\n\nperf.JO &lt;- decathlon |&gt; filter(Competition==\"OlympicG\") |&gt; select(`100m`)\nt.test(perf.JO)\n\n\n    One Sample t-test\n\ndata:  perf.JO\nt = 250.02, df = 27, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 10.82613 11.00530\nsample estimates:\nmean of x \n 10.91571 \n\n\nPouvez-vous conclure sur la question posée ? Si non, que faire ?\n\nIl n’est pas possible de conclure. La bonne approche consiste à calculer un intervalle de confiance sur la différence moyenne des performances au 100m entre les deux compétitions et de regarder si 0 se situe dans l’intervalle.\nOn obtient l’intervalle avec\n\n\nt.test(perf.D,perf.JO)\n\n\n    Welch Two Sample t-test\n\ndata:  perf.D and perf.JO\nt = 3.2037, df = 22.168, p-value = 0.00407\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.09164794 0.42769272\nsample estimates:\nmean of x mean of y \n 11.17538  10.91571 \n\n\n\n0 n’étant pas dans l’intervalle, on conclut que les performances sont différentes. On verra par la suite que les tests d’hypothèses permettent de traiter ce genre de questions de façons plus efficace."
  },
  {
    "objectID": "08-estimation.html#étude-descriptive-et-visualisation",
    "href": "08-estimation.html#étude-descriptive-et-visualisation",
    "title": "10  Estimation et intervalles de confiance",
    "section": "11.1 Étude descriptive et visualisation",
    "text": "11.1 Étude descriptive et visualisation\nOn commence par visualiser l’évolution de la tumeur en fonction du groupe à l’aide d’un boxplot :\n\nggplot(data2)+aes(x=as.factor(day_num),y=Volume,color=groupe)+\n  geom_boxplot()+xlab(\"Day\")\n\n\n\n\nIl semble que les évolutions soient différentes, notamment pour le groupe contrôle.\nOn effectue maintenant une Anova pour tester l’effet groupe. Les répétitions portant sur le temps (et non sur les groupes), on fait l’ANOVA à deux facteurs avec (voir https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-m-modmixt7-mesrepet.pdf)\n\ngroupe comme effet inter\nDay comme effet intra\n\n\nlibrary(rstatix)\nres.aov &lt;- anova_test(\n  data = data2, dv = Volume, wid = Id,\n  between = groupe,\n  within = Day\n)\nget_anova_table(res.aov)\n\nANOVA Table (type III tests)\n\n      Effect  DFn   DFd      F        p p&lt;.05   ges\n1     groupe 3.00 45.00  6.123 1.00e-03     * 0.155\n2        Day 1.22 54.76 75.359 4.41e-13     * 0.480\n3 groupe:Day 3.65 54.76  7.100 1.72e-04     * 0.207\n\n\nL’interaction est significative.\nOn peut aller un peu plus loin avec les tests post hoc. Par exemple, pour l’effet groupe à chaque pas de temps :\n\none.way &lt;- data2 |&gt; \n  group_by(day_num) |&gt;\n  anova_test(dv = Volume, wid = Id, between = groupe) |&gt;\n  get_anova_table() |&gt;\n  adjust_pvalue(method = \"bonferroni\")\none.way |&gt; as_tibble() |&gt; \n  arrange(day_num) |&gt; DT::datatable() \n\n\n\n\n\n\nLe groupe devient “de plus en plus significatif” lorsque le temps augmente (y compris avec la correction de Bonferonni).\nOn regarde maintenant les comparaisons par paires :\n\npwc &lt;- data2 |&gt;\n  group_by(Day) |&gt;\n  pairwise_t_test(\n    Volume ~ groupe,\n    p.adjust.method = \"bonferroni\"\n  )\nDT::datatable(pwc)\n\n\n\n\n\npwc |&gt; filter(p.signif!=\"ns\" | p.adj.signif!=\"ns\") |&gt; arrange(p)\n\n# A tibble: 34 × 10\n   Day   .y.    group1 group2     n1    n2       p p.signif   p.adj p.adj.signif\n   &lt;fct&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n 1 J56   Volume \"CTL \" \"EPA E…    13    14 1.83e-4 ***      0.0011  **          \n 2 J56   Volume \"CTL \" \"EPA \"     13    13 2.22e-4 ***      0.00133 **          \n 3 J56   Volume \"CTL \" \"ET \"      13    13 3.57e-4 ***      0.00214 **          \n 4 J50   Volume \"CTL \" \"EPA E…    13    14 3.71e-4 ***      0.00222 **          \n 5 J54   Volume \"CTL \" \"EPA \"     13    13 3.71e-4 ***      0.00223 **          \n 6 J50   Volume \"CTL \" \"EPA \"     13    13 4   e-4 ***      0.0024  **          \n 7 J54   Volume \"CTL \" \"EPA E…    13    14 5.2 e-4 ***      0.00312 **          \n 8 J54   Volume \"CTL \" \"ET \"      13    13 6.59e-4 ***      0.00395 **          \n 9 J48   Volume \"CTL \" \"EPA E…    13    14 8.99e-4 ***      0.00539 **          \n10 J50   Volume \"CTL \" \"ET \"      13    13 1.08e-3 **       0.00651 **          \n# ℹ 24 more rows\n\n\nLe groupe CTL se retrouve fréquemment dans les comparaisons significatives."
  },
  {
    "objectID": "08-estimation.html#modèle-mixte",
    "href": "08-estimation.html#modèle-mixte",
    "title": "10  Estimation et intervalles de confiance",
    "section": "11.2 Modèle mixte",
    "text": "11.2 Modèle mixte\nLes données étant répétées dans le temps, on ne peut pas utiliser un modèle linéaire classique. Il faut dans ce cas entraîner un modèle mixte qui va pouvoir prendre en compte les effets individuels :\nAprès plusieurs essais et comparaisons de modèle, on retient le modèle avec\n\ncomme effet fixe : le temps au carré et l’interaction temps au carré vs groupe.\ncomme effet aléatoire : la constante et le temps au carré.\n\n\nlibrary(nlme)\nm1 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          data=data2,na.action=na.omit)\n\nAnova(m1,type=3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Volume\n                     Chisq Df Pr(&gt;Chisq)    \n(Intercept)         17.050  1  3.641e-05 ***\nI(day_num^2)        81.249  1  &lt; 2.2e-16 ***\nI(day_num^2):groupe 20.854  3  0.0001129 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn retrouve bien que l’interaction est significative. Au niveau des paramètres du modèle on a :\n\nsummary(m1)\n\nLinear mixed-effects model fit by REML\n  Data: data2 \n       AIC      BIC    logLik\n  10249.63 10288.87 -5116.813\n\nRandom effects:\n Formula: ~1 + I(day_num^2) | Id\n Structure: Diagonal\n        (Intercept) I(day_num^2) Residual\nStdDev:    27.17808   0.06523892 32.77535\n\nFixed effects:  Volume ~ 1 + I(day_num^2) + I(day_num^2):(groupe) \n                                Value Std.Error  DF   t-value p-value\n(Intercept)                -16.831664  4.076271 946 -4.129182   0e+00\nI(day_num^2)                 0.164154  0.018211 946  9.013850   0e+00\nI(day_num^2):groupeEPA      -0.098116  0.025751 946 -3.810174   1e-04\nI(day_num^2):groupeET       -0.092033  0.025751 946 -3.573908   4e-04\nI(day_num^2):groupeEPA ET   -0.096512  0.025287 946 -3.816676   1e-04\n Correlation: \n                           (Intr) I(d_^2) I(_^2):EP I(_^2):ET\nI(day_num^2)               -0.018                            \nI(day_num^2):groupeEPA      0.000 -0.707                     \nI(day_num^2):groupeET       0.000 -0.707   0.500             \nI(day_num^2):groupeEPA ET   0.000 -0.720   0.509     0.509   \n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-5.702141384 -0.381625266  0.002515069  0.372061286  8.789202686 \n\nNumber of Observations: 1003\nNumber of Groups: 53 \n\n\nTous les coefficients de l’interaction sont significatifs et négatifs. Cela signifie que, le volume augmente moins vite avec de l’entraînement et du régime. On peut regarder ce qui se passe en changeant le groupe de référence :\n\ngroupe EPA :\n\nm2 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=2)),\n          data=data2,na.action=na.omit)\nsummary(m2)$tTable |&gt; round(4)\n\n                              Value Std.Error  DF t-value p-value\n(Intercept)                -16.8317    4.0763 946 -4.1292  0.0000\nI(day_num^2)                 0.0660    0.0182 946  3.6261  0.0003\nI(day_num^2):groupeCTL       0.0981    0.0258 946  3.8102  0.0001\nI(day_num^2):groupeET        0.0061    0.0258 946  0.2362  0.8133\nI(day_num^2):groupeEPA ET    0.0016    0.0253 946  0.0634  0.9494\n\n\ngroupe ET :\n\nm3 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=3)),\n          data=data2,na.action=na.omit)\nsummary(m3)$tTable |&gt; round(4)\n\n                              Value Std.Error  DF t-value p-value\n(Intercept)                -16.8317    4.0763 946 -4.1292  0.0000\nI(day_num^2)                 0.0721    0.0182 946  3.9600  0.0001\nI(day_num^2):groupeCTL       0.0920    0.0258 946  3.5739  0.0004\nI(day_num^2):groupeEPA      -0.0061    0.0258 946 -0.2362  0.8133\nI(day_num^2):groupeEPA ET   -0.0045    0.0253 946 -0.1771  0.8595\n\n\ngroupe EPA - ET :\n\nm4 &lt;- lme(Volume~1+I(day_num^2)+I(day_num^2):(groupe),\n          random=list(Id=pdDiag(~1+I(day_num^2))),\n          contrasts = list(groupe=contr.treatment(levels(data2$groupe),base=4)),\n          data=data2,na.action=na.omit)\nsummary(m4)$tTable |&gt; round(4)\n\n                           Value Std.Error  DF t-value p-value\n(Intercept)             -16.8317    4.0763 946 -4.1292  0.0000\nI(day_num^2)              0.0676    0.0175 946  3.8543  0.0001\nI(day_num^2):groupeCTL    0.0965    0.0253 946  3.8167  0.0001\nI(day_num^2):groupeEPA   -0.0016    0.0253 946 -0.0634  0.9494\nI(day_num^2):groupeET     0.0045    0.0253 946  0.1771  0.8595\n\n\n\nÀ chaque fois le groupe CTL se distingue. Il est difficile d’établir des différences significatives entre les autres groupes. On peut enfin visualiser les effets fixes :\n\naa &lt;- predict(m1,data2,level=0:1)\ndata3 &lt;- data2 |&gt; \n  mutate(prev=aa$predict.Id) |&gt; \n  group_by(groupe,day_num) |&gt; \n  summarize(moy=mean(prev))\nggplot(data3)+aes(x=day_num,y=moy,color=groupe)+geom_line()+geom_point()"
  },
  {
    "objectID": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "href": "09-regression.html#modèle-linéaire-fonctions-lm-et-predict",
    "title": "11  Régression avec R",
    "section": "11.1 Modèle linéaire : fonctions lm et predict",
    "text": "11.1 Modèle linéaire : fonctions lm et predict\n\nExercice 11.1 (Fonctions standards pour le modèle linéaire) On considère le modèle de régression linéaire \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] où \\(X_1,\\dots,X_p\\) sont les variables explicatives, \\(Y\\) la variable à expliquer et \\(\\varepsilon\\) le terme d’erreur. On fixe \\(p=5\\) et on considère les données suivantes :\n\nn &lt;- 1000\np &lt;- 5\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nConstruire un modèle linéaire permettant d’expliquer \\(Y\\) par \\(X_1,\\dots,X_5\\) (utiliser la fonction lm) et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_5\\) (on pourra utiliser les fonctions coef et summary).\n\nmod1 &lt;- lm(Y~.,data=df)\ncoef(mod1)\n\n(Intercept)          X1          X2          X3          X4          X5 \n  0.0228707   1.0111903   1.0000752   1.0034085   1.0071250   0.9962842 \n\nsummary(mod1)\n\n\nCall:\nlm(formula = Y ~ ., data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.44876 -0.33840 -0.00769  0.33308  1.76883 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.02287    0.01543   1.482    0.139    \nX1           1.01119    0.01550  65.258   &lt;2e-16 ***\nX2           1.00008    0.01575  63.479   &lt;2e-16 ***\nX3           1.00341    0.01524  65.829   &lt;2e-16 ***\nX4           1.00712    0.01552  64.908   &lt;2e-16 ***\nX5           0.99628    0.01589  62.702   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4872 on 994 degrees of freedom\nMultiple R-squared:  0.9556,    Adjusted R-squared:  0.9554 \nF-statistic:  4279 on 5 and 994 DF,  p-value: &lt; 2.2e-16\n\n\nOn considère le jeu de données test suivant.\n\nm &lt;- 500\np &lt;- 5\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=5)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nCalculer, pour chaque individu de ce nouveau jeu de données, les prédictions faites par le modèle de la question précédente (utiliser la fonction predict avec l’option newdata).\n\npred &lt;- predict(mod1,newdata=df.test)\nhead(pred)\n\n          1           2           3           4           5           6 \n 0.09630147 -1.25027415 -0.52549286  0.19569041  3.72923032 -5.79419545 \n\n\nCréer un nouveau dataframe qui contiennent les valeurs prédites \\(\\widehat y_i\\) à la question précédente sur une colonne et les valeurs observées \\(y_i\\) du jeu de données df.test sur une autre colonne.\n\npred.df &lt;- data.frame(pred=pred,obs=df.test$Y)\n\nA l’aide du verbe summarize, calculer l’erreur quadratique moyenne (estimée) du modèle linéaire : \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2.\\]\n\npred.df |&gt; summarize(MSE=mean((pred-obs)^2))\n\n        MSE\n1 0.2326355"
  },
  {
    "objectID": "09-regression.html#sélection-de-variables",
    "href": "09-regression.html#sélection-de-variables",
    "title": "11  Régression avec R",
    "section": "11.2 Sélection de variables",
    "text": "11.2 Sélection de variables\n\nExercice 11.2 (Sélection de variables) On considère les données suivantes\n\nn &lt;- 1000\np &lt;- 105\nset.seed(1234)\nX.mat &lt;- matrix(rnorm(n*p),ncol=p)\neps &lt;- rnorm(n,mean = 0,sd=0.5)\ndf &lt;- data.frame(X.mat,eps)\ndf &lt;- df |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\nissues du modèle \\[Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon\\] avec \\(p=105\\). On remarquera que seules les variables \\(X_1,\\dots,X_5\\) sont explicatives.\n\nAjuster un modèle linéaire (fonction lm) sur df et afficher les estimateurs de \\(\\beta_0,\\dots,\\beta_{105}\\).\n\nmod2 &lt;- lm(Y~.,data=df)\nsummary(mod2)$coefficients |&gt; head()\n\n               Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) -0.01307274 0.01660197 -0.787421  4.312441e-01\nX1           0.98461851 0.01656206 59.450240 7.137528e-313\nX2           0.99625236 0.01668382 59.713691 3.032293e-314\nX3           1.01858539 0.01628043 62.565035  0.000000e+00\nX4           1.00691542 0.01643050 61.283315 2.371515e-322\nX5           1.00752931 0.01718708 58.621324 1.561036e-308\n\n\nOn propose d’utiliser une procédure de sélection de variables backward à partir du critère BIC. Effectuer cette procédure à l’aide de la fonction step (on pourra utiliser les options direction=“backward” et k=log(n)). On appellera ce modèle mod.step.\n\nmod.step &lt;- step(mod2,direction=c(\"backward\"),k=log(n),trace=0)\nsummary(mod.step)\n\n\nCall:\nlm(formula = Y ~ X1 + X2 + X3 + X4 + X5 + X29 + X69 + X74, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.63923 -0.34301  0.00179  0.32041  1.45661 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.002413   0.015749  -0.153  0.87828    \nX1           0.992339   0.015807  62.777  &lt; 2e-16 ***\nX2           0.991358   0.016097  61.588  &lt; 2e-16 ***\nX3           1.010115   0.015562  64.907  &lt; 2e-16 ***\nX4           1.006043   0.015830  63.552  &lt; 2e-16 ***\nX5           1.008520   0.016242  62.093  &lt; 2e-16 ***\nX29         -0.043358   0.015158  -2.860  0.00432 ** \nX69          0.042714   0.015292   2.793  0.00532 ** \nX74         -0.043792   0.016118  -2.717  0.00670 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4969 on 991 degrees of freedom\nMultiple R-squared:  0.954, Adjusted R-squared:  0.9537 \nF-statistic:  2571 on 8 and 991 DF,  p-value: &lt; 2.2e-16\n\n\n\nOn a sélectionné un modèle avec 8 variables : les 5 explicatives et 3 variables de bruit.\n\nCalculer les erreurs quadratiques de prévision \\[\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2\\] des deux modèles (le modèle complet et le modèle sélectionné) en utilisant le jeu de données test suivant.\n\nm &lt;- 300\np &lt;- 105\nset.seed(12345)\nX.mat &lt;- matrix(rnorm(m*p),ncol=p)\neps &lt;- rnorm(m,mean = 0,sd=0.5)\ndf.test &lt;- data.frame(X.mat,eps)\ndf.test &lt;- df.test |&gt; mutate(Y=X1+X2+X3+X4+X5+eps) |&gt; select(-eps)\n\n\nOn calcule les prévisions et on les intègre dans un tibble :\n\n\np.full &lt;- predict(mod2,newdata=df.test)\np.step &lt;- predict(mod.step,newdata=df.test)\npred.df &lt;- tibble(full=p.full,step=p.step,obs=df.test$Y)\n\n\nOn en déduit les erreurs quadratiques moyennes :\n\n\npred.df |&gt; summarize(MSE.full=mean((full-obs)^2),MSE.step=mean((step-obs)^2))\n\n# A tibble: 1 × 2\n  MSE.full MSE.step\n     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.300    0.254\n\n#ou\npred.df |&gt; summarize_at(1:2,~(mean((.-obs)^2)))\n\n# A tibble: 1 × 2\n   full  step\n  &lt;dbl&gt; &lt;dbl&gt;\n1 0.300 0.254"
  },
  {
    "objectID": "09-regression.html#régression-logistique-et-arbre",
    "href": "09-regression.html#régression-logistique-et-arbre",
    "title": "11  Régression avec R",
    "section": "11.3 Régression logistique et arbre",
    "text": "11.3 Régression logistique et arbre\n\nExercice 11.3 On considère le jeu de données spam disponible ici\n\nlibrary(kernlab)\ndata(spam)\n\nLe problème est d’expliquer la variable type (un email est un spam ou non) par les 57 autres variables.\n\nSéparer les données en un échantillon d’apprentissage dapp de taille 3000 et un échantillon test dtest de taille 1601. On pourra utiliser la fonction sample.\n\nset.seed(4321)\nperm &lt;- sample(nrow(spam),3000)\ndapp &lt;- spam[perm,]\ndtest &lt;- spam[-perm,]\n\nConstruire un modèle logistique permettant de répondre au problème en utilisant uniquement les données d’apprentissage. On utilisera la fonction glm avec l’option family=\"binomial\".\n\nm.logit &lt;- glm(type~.,data=dapp,family=\"binomial\")\n\nA l’aide de la fonction step, effectuer une sélection backward (ça peut prendre quelques minutes).\n\nm.step &lt;- step(m.logit,direction=\"backward\",trace=0)\n\nA l’aide de la fonction rpart du package rpart, construire un arbre de régression (toujours sur les données d’apprentissage) pour répondre au problème. On utilisera les paramètres par défaut de la fonction.\n\nlibrary(rpart)\narbre &lt;- rpart(type~.,data=dapp)\n\nVisualiser l’arbre construit à l’aide des fonctions rpart.plot et visTree des packages rpart.plot et visNetwork\n\nlibrary(rpart.plot)\nrpart.plot(arbre)\n\n\n\nlibrary(visNetwork)\nvisTree(arbre)\n\n\n\n\n\nPour les 3 modèles construits (logistique, backward et arbre) calculer les prédictions de la variable type pour les individus de l’échantillon dtest. On pourra regrouper ces prévisions dans un data-frame à 3 colonnes.\n\nprev &lt;- data.frame(\n  logit=predict(m.logit,newdata=dtest,type=\"response\") |&gt; round() |&gt; recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n  step=predict(m.step,newdata=dtest,type=\"response\") |&gt; round() |&gt; recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n  arbre=predict(arbre,newdata=dtest,type=\"class\"))\n\nAjouter au data-frame précédent une colonne où on mettra les valeurs observées de la variable à expliquer.\n\nprev1 &lt;- prev |&gt; mutate(obs=dtest$type)\n\nA l’aide de summarize_at calculer les erreurs de classification des 3 modèles.\n\nprev1 |&gt; summarize_at(1:3,~(mean(obs!=.))) |&gt; round(3)\n\n  logit  step arbre\n1  0.07 0.074 0.109\n\n\nReprésenter les courbes ROC et calculer les AUC. On pourra consulter les pages 346 et 347 dans Cornillon et al. (2018) pour le tracé de courbes ROC sur R.\n\nscore &lt;- data.frame(\n  logit=predict(m.logit,newdata=dtest,type=\"response\"),\n  step=predict(m.step,newdata=dtest,type=\"response\"),\n  arbre=predict(arbre,newdata=dtest,type=\"prob\")[,2]) |&gt; \n  mutate(obs=dtest$type) |&gt; \n  pivot_longer(-obs,names_to = \"Methode\",values_to=\"score\")\n\n\nlibrary(plotROC)\nggplot(score)+aes(d=obs,m=score,color=Methode)+geom_roc()+theme_classic()\n\n\n\n\n\nscore |&gt; group_by(Methode) |&gt; \n  summarize(AUC=as.numeric(pROC::auc(obs,score))) |&gt; \n  mutate(AUC=round(AUC,3)) |&gt;\n  arrange(desc(AUC))\n\n# A tibble: 3 × 2\n  Methode   AUC\n  &lt;chr&gt;   &lt;dbl&gt;\n1 logit   0.975\n2 step    0.975\n3 arbre   0.894\n\n\n\n\n\n\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N. Klutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, et B. Thieurmel. 2018. R pour la statistique et la science des données. PUR. https://r-stat-sc-donnees.github.io."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Références",
    "section": "",
    "text": "Barnier, J. 2020. Introduction à r Et Au Tidyverse. https://juba.github.io/tidyverse/index.html.\n\n\nCornillon, P. A., A. Guyader, F. Husson, N. Jégou, J. Josse, N.\nKlutchnikoff, E. Le Pennec, E. Matzner-Løber, L. Rouvière, and B.\nThieurmel. 2018. R Pour La Statistique Et La Science Des\nDonnées. PUR. https://r-stat-sc-donnees.github.io.\n\n\nPebesma, E. 2018. “Simple Features for r: Standardized Support for\nSpatial Vector Data.” The R Journal 10: 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\nWickham, A., and G. Grolemund. 2017. R for Data Science.\nO’Reilly. https://r4ds.had.co.nz."
  }
]