{
  "hash": "425c197833a1999c776d109816ec98ba",
  "result": {
    "markdown": "\n::: {.content-visible when-format=\"html\"}\n::: {.cell}\n\\newcommand{\\prob}{\\mathbf P}\n\\newcommand{\\lt}{<}\n\\newcommand{\\mt}{>}\n:::\n\n```{=html}\n<style>\ndiv.correction {\n  color: black;\n  background-color: #F0F0F0;\n  font-style: normal;\n  /*display: none;*/\n}\n\n.corR {\n  font-style: italic;\n  /*display: none;*/\n}\n</style>\n```\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\\solntrue\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n# Estimation et intervalles de confiance {#estimation}\n\nDans cette partie nous allons construire des échantillons par simulation et nous intéresser à l'étude de la moyenne de ces échantillons.\n\n## Générer des observations selon des lois de probabilités\n\n**R** étant un logiciel de statistique, il est bien entendu possible de\n\n-   visualiser\n-   calculer des indicateurs (quantiles, probabilités...)\n-   générer des observations\n\npour toutes les lois classiques de probabilités. Chaque loi va être identifiée par une chaîne de caractères :\n\n|      Loi      | Chaîne |\n|:-------------:|:------:|\n|   Binomiale   | binom  |\n|    Poisson    |  pois  |\n|   Uniforme    |  unif  |\n| Exponentielle |  exp   |\n|    Normale    |  norm  |\n\nUn préfixe permettra de spécifier l'action que l'on souhaite effectuer sur la loi :\n\n-   **d** : calculer la densité pour une loi continue ou la fonction de masse pour une loi discrète\n-   **q** : calculer les quantiles\n-   **r** : générer des observations.\n\nOn pourra par exemple :\n\n-   Calculer la densité de la loi $\\mathcal N(0,1)$ en -1,0,1 avec\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dnorm(c(-1,0,1),mean=0,sd=1)\n    ## [1] 0.2419707 0.3989423 0.2419707\n    ```\n    :::\n\n\n\n-   Calculer les quantiles d'ordre 0.05, 0.5 et 0.95 de la loi $\\mathcal N(0,1)$ en -1,0,1 avec\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    qnorm(c(0.05,0.5,0.95),mean=0,sd=1)\n    ## [1] -1.644854  0.000000  1.644854\n    ```\n    :::\n\n\n\n-   Générer 10 observations selon une loi $\\mathcal N(0,1)$ avec\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rnorm(10,mean=0,sd=1)\n    ##  [1] -0.46644965 -1.61691555  2.00976392 -1.90421851 -1.04733885 -1.07726806\n    ##  [7]  0.84556263 -0.07825356  1.24893360  0.22277885\n    ```\n    :::\n\n\n\n::: {#exr-exo-loibinomiale name=\"Loi binomiale\"}\nOn étudie les fonctions `R` associées à la loi binomiale.\n\n1.  Soit $X$ un variable de loi binomiale $B(20,0.6)$. Calculer la probabilité que $X$ soit égale à 1,5,10,15.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    dbinom(c(1,5,10,15),size=20,prob=0.6)\n    ## [1] 3.298535e-07 1.294494e-03 1.171416e-01 7.464702e-02\n    ```\n    :::\n\n\n\n2.  Pour la même loi calculer la probabilités : $$\\prob(X\\leq 13),\\quad\\prob(X>13),\\quad \\prob(X\\geq 13)\\quad\\text{et}\\quad \\prob(X\\in[8,15]).$$\n\n    ::: {.corR data-latex=\"\"}\n    Pour la première il suffit d'utiliser **pbinorm** :\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pbinom(13,size=20,prob=0.6)\n    ## [1] 0.7499893\n    ```\n    :::\n\n\n\n    On remarque ensuite que $$\\prob(X\\mt 13)=1-\\prob(X\\leq 13)\\quad\\text{et}\\quad\\prob(X\\geq 13)=\\prob(X\\mt 13)+\\prob(X=13)$$\n\n    donc\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    1-pbinom(13,size=20,prob=0.6)\n    ## [1] 0.2500107\n    1-pbinom(13,size=20,prob=0.6)+dbinom(13,size=20,prob=0.6)\n    ## [1] 0.4158929\n    ```\n    :::\n\n\n\n    Pour la dernière, on utilise $$\\prob(X\\in[8,15]=\\prob(X\\leq 15)-\\prob(X\\leq 8)+\\prob(X=8)$$\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pbinom(15,size=20,prob=0.6)-pbinom(8,size=20,prob=0.6)+dbinom(8,size=20,prob=0.6)\n    ## [1] 0.9280191\n    ```\n    :::\n\n\n\n    On aurait aussi pu faire\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    sum(dbinom(8:15,size=20,prob=0.6))\n    ## [1] 0.9280191\n    ```\n    :::\n\n\n    :::\n\n3.  Représenter le diagramme en barre associé à la loi $B(20,0.6)$. On pourra utiliser l'argument **stat=\"identity\"** dans la fonction **geom_bar**.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prob <- dbinom(0:20,size=20,prob=0.6)\n    df <- data.frame(x=0:20,prob=prob)\n    ggplot(df)+aes(x=x,y=prob)+geom_bar(stat=\"identity\",width=0.15)+theme_classic()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-10-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n\n4.  Générer un échantillon de taille 5000 selon la loi $B(20,0.6)$. Tracer le diagramme en barres associé à cet échantillon et comparer le à celui de la question précédente.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    X <- rbinom(5000,size=20,prob=0.6)\n    df1 <- data.frame(X=X)\n    ggplot(df1)+aes(x=X,y=..prop..)+geom_bar(width=0.15)+theme_classic()+xlim(c(0,20))\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-11-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On peut visualiser les digrammes en barres cote à cote avec\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prop <- table(X)/5000\n    prop1 <- data.frame(X=as.numeric(names(prop)),Freq=as.numeric(prop))\n    df2 <- full_join(df,prop1,by=c(\"x\"=\"X\"))\n    names(df2)[2:3] <- c(\"Theo\",\"Emp\")\n    df2[is.na(df2)] <- 0\n    df3 <- df2 |> pivot_longer(-x,names_to=\"type\",values_to=\"valeur\")\n    ggplot(df3)+aes(x=x,y=valeur,fill=type)+geom_bar(stat=\"identity\",position='dodge',width=0.25)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n:::\n\n::: {#exr-exo-loinormale name=\"Loi normale\"}\nOn considère ici la loi normale $\\mathcal N(\\mu,\\sigma^2)$.\n\n1.  Tracer la densité de la loi $\\mathcal N(0,1)$.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    df <- data.frame(x=seq(-3,3,by=0.01)) |> mutate(y=dnorm(x))\n    ggplot(df)+aes(x=x,y=y)+geom_line()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-13-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n\n2.  Soit $X$ une variable aléatoire de loi $\\mathcal N(2,2^2)$ (variance 4, écart-type 2). Calculer les probabilités suivantes : $$\\prob(X=2),\\quad \\prob(X\\leq 2),\\quad \\prob(X<2),\\quad \\prob(X>3).$$\n\n    ::: {.corR data-latex=\"\"}\n    La première probabilité est nulle. Les deux suivantes sont égales et valent\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pnorm(2,2,2)\n    ## [1] 0.5\n    ```\n    :::\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On obtient la dernière avec\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    1-pnorm(3,2,2)\n    ## [1] 0.3085375\n    ```\n    :::\n\n\n\n3.  Générer un échantillon de taille 5000 selon la loi $\\mathcal N(0,1)$. Tracer l'histogramme associé à cet échantillon et comparer le à la densité tracée à la question précédente (on pourra supperposer les 2 représentations).\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    df1 <- data.frame(X=rnorm(5000))\n    ggplot(df1)+aes(x=X,y=..density..)+geom_histogram()+theme_classic()+\n      geom_line(data=df,aes(x=x,y=y),color=\"red\",size=1)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-16-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n:::\n\n## Une étude numérique de la moyenne empirique.\n\nOn considère un échantillon de $x_1,\\dots,x_n$ i.i.d de loi uniforme sur $[a,b]$ avec $a$ et $b$ supposés inconnus. Le problème est d'estimer l'espérance de cette loi uniforme $$\\mathbf E[X]=\\frac{a+b}{2}.$$\n\nUn estimateur naturel est la moyenne empirique $$\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i$$ Remarquons déjà que la moyenne empirique dépend des observations $x_1,\\dots,x_n$ : la moyenne va donc changer lorsque les observations changent.\n\n### Exemple\n\nPour fixer les idées, on suppose dans cette partie que $a=0$ et $b=1$. L'espérance à estimer vaut donc 0.5 (on peut faire comme si on le la connaissait pas.)\n\nOn considère deux échantillons de taille 20 générées selon une loi uniforme entre 0 et 1 :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nech1 <- runif(20)\nech2 <- runif(20)\ndf <- data.frame(ech1,ech2)\n```\n:::\n\n\n\nLes moyennes empiriques pour ces deux échantillons sont différentes :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> summarise_all(mean)\n##        ech1      ech2\n## 1 0.5446154 0.3468529\n```\n:::\n\n\n\nLa moyenne empirique peut-être considérée comme une **variable aléatoire** : elle va donc posséder une loi de probabilité, une espérance... Si on considère l'exemple précédent, on sent bien que la distribution de la moyenne empirique doit\n\n-   se répartir autours de 0.5 (qui est la valeur à estimer).\n-   être de plus en plus concentrée autours de 0.5 lorsque le nombre d'observations $n$ augmente.\n\nOn peut visualiser ce fait en considérant un grand nombre d'échantillon et en regardant comment se comporte les valeurs moyennes de chaque échantillon. Pour cela on\n\n1.  génère un nombre $B$ (grand) d'échantillons de taille $n=20$ selon une loi uniforme entre 0 et 1.\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    set.seed(1234)\n    df <- matrix(runif(20*5000),nrow=20) |> as.data.frame()\n    ```\n    :::\n\n\n\n2.  calcule les moyennes obtenues pour chaque échantillon\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    moy <- df |> summarize_all(mean)\n    head(t(moy))\n    ##         [,1]\n    ## V1 0.4719301\n    ## V2 0.4449401\n    ## V3 0.4833523\n    ## V4 0.3740339\n    ## V5 0.4132300\n    ## V6 0.3734092\n    ```\n    :::\n\n\n\n3.  visualise la distribution de la moyenne de chaque échantillon (en traçant l'histogramme de ces valeurs par exemple).\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    moy <- data.frame(M=t(moy))\n    ggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+theme_classic()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](08-estimation_files/figure-pdf/unnamed-chunk-21-1.pdf){fig-pos='H'}\n    :::\n    :::\n\n\n\nOn voit que cette distribution semble se comporter comme une **distribution gaussienne** autours de la vraie valeur (0.5). Le théorème central limite confirme (et surtout prouve) ce constat. En effet, le théorème central limite nous dit que cette moyenne $\\bar x_n$ vérifie $$\\sqrt{n}\\frac{\\bar x_n-\\mu}{\\sigma}\\to \\mathcal N(0,1)$$ avec $\\mu=0.5$ et $\\sigma=1/\\sqrt{12}$ ici. On a donc $$\\sqrt{n}\\frac{\\bar X_n-0.5}{1/\\sqrt{12}}\\to \\mathcal N(0,1)$$ Ce qui signifie qu'on peut approcher la loi de $\\bar X_n$ par la loi $\\mathcal N(0.5,1/(12n))$ avec $n=20$. On le retrouve sur notre exemple en supperposant cette distribution gaussienne sur l'histogramme\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(0.25,0.75,by=0.001)\ndf <- data.frame(x=x,y=dnorm(x,0.5,1/(sqrt(12*20))))\nggplot(moy)+aes(x=M,y=..density..)+geom_histogram(bins=20)+\n  geom_line(data=df,aes(x=x,y=y),color=\"red\",size=2)+xlab(\"x\")\n```\n\n::: {.cell-output-display}\n![](08-estimation_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {#exr-exo-TCL name=\"Théorème central limite\"}\nFaire le même travail pour des tailles d'échantillon de 50, 100 et 500. Interpréter.\n\n\n\n::: {.cell teacher='true'}\n\n```{.r .cell-code}\ndf1 <- matrix(runif(20*5000),nrow=20) \ndf2 <- matrix(runif(50*5000),nrow=50) \ndf3 <- matrix(runif(100*5000),nrow=100) \ndf4 <- matrix(runif(500*5000),nrow=500)\ndf <- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n                  n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 <- df |> gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"))+theme_classic()\n```\n\n::: {.cell-output-display}\n![](08-estimation_files/figure-pdf/unnamed-chunk-23-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.corR data-latex=\"\"}\nOn remarque que :\n\n-   dans tous les cas, la distribution de la moyenne empirique semble être gaussienne et centrée en 0.5 (qui est la valeur à estimer).\n-   la dispersion augmente lorsque le nombre d'observations $n$ diminue (moins précis).\n:::\n:::\n\n::: {#exr-exo-TCL2 name=\"Théorème central limite (toujours)\"}\nFaire le même exercice pour une loi gaussienne $\\mathcal N(1,2)$ et une loi de Bernoulli $\\mathcal B(0.6)$.\n\n::: {.corR data-latex=\"\"}\nPour la loi $\\mathcal N(1,2)$\n\n\n\n::: {.cell teacher='true'}\n\n```{.r .cell-code}\ndf1 <- matrix(rnorm(20*5000,1,2),nrow=20) \ndf2 <- matrix(rnorm(50*5000,1,2),nrow=50) \ndf3 <- matrix(rnorm(100*5000,1,2),nrow=100) \ndf4 <- matrix(rnorm(500*5000,1,2),nrow=500)\ndf <- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 <- df |> gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=50)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n```\n\n::: {.cell-output-display}\n![](08-estimation_files/figure-pdf/unnamed-chunk-24-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nPour la $\\mathcal B(0.6)$\n\n\n\n::: {.cell teacher='true'}\n\n```{.r .cell-code}\ndf1 <- matrix(rbinom(20*50000,1,0.6),nrow=20) \ndf2 <- matrix(rbinom(50*50000,1,0.6),nrow=50) \ndf3 <- matrix(rbinom(100*50000,1,0.6),nrow=100) \ndf4 <- matrix(rbinom(500*50000,1,0.6),nrow=500)\ndf <- data.frame(n20=apply(df1,2,mean),n50=apply(df2,2,mean),\n              n100=apply(df3,2,mean),n500=apply(df4,2,mean))\ndf1 <- df |> gather(key=\"taille_ech\",value=x)\nggplot(df1)+aes(x=x,y=..density..)+geom_histogram(bins=30)+\n  facet_wrap(~fct_relevel(taille_ech,\"n20\",\"n50\",\"n100\",\"n500\"),scales=\"fixed\")\n```\n\n::: {.cell-output-display}\n![](08-estimation_files/figure-pdf/unnamed-chunk-25-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nDans tous ces cas, on retrouve bien que la moyenne empirique a une distribution gaussienne autours de la valeur à estimer (l'espérance). La dispersion dépend de :\n\n-   la dispersion des observations (de la loi de $x_i$) ;\n-   du nombre d'observations.\n\nLa moyenne empirique est donc d'autant plus **précise** que la **variance des observations** est petite et que le **nombre d'observations** est grand. Le théorème central limite permet de quantifier tout ça et donc de déduire des intervalles de confiance et de faire des tests...\n:::\n:::\n\n## Intervalles de confiance\n\nOn cherche ici à illustrer numériquement le niveau d'un intervalle de confiance. On rappelle que $[A,B]$ est un IC de niveau $1-\\alpha$ pour un paramètre $\\theta$ si $$P(\\theta\\in[A,B])=1-\\alpha.$$\n\n::: {#exr-exo-ICgaussienne name=\"IC pour l'espérance d'une gaussienne\"}\nOn fixe ici le niveau à 0.95 ($\\alpha=0.05$). On considère $n$ observations $x_1,\\dots,x_n$ i.i.d de loi $\\mathcal N(\\mu,1)$ et on cherche un intervalle de confiance pour $\\mu$.\n\n1.  Générer $n=100$ observations i.i.d. selon la loi $\\mathcal N(\\mu,1)$ avec $\\mu=1$.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    ech <- rnorm(100,1,1)\n    ```\n    :::\n\n\n\n2.  Calculer un intervalle de confiance pour $\\mu$ de niveau 0.95.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    t.test(ech)$conf.int\n    ## [1] 0.8038101 1.2314117\n    ## attr(,\"conf.level\")\n    ## [1] 0.95\n    ```\n    :::\n\n\n\n3.  Selon-vous, peut-on dire que la probabilité que $\\mu$ appartienne à l'intervalle trouvé est de 0.95 ? Si non, comment peut-on interpréter cette formule.\n\n    ::: {.corR data-latex=\"\"}\n    **Non**. Dans notre cas, $\\mu$ (qui vaut 1) appartient à l'intervalle trouvé. Dans la vraie vie, $\\mu$ est inconnu. Ce que la formule nous dit, c'est que si nos données sont issues d'un loi $\\mathcal N(\\mu,\\sigma^2)$, on a une probabilité de 0.95 que $\\mu$ appartienne à l'intervalle trouvé. Donc si on génère un très grand nombre d'échantillon i.i.d selon la loi $\\mathcal N(\\mu,\\sigma^2)$, alors dans 95% des cas, la vraie valeur de $\\mu$ appartiendra à l'intervalle trouvé. C'est ce qu'on propose de vérifier dans les questions suivantes.\n    :::\n\n4.  Générer 5000 échantillons i.i.d. de loi $\\mathcal N(1,1)$ de tailles 100. On pourra mettre le tout dans une matrice de dimension $5000\\times 100$.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    mu <- 1\n    n <- 100\n    B <- 5000\n    X <- matrix(rnorm(n*B,mean=mu),nrow=B)\n    ```\n    :::\n\n\n\n5.  Calculer un intervalle de confiance de niveau 0.95 pour chacun des 5000 échantillons. On pourra utiliser une boucle **for** ou la fonction **apply**.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    b1 <- apply(X,1, function(x) t.test(x)$conf.int[1:2])\n    ```\n    :::\n\n\n\n6.  Sur les 5000 intervalles obtenus, calculer le nombre de fois où la vraie valeur de $\\mu$ (en l'occcurence ici 1) se trouve à l'intérieur de l'intervalle.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    b2 <- as.data.frame(t(b1))\n    b2 |> mutate(test=mu>V1 & mu<V2) |> summarize(mean(test))\n    ##   mean(test)\n    ## 1     0.9494\n    ```\n    :::\n\n\n\n7.  Refaire les questions 5-6-7 avec des IC de niveau 0.90.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    c1 <- apply(X,1, function(x) t.test(x,conf.level=0.90)$conf.int[1:2])\n    c2 <- as.data.frame(t(c1))\n    c2 |> mutate(test=mu>V1 & mu<V2) |> summarize(mean(test))\n    ##   mean(test)\n    ## 1      0.898\n    ```\n    :::\n\n\n:::\n\n::: {#exr-exo-ICiris name=\"IC pour les iris de Fisher\"}\nOn considère les données sur les iris de Fisher. Construire un intervalle de confiance de niveau 90% pour les paramètres suivants :\n\n-   La longueur de Pétales moyenne\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    t.test(iris$Petal.Length,conf.level=0.90)$conf.int\n    ## [1] 3.519434 3.996566\n    ## attr(,\"conf.level\")\n    ## [1] 0.9\n    ```\n    :::\n\n\n\n-   La largeur de Sépales moyenne de l'espèce Setosa\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    sep_set <- iris |> filter(Species==\"setosa\") |> select(Sepal.Width) \n    t.test(sep_set,conf.level=0.90)$conf.int\n    ## [1] 3.338124 3.517876\n    ## attr(,\"conf.level\")\n    ## [1] 0.9\n    #ou\n    iris |> filter(Species==\"setosa\") |> \n      select(Sepal.Width) |> t.test(conf.level=0.9)\n    ## \n    ## \tOne Sample t-test\n    ## \n    ## data:  select(filter(iris, Species == \"setosa\"), Sepal.Width)\n    ## t = 63.946, df = 49, p-value < 2.2e-16\n    ## alternative hypothesis: true mean is not equal to 0\n    ## 90 percent confidence interval:\n    ##  3.338124 3.517876\n    ## sample estimates:\n    ## mean of x \n    ##     3.428\n    ```\n    :::\n\n\n\n-   La largeur de Sépales moyenne des espèces Versicolor et Virginica\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    sep_vervin <- iris |> filter(Species==\"versicolor\" | Species ==\"virginica\") |> select(Sepal.Width) \n    t.test(sep_vervin,conf.level=0.90)$conf.int\n    ## [1] 2.81675 2.92725\n    ## attr(,\"conf.level\")\n    ## [1] 0.9\n    ```\n    :::\n\n\n:::\n\n::: {#exr-exo-ICproportion name=\"IC pour une proportion\"}\nOn considère $x_1,\\dots,x_n$ un échantillon i.i.d issu d'une loi de Bernoulli de paramètre $p\\in[0,1]$ inconnu.\n\n1.  Proposer un estimateur $\\widehat p$ pour $p$.\n\n    ::: {.corR data-latex=\"\"}\n    On peut prendre $$\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.$$\n    :::\n\n2.  A l'aide du TCL, obtenir la loi asymptotique de $\\hat p$.\n\n    ::: {.corR data-latex=\"\"}\n    On a d'après la TCL\n\n    $$\\sqrt{n}\\frac{\\widehat{p}-p}{\\sqrt{p(1-p)}}\\stackrel{\\mathcal L}{\\to}\\mathcal N(0,1)$$\n    :::\n\n3.  En déduire un intervalle de confiance de niveau $1-\\alpha$ pour $p$.\n\n    ::: {.corR data-latex=\"\"}\n    On déduit que $$\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right].$$\n\n    est un IC de niveau $1-\\alpha$.\n    :::\n\n4.  Que pouvez-vous reprocher à l'intervalle proposé à la question précédente ?\n\n    ::: {.corR data-latex=\"\"}\n    L'IC proposé dépend de $p$ qui est inconnu ! Il ne sera donc pas calculable en pratique !\n    :::\n\n5.  Proposer une solution.\n\n    ::: {.corR data-latex=\"\"}\n    Un solution classique consiste à remplacer le paramètre $p$ inconnu par son estimateur $\\widehat p$. On obtient ainsi l'IC $$\\left[\\widehat p-q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}, \\widehat p+q_{1-\\alpha/2}\\sqrt{\\frac{\\widehat p(1-\\widehat p)}{n}}\\right].$$\n    :::\n:::\n\n::: {#exr-exo-ICproportion2 name=\"IC pour une proportion (suite)\"}\nAfin de tenter de deviner qui va gagner une élection entre deux candidats $A$ et $B$ on effectue un sondage. On demande à 100 personnes pour qui elles vont voter. Les résultats sont reportés dans le vecteur suivant.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\nres <- rbinom(100,1,0.52)\n```\n:::\n\n\n\nOn désigne par $p$ la propotion (inconnue) d'électeurs qui vont voter pour $A$.\n\n1.  Proposer et calculer un estimateur de $p$.\n\n    ::: {.corR data-latex=\"\"}\n    On peut prendre la moyenne empirique $$\\widehat p=\\bar x_n=\\frac{1}{n}\\sum_{i=1}^nx_i.$$ On la calcule avec\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    phat <- mean(res)\n    phat\n    ## [1] 0.54\n    ```\n    :::\n\n\n\n2.  Que pouvez-vous conclure a priori.\n\n    ::: {.corR data-latex=\"\"}\n    Il semble que $A$ va remporter l'élection.\n    :::\n\n3.  En vous basant sur l'exercice précédent, calculer un intervalle de confiance de niveau 95% pour $p$.\n\n    ::: {.corR data-latex=\"\"}\n    On le calcule avec\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    n <- length(res)\n    binf <- phat-qnorm(0.975)*sqrt(phat*(1-phat)/n)\n    bsup <- phat+qnorm(0.975)*sqrt(phat*(1-phat)/n)\n    c(binf,bsup)\n    ## [1] 0.4423159 0.6376841\n    ```\n    :::\n\n\n\n4.  Est-ce que l'intervalle obtenu conforte votre conclusion de la question 2 ?\n\n    ::: {.corR data-latex=\"\"}\n    Non, en effet 0.5 se trouve dans l'intervalle de confiance !\n    :::\n\n5.  Calculer un intervalle de confiance pour $p$ à l'aide de la fonction **prop.test**.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prop.test(sum(res),n)\n    ## \n    ## \t1-sample proportions test with continuity correction\n    ## \n    ## data:  sum(res) out of n, null probability 0.5\n    ## X-squared = 0.49, df = 1, p-value = 0.4839\n    ## alternative hypothesis: true p is not equal to 0.5\n    ## 95 percent confidence interval:\n    ##  0.4377639 0.6391280\n    ## sample estimates:\n    ##    p \n    ## 0.54\n    ```\n    :::\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On remarque que l'IC obtenu ne correspond pas exactement à celui que nous avons calculé à la question 3. La fonction **prop.test** utilise une solution plus pertinente que de remplacer $p$ par son estimateur. La correction utilisée dans **prop.test** est plus préciser, il est recommandé d'utiliser celle là.\n    :::\n:::\n\n::: {#exr-exo-compmoyenne name=\"Comparaison de moyennes\"}\nPour le jeu de données `decathlon` disponible ici\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(FactoMineR)\ndata(decathlon)\n```\n:::\n\n\n\non souhaite comparer les performances au 100m en fonction de la compétition (Decastar vs JO).\n\n1.  Calculer un intervalle de confiance de niveau 95% pour la vitesse moyenne au 100m au Decastar.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    perf.D <- decathlon |> filter(Competition==\"Decastar\") |> select(`100m`)\n    t.test(perf.D)\n    ## \n    ## \tOne Sample t-test\n    ## \n    ## data:  perf.D\n    ## t = 163.64, df = 12, p-value < 2.2e-16\n    ## alternative hypothesis: true mean is not equal to 0\n    ## 95 percent confidence interval:\n    ##  11.02659 11.32418\n    ## sample estimates:\n    ## mean of x \n    ##  11.17538\n    ```\n    :::\n\n\n\n2.  Même question pour les jeux olympiques.\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    perf.JO <- decathlon |> filter(Competition==\"OlympicG\") |> select(`100m`)\n    t.test(perf.JO)\n    ## \n    ## \tOne Sample t-test\n    ## \n    ## data:  perf.JO\n    ## t = 250.02, df = 27, p-value < 2.2e-16\n    ## alternative hypothesis: true mean is not equal to 0\n    ## 95 percent confidence interval:\n    ##  10.82613 11.00530\n    ## sample estimates:\n    ## mean of x \n    ##  10.91571\n    ```\n    :::\n\n\n\n3.  Pouvez-vous conclure sur la question posée ? Si non, que faire ?\n\n    ::: {.corR data-latex=\"\"}\n    Il n'est pas possible de conclure. La bonne approche consiste à calculer un intervalle de confiance sur la différence moyenne des performances au 100m entre les deux compétitions et de regarder si 0 se situe dans l'intervalle.\n\n    On obtient l'intervalle avec\n    :::\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    t.test(perf.D,perf.JO)\n    ## \n    ## \tWelch Two Sample t-test\n    ## \n    ## data:  perf.D and perf.JO\n    ## t = 3.2037, df = 22.168, p-value = 0.00407\n    ## alternative hypothesis: true difference in means is not equal to 0\n    ## 95 percent confidence interval:\n    ##  0.09164794 0.42769272\n    ## sample estimates:\n    ## mean of x mean of y \n    ##  11.17538  10.91571\n    ```\n    :::\n\n\n\n    ::: {.corR data-latex=\"\"}\n    0 n'étant pas dans l'intervalle, on conclut que les performances sont différentes. On verra par la suite que les tests d'hypothèses permettent de traiter ce genre de questions de façons plus efficace.\n    :::\n:::\n",
    "supporting": [
      "08-estimation_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}