{
  "hash": "5a10993d80a456b5b7e19e3fb13fba96",
  "result": {
    "markdown": "\n::: {.content-visible when-format=\"html\"}\n::: {.cell}\n\\newcommand{\\prob}{\\mathbf P}\n\\newcommand{\\lt}{<}\n\\newcommand{\\mt}{>}\n:::\n\n```{=html}\n<style>\ndiv.correction {\n  color: black;\n  background-color: #F0F0F0;\n  font-style: normal;\n  /*display: none;*/\n}\n\n.corR {\n  font-style: italic;\n  /*display: none;*/\n}\n</style>\n```\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\\solntrue\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n# Régression avec R {#sec:estimation}\n\nLes problèmes de régression et de classification supervisée consistent à expliquer et/ou prédire une sortie $y\\in\\mathcal Y$ avec\n\n-   $\\mathcal Y=\\mathbb R$ pour la régression\n-   $\\mathcal Y$ de cardinal fini pour la classification supervisée,\n\npar des entrées $x\\in\\mathbb R^p$. Il s'agit donc de trouver une fonction $$m:\\mathbb R^p\\to\\mathcal Y$$ à partir de données $(X_1,Y_1),\\dots,(X_n,Y_n)$.\n\nCes données sont souvent collectées dans un **dataframe** `df` de la forme\n\n|   $Y$    |   $X_1$   |   $X_2$   | $\\dots$  |   $X_p$   |\n|:--------:|:---------:|:---------:|:--------:|:---------:|\n|  $y_1$   | $x_{1,1}$ | $x_{1,2}$ | $\\dots$  | $x_{1,p}$ |\n| $\\vdots$ | $\\vdots$  | $\\vdots$  | $\\vdots$ | $\\vdots$  |\n| $\\vdots$ | $\\vdots$  | $\\vdots$  | $\\vdots$ | $\\vdots$  |\n|  $y_n$   | $x_{n,1}$ | $x_{n,2}$ | $\\dots$  | $x_{n,p}$ |\n\nLe protocole pour construire un algorithme de régression sur **R** est toujours le même. Il faut spécifier :\n\n-   la méthode (ou l'algorithme)\n-   la variable à expliquer\n-   les variables explicatives\n-   le jeu de données\n-   les éventuelles options de la méthode considérée.\n\nPar exemple la commande\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmethod(Y~X1+X3,data=df,...)\n```\n:::\n\n\n\n\najustera le modèle **method** pour expliquer $Y$ par $X_1$ et $X_3$ avec les données dans **df** (les points représentent d'éventuelles options). Voici quelques exemples de méthodes :\n\n|    fonction R    |           algorithme           |   Package    |   Problème   |\n|:--------------:|:----------------------:|:--------------:|:--------------:|\n|      **lm**      |        modèle linéaire         |              |     Reg      |\n|     **glm**      |       modèle logistique        |              |    Class     |\n|     **lda**      | analyse discriminante linéaire |     MASS     |    Class     |\n|     **svm**      |     Support Vector Machine     |    e1071     |    Class     |\n|   **knn.reg**    |      plus proches voisins      |     FNN      |     Reg      |\n|     **knn**      |      plus proches voisins      |    class     |    Class     |\n|    **rpart**     |             arbres             |    rpart     | Reg et Class |\n|    **glmnet**    |         ridge et lasso         |    glmnet    | Reg et Class |\n|     **gbm**      |            boosting            |     gbm      | Reg et Class |\n| **randomForest** |       forêts aléatoires        | randomForest | Reg et Class |\n\n**Remarque**: pour `glmnet`, on ne peut pas utiliser de formule de la forme `Y~.`. Il faut spécifier une matrice pour les $X$ et un vecteur pour $Y$. La fonction **model.matrix** peut se révéler très utile pour calculer la matrice des $X$.\n\nPuisqu'il existe un grand nombre d'algorithmes pour répondre à un même problème de régression, il est important de définir des critères de performance afin de les comparer. Ces critères sont généralement inconnus et doivent être estimés à l'aide de procédure de type **apprentissage/validation** ou **validation croisée**. On a souvent besoin d'utiliser la fonction **predict** pour calculer ces critères. Cette fonction est une **fonction générique** : on peut utiliser **predict** pour une régression linéaire, logistique, un arbre, une forêt aléatoire... Pour obtenir l'aide de cette fonction pour\n\n-   la régression linéaire : taper **help(predict.lm)**\n-   la régression logisitque : taper **help(predict.glm)**\n-   les régressions pénalisées : taper **help(predict.glmnet)**\n-   les arbres : taper **help(predict.rpart)**\n-   les forêts aléatoires : taper **help(predict.randomForest)**\n-   ...\n\nDans la suite on suppose que $\\mathcal Y=\\mathbb R$ et on considère le modèle de régression $$Y=m(X)+\\varepsilon.$$ La performance d'un estimateur $\\widehat{m}$ de $m$ sera mesurée par son erreur quadratique de prédiction : $$E[(Y-\\widehat m(X))^2].$$\n\n## Modèle linéaire : fonctions lm et predict\n\n::: {#exr-exo-regression-intro name=\"Fonctions standards pour le modèle linéaire\"}\nOn considère le modèle de régression linéaire $$Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon$$ où $X_1,\\dots,X_p$ sont les variables explicatives, $Y$ la variable à expliquer et $\\varepsilon$ le terme d'erreur. On fixe $p=5$ et on considère les données suivantes :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1000\np <- 5\nset.seed(1234)\nX.mat <- matrix(rnorm(n*p),ncol=p)\neps <- rnorm(n,mean = 0,sd=0.5)\ndf <- data.frame(X.mat,eps)\ndf <- df |> mutate(Y=X1+X2+X3+X4+X5+eps) |> select(-eps)\n```\n:::\n\n\n\n\n1.  Construire un modèle linéaire permettant d'expliquer $Y$ par $X_1,\\dots,X_5$ (utiliser la fonction **lm**) et afficher les estimateurs de $\\beta_0,\\dots,\\beta_5$ (on pourra utiliser les fonctions **coef** et **summary**).\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    mod1 <- lm(Y~.,data=df)\n    coef(mod1)\n    ## (Intercept)          X1          X2          X3          X4          X5 \n    ##   0.0228707   1.0111903   1.0000752   1.0034085   1.0071250   0.9962842\n    summary(mod1)\n    ## \n    ## Call:\n    ## lm(formula = Y ~ ., data = df)\n    ## \n    ## Residuals:\n    ##      Min       1Q   Median       3Q      Max \n    ## -1.44876 -0.33840 -0.00769  0.33308  1.76883 \n    ## \n    ## Coefficients:\n    ##             Estimate Std. Error t value Pr(>|t|)    \n    ## (Intercept)  0.02287    0.01543   1.482    0.139    \n    ## X1           1.01119    0.01550  65.258   <2e-16 ***\n    ## X2           1.00008    0.01575  63.479   <2e-16 ***\n    ## X3           1.00341    0.01524  65.829   <2e-16 ***\n    ## X4           1.00712    0.01552  64.908   <2e-16 ***\n    ## X5           0.99628    0.01589  62.702   <2e-16 ***\n    ## ---\n    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    ## \n    ## Residual standard error: 0.4872 on 994 degrees of freedom\n    ## Multiple R-squared:  0.9556,\tAdjusted R-squared:  0.9554 \n    ## F-statistic:  4279 on 5 and 994 DF,  p-value: < 2.2e-16\n    ```\n    :::\n\n\n\n\n2.  On considère le jeu de données test suivant.\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    m <- 500\n    p <- 5\n    set.seed(12345)\n    X.mat <- matrix(rnorm(m*p),ncol=5)\n    eps <- rnorm(m,mean = 0,sd=0.5)\n    df.test <- data.frame(X.mat,eps)\n    df.test <- df.test |> mutate(Y=X1+X2+X3+X4+X5+eps) |> select(-eps)\n    ```\n    :::\n\n\n\n\n    Calculer, pour chaque individu de ce nouveau jeu de données, les prédictions faites par le modèle de la question précédente (utiliser la fonction **predict** avec l'option *newdata*).\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pred <- predict(mod1,newdata=df.test)\n    head(pred)\n    ##           1           2           3           4           5           6 \n    ##  0.09630147 -1.25027415 -0.52549286  0.19569041  3.72923032 -5.79419545\n    ```\n    :::\n\n\n\n\n3.  Créer un nouveau dataframe qui contiennent les valeurs prédites $\\widehat y_i$ à la question précédente sur une colonne et les valeurs observées $y_i$ du jeu de données `df.test` sur une autre colonne.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pred.df <- data.frame(pred=pred,obs=df.test$Y)\n    ```\n    :::\n\n\n\n\n4.  A l'aide du verbe **summarize**, calculer l'erreur quadratique moyenne (estimée) du modèle linéaire : $$\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2.$$\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pred.df |> summarize(MSE=mean((pred-obs)^2))\n    ##         MSE\n    ## 1 0.2326355\n    ```\n    :::\n\n\n\n:::\n\n## Sélection de variables\n\n::: {#exr-exo-regression-sel-var name=\"Sélection de variables\"}\nOn considère les données suivantes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1000\np <- 105\nset.seed(1234)\nX.mat <- matrix(rnorm(n*p),ncol=p)\neps <- rnorm(n,mean = 0,sd=0.5)\ndf <- data.frame(X.mat,eps)\ndf <- df |> mutate(Y=X1+X2+X3+X4+X5+eps) |> select(-eps)\n```\n:::\n\n\n\n\nissues du modèle $$Y=\\beta_0+\\beta_1X_1+\\dots+\\beta_pX_p+\\varepsilon$$ avec $p=105$. On remarquera que seules les variables $X_1,\\dots,X_5$ sont explicatives.\n\n1.  Ajuster un modèle linéaire (fonction **lm**) sur `df` et afficher les estimateurs de $\\beta_0,\\dots,\\beta_{105}$.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    mod2 <- lm(Y~.,data=df)\n    summary(mod2)$coefficients |> head()\n    ##                Estimate Std. Error   t value      Pr(>|t|)\n    ## (Intercept) -0.01307274 0.01660197 -0.787421  4.312441e-01\n    ## X1           0.98461851 0.01656206 59.450240 7.137528e-313\n    ## X2           0.99625236 0.01668382 59.713691 3.032293e-314\n    ## X3           1.01858539 0.01628043 62.565035  0.000000e+00\n    ## X4           1.00691542 0.01643050 61.283315 2.371515e-322\n    ## X5           1.00752931 0.01718708 58.621324 1.561036e-308\n    ```\n    :::\n\n\n\n\n2.  On propose d'utiliser une procédure de sélection de variables **backward** à partir du critère **BIC**. Effectuer cette procédure à l'aide de la fonction **step** (on pourra utiliser les options **direction=\"backward\"** et **k=log(n)**). On appellera ce modèle **mod.step**.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    mod.step <- step(mod2,direction=c(\"backward\"),k=log(n),trace=0)\n    summary(mod.step)\n    ## \n    ## Call:\n    ## lm(formula = Y ~ X1 + X2 + X3 + X4 + X5 + X29 + X69 + X74, data = df)\n    ## \n    ## Residuals:\n    ##      Min       1Q   Median       3Q      Max \n    ## -1.63923 -0.34301  0.00179  0.32041  1.45661 \n    ## \n    ## Coefficients:\n    ##              Estimate Std. Error t value Pr(>|t|)    \n    ## (Intercept) -0.002413   0.015749  -0.153  0.87828    \n    ## X1           0.992339   0.015807  62.777  < 2e-16 ***\n    ## X2           0.991358   0.016097  61.588  < 2e-16 ***\n    ## X3           1.010115   0.015562  64.907  < 2e-16 ***\n    ## X4           1.006043   0.015830  63.552  < 2e-16 ***\n    ## X5           1.008520   0.016242  62.093  < 2e-16 ***\n    ## X29         -0.043358   0.015158  -2.860  0.00432 ** \n    ## X69          0.042714   0.015292   2.793  0.00532 ** \n    ## X74         -0.043792   0.016118  -2.717  0.00670 ** \n    ## ---\n    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    ## \n    ## Residual standard error: 0.4969 on 991 degrees of freedom\n    ## Multiple R-squared:  0.954,\tAdjusted R-squared:  0.9537 \n    ## F-statistic:  2571 on 8 and 991 DF,  p-value: < 2.2e-16\n    ```\n    :::\n\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On a sélectionné un modèle avec 8 variables : les 5 explicatives et 3 variables de bruit.\n    :::\n\n3.  Calculer les erreurs quadratiques de prévision $$\\frac{1}{m}\\sum_{i\\in test}(\\widehat y_i-y_i)^2$$ des deux modèles (le modèle complet et le modèle sélectionné) en utilisant le jeu de données test suivant.\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    m <- 300\n    p <- 105\n    set.seed(12345)\n    X.mat <- matrix(rnorm(m*p),ncol=p)\n    eps <- rnorm(m,mean = 0,sd=0.5)\n    df.test <- data.frame(X.mat,eps)\n    df.test <- df.test |> mutate(Y=X1+X2+X3+X4+X5+eps) |> select(-eps)\n    ```\n    :::\n\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On calcule les prévisions et on les intègre dans un `tibble` :\n    :::\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    p.full <- predict(mod2,newdata=df.test)\n    p.step <- predict(mod.step,newdata=df.test)\n    pred.df <- tibble(full=p.full,step=p.step,obs=df.test$Y)\n    ```\n    :::\n\n\n\n\n    ::: {.corR data-latex=\"\"}\n    On en déduit les erreurs quadratiques moyennes :\n    :::\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    pred.df |> summarize(MSE.full=mean((full-obs)^2),MSE.step=mean((step-obs)^2))\n    ## # A tibble: 1 × 2\n    ##   MSE.full MSE.step\n    ##      <dbl>    <dbl>\n    ## 1    0.300    0.254\n    #ou\n    pred.df |> summarize_at(1:2,~(mean((.-obs)^2)))\n    ## # A tibble: 1 × 2\n    ##    full  step\n    ##   <dbl> <dbl>\n    ## 1 0.300 0.254\n    ```\n    :::\n\n\n\n:::\n\n## Régression logistique et arbre\n\n::: {#exr-exo-logit-arbre}\nOn considère le jeu de données **spam** disponible ici\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(kernlab)\ndata(spam)\n```\n:::\n\n\n\n\nLe problème est d'expliquer la variable `type` (un email est un spam ou non) par les 57 autres variables.\n\n1.  Séparer les données en un échantillon d'apprentissage `dapp` de taille 3000 et un échantillon test `dtest` de taille 1601. On pourra utiliser la fonction **sample**.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    set.seed(4321)\n    perm <- sample(nrow(spam),3000)\n    dapp <- spam[perm,]\n    dtest <- spam[-perm,]\n    ```\n    :::\n\n\n\n\n2.  Construire un modèle logistique permettant de répondre au problème en utilisant uniquement les données d'apprentissage. On utilisera la fonction **glm** avec l'option `family=\"binomial\"`.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    m.logit <- glm(type~.,data=dapp,family=\"binomial\")\n    ```\n    :::\n\n\n\n\n3.  A l'aide de la fonction **step**, effectuer une sélection backward (ça peut prendre quelques minutes).\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    m.step <- step(m.logit,direction=\"backward\",trace=0)\n    ```\n    :::\n\n    ::: {.cell}\n    \n    :::\n\n    ::: {.cell}\n    \n    :::\n\n\n\n\n4.  A l'aide de la fonction **rpart** du package **rpart**, construire un arbre de régression (toujours sur les données d'apprentissage) pour répondre au problème. On utilisera les paramètres par défaut de la fonction.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    library(rpart)\n    arbre <- rpart(type~.,data=dapp)\n    ```\n    :::\n\n\n\n\n5.  Visualiser l'arbre construit à l'aide des fonctions **rpart.plot** et **visTree** des packages **rpart.plot** et **visNetwork**\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    library(rpart.plot)\n    rpart.plot(arbre)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](09-regression_files/figure-epub/unnamed-chunk-21-1.png)\n    :::\n    \n    ```{.r .cell-code}\n    library(visNetwork)\n    visTree(arbre)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](09-regression_files/figure-epub/unnamed-chunk-21-2.png)\n    :::\n    :::\n\n\n\n\n6.  Pour les 3 modèles construits (logistique, backward et arbre) calculer les prédictions de la variable `type` pour les individus de l'échantillon `dtest`. On pourra regrouper ces prévisions dans un data-frame à 3 colonnes.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prev <- data.frame(\n      logit=predict(m.logit,newdata=dtest,type=\"response\") |> round() |> recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n      step=predict(m.step,newdata=dtest,type=\"response\") |> round() |> recode_factor(`0`=\"nonspam\",`1`=\"spam\"),\n      arbre=predict(arbre,newdata=dtest,type=\"class\"))\n    ```\n    :::\n\n\n\n\n7.  Ajouter au data-frame précédent une colonne où on mettra les valeurs observées de la variable à expliquer.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prev1 <- prev |> mutate(obs=dtest$type)\n    ```\n    :::\n\n\n\n\n8.  A l'aide de **summarize_at** calculer les erreurs de classification des 3 modèles.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    prev1 |> summarize_at(1:3,~(mean(obs!=.))) |> round(3)\n    ##   logit  step arbre\n    ## 1  0.07 0.074 0.109\n    ```\n    :::\n\n\n\n\n9.  Représenter les courbes **ROC** et calculer les **AUC**. On pourra consulter les pages 346 et 347 dans @rstat18 pour le tracé de courbes ROC sur **R**.\n\n\n\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    score <- data.frame(\n      logit=predict(m.logit,newdata=dtest,type=\"response\"),\n      step=predict(m.step,newdata=dtest,type=\"response\"),\n      arbre=predict(arbre,newdata=dtest,type=\"prob\")[,2]) |> \n      mutate(obs=dtest$type) |> \n      pivot_longer(-obs,names_to = \"Methode\",values_to=\"score\")\n    ```\n    :::\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    library(plotROC)\n    ggplot(score)+aes(d=obs,m=score,color=Methode)+geom_roc()+theme_classic()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](09-regression_files/figure-epub/unnamed-chunk-26-1.png)\n    :::\n    :::\n\n    ::: {.cell teacher='true'}\n    \n    ```{.r .cell-code}\n    score |> group_by(Methode) |> \n      summarize(AUC=as.numeric(pROC::auc(obs,score))) |> \n      mutate(AUC=round(AUC,3)) |>\n      arrange(desc(AUC))\n    ## # A tibble: 3 × 2\n    ##   Methode   AUC\n    ##   <chr>   <dbl>\n    ## 1 logit   0.975\n    ## 2 step    0.975\n    ## 3 arbre   0.894\n    ```\n    :::\n\n\n\n:::\n",
    "supporting": [
      "09-regression_files/figure-epub"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}